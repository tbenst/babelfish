{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3\"\n",
    "fidx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishIdx = [(\"e\", 2),  (\"e\", 5), (\"c\", 1),  (\"c\", 6),  (\"enp\", 1), (\"enp\", 5)]\n",
    "\n",
    "#%%\n",
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "import gc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from torchvision.transforms import Resize\n",
    "import dill\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "import resource\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import apex # https://github.com/NVIDIA/apex.git\n",
    "from apex.amp import amp\n",
    "\n",
    "\n",
    "import os, sys, datetime\n",
    "import itertools\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "sys.path.insert(0,\".\")\n",
    "from deepfish.helpers import get_frames_from_z, get_imaging_from_fish, gen_imaging, resize_volume, resize_batch, read_cnmf, no_overlap_idx, train_valid_test_split, train_test_split, pad_imaging\n",
    "\n",
    "from deepfish.stats import sampleMSE\n",
    "from deepfish.plot import interpret, plot_model_vs_real, makePredVideo, MSEbyDist, plot_embedding_over_time\n",
    "\n",
    "from deepfish.data import ZebraFishData\n",
    "# from deepfish.deep_kSVD import Deep_KSVD, train\n",
    "from deepfish.deep_skip import DeepSkip, train\n",
    "from deepfish.half_precision import network_to_half\n",
    "from deepfish.volume import volume_mse\n",
    "\n",
    "Model = DeepSkip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = False\n",
    "# gen = True\n",
    "cuda=True\n",
    "# cnmf=True\n",
    "cnmf=False\n",
    "half=True\n",
    "half=False\n",
    "multi_gpu = True\n",
    "num_workers = 16\n",
    "prev_frames = 5\n",
    "next_frames = 5\n",
    "model_name = \"180824_skip_resfix_small_X=t-4:t_Y=t+1,t+5_epochs=24_KL=1e-3_X_val_MSE(X)=2.64E+01_Y_val_MSE(Y)=3.054E+01\"\n",
    "\n",
    "f = all_data[fishIdx[fidx][0]][fishIdx[fidx][1]]\n",
    "\n",
    "\n",
    "frame_times = T.from_numpy(f.frame_st.mean(1).astype(np.float32))\n",
    "shocks = T.FloatTensor(frame_times.shape).zero_()\n",
    "shocks[np.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1\n",
    "\n",
    "tail_movements = T.FloatTensor(frame_times.shape).zero_()\n",
    "tail_movements[np.searchsorted(f.frame_et[:,-1],\n",
    "    f.tail_movement_start_times,side=\"left\")] = 1\n",
    "\n",
    "fishpath = '/data2/Data/MPzfish/drn_hb/{}/{}_small.npz'.format(f.fishid, f.fishid)\n",
    "imaging = np.load(fishpath)['fish']\n",
    "imaging = pad_imaging(imaging, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvt_split = train_test_split(2826, nchunks=20)\n",
    "total_examples = sum([len(x) for x in tvt_split.values()])\n",
    "print([\"{}: {} ({:.2f}%)\".format(k, len(v), 100*len(v)/total_examples) for k,v in tvt_split.items()])\n",
    "\n",
    "train_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        tvt_split['train'], prev_frames,next_frames)\n",
    "\n",
    "# valid_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "#                         tvt_split['validation'], prev_frames,next_frames)\n",
    "\n",
    "test_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        tvt_split['test'], prev_frames,next_frames)\n",
    "\n",
    "total_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        None, prev_frames,next_frames)\n",
    "\n",
    "_, nZ, H, W = train_data[0][0][\"brain\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEmbedding = 20\n",
    "batch_size = 8\n",
    "batch_size = 32\n",
    "\n",
    "conv_model = Model(nZ,H,W,nEmbedding,prev_frames,next_frames,\n",
    "                   tensor=T.cuda.FloatTensor)\n",
    "if multi_gpu:\n",
    "    conv_model = nn.DataParallel(conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.load_state_dict(T.load(\"/home/ubuntu/rsync/\"+model_name+\".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.cuda()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses_train = sampleMSE(conv_model, train_data, 16)\n",
    "mses_test = sampleMSE(conv_model, test_data, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mses_train[\"MSE(X_pred,Y_t+5)\"]\n",
    "b = mses_train[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mses_train[\"MSE(X_pred,X_t)\"]\n",
    "b = mses_train[\"MSE(Y_pred,X_t)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mses_test[\"MSE(X_pred,Y_t+5)\"]\n",
    "b = mses_test[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b), a.mean()-b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(2,1,1)\n",
    "mse_diff = mses_train[\"MSE(Y_pred,X_t-1)\"]-mses_train[\"MSE(X_pred,X_t-1)\"]\n",
    "sb.distplot(mse_diff,1000)\n",
    "plt.axvline(0,c='k')\n",
    "plt.title(\"Train\")\n",
    "plt.axvline(mse_diff.mean(),c='r')\n",
    "plt.subplot(2,1,2,sharex=ax)\n",
    "sb.distplot(mses_train[\"MSE(Y_pred,Y_t+5)\"] - \\\n",
    "            mses_train[\"MSE(X_pred,Y_t+5)\"], 1000)\n",
    "plt.axvline(0,c='k')\n",
    "plt.xlim(-0.5e8,.5e8)\n",
    "plt.savefig(\"train_mse_diff.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(2,1,1)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,X_t)\"]-mses_test[\"MSE(X_pred,X_t)\"])\n",
    "plt.axvline(0,c='k')\n",
    "plt.title(\"X_pred is closer to t (Test)\")\n",
    "plt.subplot(2,1,2,sharex=ax)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,Y_t+5)\"]-mses_test[\"MSE(X_pred,Y_t+5)\"])\n",
    "plt.title(\"Y_pred is closer to t+5 (Test)\")\n",
    "plt.axvline(0,c='k')\n",
    "plt.savefig('test_mse_diff.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(tvt_split[\"test\"],mses_test[\"MSE(X_pred,Y_t+5)\"],'.',c='indianred',alpha=0.5)\n",
    "plt.plot(tvt_split[\"test\"],mses_test[\"MSE(Y_pred,Y_t+5)\"],'.',c='steelblue',alpha=0.5)\n",
    "plt.subplot(2,1,2)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,Y_t+5)\"]-mses_test[\"MSE(X_pred,Y_t+5)\"])\n",
    "plt.axvline(0,c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_over_time(model,data, batch_size=64, num_workers=12):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    embeddings = []\n",
    "    logvars = []\n",
    "    model.eval()\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        with T.no_grad():\n",
    "            embedding, logvar, _ = model.encode(X.cuda())\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "        logvars.append(logvar.cpu().numpy())\n",
    "    model.train()\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    logvars = np.vstack(logvars)\n",
    "    nEmbeddings = embeddings.shape[1]\n",
    "    half = int(np.ceil(nEmbeddings / 2))\n",
    "    \n",
    "    plt.figure(figsize=(15,20))\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(embeddings[:,0:half])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(embeddings[:,half:])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    \n",
    "    plt.subplot(4,1,3)\n",
    "    plt.plot(logvars[:,0:half])\n",
    "    plt.title(\"Logvars over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(logvars[:,half:])\n",
    "    plt.title(\"Logvars over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = plot_embedding_over_time(conv_model.module,total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_for_vid(arr, mymin, mymax):\n",
    "    return ((arr - mymin) * (1/(mymax - mymin)) * 255).astype('uint8')\n",
    "\n",
    "import skvideo.io\n",
    "def makePredVideo(model, data, batch_size=32, num_workers=12, name=\"test\"):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    writer = skvideo.io.FFmpegWriter(model_name + \"_\"+name+\"_prediction.mp4\",outputdict={\n",
    "        '-b': '30000000', '-vcodec': 'libx264'})\n",
    "    mymax = float(T.cat([test_data[i][0]['brain'] for i in np.arange(len(test_data))]).max())\n",
    "    mymin = float(T.cat([test_data[i][0]['brain'] for i in np.arange(len(test_data))]).min())\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        with T.no_grad():\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), _, _= model(X.cuda(),Y_shock.cuda())\n",
    "        for x, x_pred, y, y_pred in zip(X,X_pred,Y,Y_pred):\n",
    "            # 7th z layer\n",
    "            zslice = x_pred[6]\n",
    "            H = zslice.shape[0]\n",
    "            W = zslice.shape[1]\n",
    "            frame = np.zeros([H*2,W*3])\n",
    "            \n",
    "            frame[:H, :W] = y[0,6]\n",
    "            frame[:H, W:(2*W)] = y[-1,6] - y[0,6]\n",
    "            frame[:H, (2*W):] = y[-1,6]\n",
    "            frame[H:, :W] = x_pred[6]\n",
    "            frame[H:, W:(2*W)] = y_pred[6] - y[0,6].cuda() #x_pred[6]\n",
    "            frame[H:, (2*W):] = y_pred[6]\n",
    "            writer.writeFrame(scale_for_vid(frame,mymin,mymax))\n",
    "    writer.close()\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = makePredVideo(conv_model,train_data,name='train')\n",
    "\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
