{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "import skimage as sk\n",
    "import skimage.io\n",
    "import skvideo\n",
    "import skvideo.io\n",
    "import torch\n",
    "import torch as T\n",
    "import scipy\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral,\n",
    "                                 denoise_wavelet, estimate_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/ubuntu/\"\n",
    "# filename = \"20180410_1.mp4\"\n",
    "filename = \"20180109_2.mp4\"\n",
    "vid_gen = skvideo.io.vreader(directory+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in vid_gen:\n",
    "    firstFrame = frame\n",
    "    break\n",
    "\n",
    "n = 20\n",
    "frames = np.zeros([n,*frame.shape]).astype(np.uint8)\n",
    "f = 0\n",
    "# get some frames over time \n",
    "for i,frame in enumerate(vid_gen):\n",
    "    if f >= n:\n",
    "        break\n",
    "    elif i % 1000 == 0:\n",
    "        frames[f] = frame\n",
    "        f+=1\n",
    "\n",
    "vid_gen = skvideo.io.vreader(directory+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(firstFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a good frame for ROI\n",
    "plt.imshow(frames[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 30\n",
    "maxThreshold = 30\n",
    "minThreshold = 7\n",
    "\n",
    "frame = np.full([pad*2+firstFrame.shape[0],pad*2+firstFrame.shape[1]], 1)\n",
    "frame[pad:-pad,pad:-pad] = denoise_tv_chambolle(frames[11,:,:,0]).copy()*255\n",
    "frame[frame>maxThreshold] = maxThreshold\n",
    "frame[frame<minThreshold] = 0\n",
    "plt.imshow(frame)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishCenter = (pad+235,pad+190)\n",
    "pad = 200\n",
    "\n",
    "fishROI = frame[fishCenter[0]-pad:fishCenter[0]+pad,fishCenter[1]-pad:fishCenter[1]+pad]\n",
    "\n",
    "# fishROI = normalize(fishROI, norm='l2')\n",
    "fishROI = fishROI - fishROI.mean()\n",
    "# fishROI = (fishROI - fishROI.mean())/fishROI.std()\n",
    "# fishROI = fishROI - fishROI.sum()/len(fishROI)\n",
    "fishROI = fishROI.astype(float32)\n",
    "\n",
    "fishROI[pad,pad] = np.max(fishROI)*2\n",
    "plt.imshow(fishROI)\n",
    "plt.colorbar()\n",
    "imageW, imageH = firstFrame.shape[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateImage(img, angle, pivot):\n",
    "    padX = [img.shape[1] - pivot[1], pivot[1]]\n",
    "    padY = [img.shape[0] - pivot[0], pivot[0]]\n",
    "    imgP = np.pad(img, [padY, padX], 'constant')\n",
    "    imgR = scipy.ndimage.rotate(imgP, angle, reshape=False)\n",
    "    return imgR[padY[0] : -padY[1], padX[0] : -padX[1]]\n",
    "\n",
    "def ROI_to_filters(img, center, pad, imageW, imageH, nfilters=8, fft=False, dtype=np.float32):\n",
    "    filter_size = 2*pad\n",
    "    # we will use the center of the img plus a pad to create rotationally invariant filters\n",
    "    filters = np.zeros([nfilters,filter_size,filter_size]).astype(np.float64)\n",
    "    norm = (img - img.mean()).astype(np.float64) # subtract mean\n",
    "    for i in range(nfilters):\n",
    "        # rotate the image first around the provided pivot\n",
    "        rot = rotateImage(norm, i * 360 / nfilters, center)\n",
    "        # select the ROI for the filter\n",
    "        filters[i] = rot[center[0]-pad:center[0]+pad,center[1]-pad:center[1]+pad]\n",
    "        \n",
    "    if fft:\n",
    "        complex_filters = T.cuda.FloatTensor(nfilters,imageW, imageH, 2).zero_()\n",
    "        complex_filters[:,0:filter_size,0:filter_size,0] = T.from_numpy(filters)\n",
    "        return T.fft(complex_filters,2)\n",
    "    else:\n",
    "        return T.from_numpy(filters.astype(dtype)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = np.float32\n",
    "filters = ROI_to_filters(frame, fishCenter, pad, imageW, imageH, 8,dtype=dtype)\n",
    "filters_fft = ROI_to_filters(frame, fishCenter, pad, imageW, imageH, 8, fft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(6,6,figsize=(12,12))\n",
    "for i in range(32):\n",
    "    plt.subplot(6,6,1+i)\n",
    "    plt.imshow(filters[i].cpu().numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = firstFrame[:,:,0].astype(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_fft(img, w, shape):\n",
    "    fimg = T.cuda.FloatTensor(*w.shape[1:]).zero_()\n",
    "    fimg[:,:,0] = T.from_numpy(img).cuda()\n",
    "    conv = T.ifft(T.fft(fimg,2)*w,2)\n",
    "    return conv[:,:,:,0]\n",
    "\n",
    "def heatmap(img, w, shape):\n",
    "    fimg = T.from_numpy(img).cuda()\n",
    "    pad = (int((w.shape[1])/2),int((w.shape[2])/2))\n",
    "    conv = F.conv2d(fimg[None,None,:,:,], w[:,None],padding=pad)\n",
    "    return conv[0,:,:,:]\n",
    "\n",
    "\n",
    "def find_position_fft(img, w, shape):\n",
    "    fimg = T.cuda.FloatTensor(*w.shape[1:]).zero_()\n",
    "    fimg[:,:,0] = T.from_numpy(img).cuda()\n",
    "    conv = T.ifft(T.fft(fimg,2)*w,2)\n",
    "    idx = conv.argmax()\n",
    "    return np.unravel_index(idx, shape)[1:3]\n",
    "\n",
    "def find_position(img, w):\n",
    "    fimg = T.from_numpy(img).cuda()\n",
    "    pad = (int((w.shape[1]-1)/2),int((w.shape[2]-1)/2))\n",
    "    conv = F.conv2d(fimg[None,None,:,:,], w[:,None],padding=pad)\n",
    "    idx = int(conv.argmax())\n",
    "    y, x = np.unravel_index(idx, conv.shape)[2:]\n",
    "    return y, x\n",
    "\n",
    "def find_position_threshold(img, w, minThreshold=0,maxThreshold=20):\n",
    "    fimg = T.from_numpy(img).cuda()\n",
    "    fimg[fimg>maxThreshold] = maxThreshold\n",
    "    fimg[fimg<minThreshold] = 0\n",
    "    pad = (int((w.shape[1]-1)/2),int((w.shape[2]-1)/2))\n",
    "    conv = F.conv2d(fimg[None,None,:,:,], w[:,None],padding=pad)\n",
    "    idx = int(conv.argmax())\n",
    "    y, x = np.unravel_index(idx, conv.shape)[2:]\n",
    "    return y, x\n",
    "\n",
    "\n",
    "def find_position_fft_np_argmax(img, w, shape):\n",
    "    fimg = T.cuda.FloatTensor(*w.shape[1:]).zero_()\n",
    "    fimg[:,:,0] = T.from_numpy(img).cuda()\n",
    "    conv = T.ifft(T.fft(fimg,2)*w,2)\n",
    "    idx = conv[:,:,:,0].cpu().numpy().argmax()\n",
    "    return np.unravel_index(idx, shape)[1:3]\n",
    "\n",
    "shape = [1, filters.shape[0],*img.shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "pos = heatmap_fft(img,filters_fft,shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "# for some reason, pytorch argmax is performing very slowly.\n",
    "pos = find_position_fft(img,filters_fft,shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "# numpy's argmax is performing much better, but this is suboptimal\n",
    "# as must transfer entire image back to CPU\n",
    "pos = find_position_fft_np_argmax(img,filters_fft,shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "pos = heatmap(img,filters,shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "pos = find_position(img,filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img8 = img.astype(np.uint8)\n",
    "filters8 = filters.byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(img, w, shape):\n",
    "    fimg = T.from_numpy(img).cuda()\n",
    "    pad = (int((w.shape[1])/2),int((w.shape[2])/2))\n",
    "    conv = F.conv2d(fimg[None,None,:,:,], w[:,None])\n",
    "#     conv = F.conv2d(fimg[None,None,:,:,], w[:,None])\n",
    "    return conv[0,:,:,:]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,c,kernel):\n",
    "        super(Net, self).__init__()\n",
    "        pad = (int((kernel[0])/2),int((kernel[1])/2))\n",
    "        self.conv2d = nn.Conv2d(1,c,kernel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2d(x[None,None])\n",
    "        return x[0,:,:,:]\n",
    "\n",
    "model = Net(8,filters.shape[1:])\n",
    "model.cuda()\n",
    "fimg = T.from_numpy(img).cuda()\n",
    "ITERS = 100\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "for i in range(ITERS):\n",
    "    model(fimg)\n",
    "# pos = heatmap(img,filters,shape)\n",
    "torch.cuda.synchronize()\n",
    "print(\"Time / iteration: \", (time.time()-start)/ITERS)\n",
    "\n",
    "model = Net(8,filters.shape[1:])\n",
    "model.cuda().half()\n",
    "fimg = T.from_numpy(img16).cuda()\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "for i in range(ITERS):\n",
    "    model(fimg)\n",
    "# pos = heatmap(img16,filters16,shape)\n",
    "torch.cuda.synchronize()\n",
    "print(\"Time / iteration: \", (time.time()-start)/ITERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.from_numpy(img16).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "pos = heatmap(img16,filters16,shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "pos = find_position_threshold(img,filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT conv validation (failing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(heatmap(img, filters, shape).cpu().numpy()[0].astype(np.float64))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(heatmap_fft(img, filters_fft, shape)[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tracking video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawROI(img, y, x, width=20,dot=1):\n",
    "    colorimg = img.copy()\n",
    "    colorimg[y-dot:y+dot,x-dot:x+dot] = [0,255,0]\n",
    "\n",
    "    ystart = max(0,y-width)\n",
    "    yend = min(img.shape[0]-1,y+width)\n",
    "    xstart = max(0,x-width)\n",
    "    xend = min(img.shape[1]-1,x+width)\n",
    "    colorimg[ystart:yend,xstart] = [255,0,0]\n",
    "    colorimg[ystart:yend,xend] = [255,0,0]\n",
    "    colorimg[ystart,xstart:xend] = [255,0,0]\n",
    "    colorimg[yend,xstart:xend] = [255,0,0]\n",
    "    return colorimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = find_position_threshold(img,filters)\n",
    "plt.figure(figsize=(17,17))\n",
    "plt.imshow(drawROI(frames[7],*pos,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = skvideo.io.FFmpegWriter(directory + \"track_close_32filters_\" + filename)\n",
    "for t, frame in tqdm(enumerate(vid_gen)):\n",
    "    if t % 10 ==0:\n",
    "        img = frame[:,:,0].astype(np.float32)\n",
    "        pos = find_position(img,filters)\n",
    "        f = drawROI(frame,*pos,80)\n",
    "        writer.writeFrame(f)\n",
    "    if t > 1000*10:\n",
    "        break\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
