{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "sys.path.insert(0,os.path.expanduser(\"deepfish\"))\n",
    "from deepfish.deep_skip import DeepSkip, train\n",
    "Model = DeepSkip\n",
    "\n",
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from torchvision.transforms import Resize\n",
    "import dill\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "import resource\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "# import apex # https://github.com/NVIDIA/apex.git\n",
    "# from apex.amp import amp\n",
    "\n",
    "\n",
    "import os, sys, datetime\n",
    "import itertools\n",
    "# LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "# FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "# FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "# sys.path.insert(0,LF_CODE_PATH)\n",
    "# sys.path.insert(0,FT_CODE_PATH)\n",
    "# sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "# import passivity_2p_imaging_utils as p2putils\n",
    "# reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "# all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "# sys.path.insert(0,\".\")\n",
    "from deepfish.helpers import get_frames_from_z, get_imaging_from_fish, gen_imaging, resize_volume, resize_batch, read_cnmf, no_overlap_idx, train_valid_test_split, train_test_split, pad_imaging\n",
    "\n",
    "from deepfish.stats import sampleMSE\n",
    "from deepfish.plot import interpret, plot_model_vs_real, makePredVideo, MSEbyDist\n",
    "\n",
    "from deepfish.data import ZebraFishData\n",
    "# from deepfish.deep_kSVD import Deep_KSVD, train\n",
    "from deepfish.half_precision import network_to_half\n",
    "\n",
    "T.backends.cudnn.benchmark = True\n",
    "\n",
    "# PARAMETERS\n",
    "gen = False\n",
    "# gen = True\n",
    "cuda=True\n",
    "# cnmf=True\n",
    "cnmf=False\n",
    "half=True\n",
    "half=False\n",
    "multi_gpu = True\n",
    "num_workers = 16\n",
    "prev_frames = 5\n",
    "next_frames = 5\n",
    "kl_lambda = 5e-4\n",
    "sparse_lambda=1e-3\n",
    "lr=1e-3\n",
    "nepochs = 11\n",
    "nEmbedding = 20\n",
    "# batch_size = 6\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZebraFishDataRNA(Dataset):\n",
    "    \"B x nFrames x Z x H x W\"\n",
    "    def __init__(self, imaging, structural, shocks, tail_movements,\n",
    "                 index_map=None, prev_frames=2, next_frames=1):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        # use channel for future / prev frames\n",
    "        self.data = T.from_numpy(data)\n",
    "        self.prev_frames = prev_frames\n",
    "        self.next_frames = next_frames\n",
    "        self.shocks = shocks\n",
    "        self.tail_movements = tail_movements\n",
    "        self.index_map = index_map\n",
    "        self.structural = structural\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.index_map:\n",
    "            return len(self.index_map)\n",
    "        else:\n",
    "            return self.data.shape[0]-self.prev_frames - self.next_frames + 1\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"X[0]==X_i, X[1]==X_i-1, Y[0]==Y_i+1, Y[1]==Y_i+2\"\n",
    "        if self.index_map:\n",
    "            idx = self.index_map[i]\n",
    "        else:\n",
    "            idx = i + self.prev_frames - 1 # avoid wraparound\n",
    "        X = {\"brain\": [], \"shock\": [], \"tail_movement\": []}\n",
    "        Y = {\"brain\": [], \"shock\": [], \"tail_movement\": []}\n",
    "        for i in reversed(range(self.prev_frames)):\n",
    "            ix = idx-i\n",
    "            X[\"brain\"].append(self.data[ix])\n",
    "            X[\"shock\"].append(self.shocks[ix])\n",
    "            X[\"tail_movement\"].append(self.tail_movements[ix])\n",
    "        for i in range(1,self.next_frames+1):\n",
    "            ix = idx+i\n",
    "            Y[\"brain\"].append(self.data[ix])\n",
    "            Y[\"shock\"].append(self.shocks[ix])\n",
    "            Y[\"tail_movement\"].append(self.tail_movements[ix])\n",
    "        for s in structural:\n",
    "            X[\"brain\"].append(s)\n",
    "        X = {k: T.stack(v,0) for k,v in X.items()}\n",
    "        Y = {k: T.stack(v,0) for k,v in Y.items()}\n",
    "        return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imread\n",
    "from glob import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/data2/Data/f10542/small/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num = re.compile(\".*_zplane=(\\d*).npy\")\n",
    "get_z = lambda x: int(get_num.search(x).group(1))\n",
    "# planes = glob(directory+\"functional*.npy\")\n",
    "structural = glob(directory+\"*.npy\")\n",
    "structural = list(filter(lambda x: get_num.match(x) is None, structural))\n",
    "# planes = sorted(planes, key=lambda a: get_z(a))\n",
    "# nZ = len(planes)\n",
    "# print(f\"Number of planes: {nZ}\")\n",
    "structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging = np.load(directory+\"functional.npy\")\n",
    "isosbestic_gcamp = np.load(structural[1])\n",
    "postfix_gcamp = np.load(structural[2])\n",
    "postfix_gad = np.load(structural[3])\n",
    "postfix_vglut = np.load(structural[4])\n",
    "\n",
    "structural = T.from_numpy(np.stack([isosbestic_gcamp, postfix_gcamp, postfix_gad, postfix_vglut]))\n",
    "structural.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_frame = imaging.mean(0)\n",
    "\n",
    "nT, nZ, H, W = imaging.shape\n",
    "nT, nZ, H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shocks = T.from_numpy(np.zeros(nT).astype(np.float32))\n",
    "tail_movements = T.from_numpy(np.zeros(nT).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvt_split = train_valid_test_split(2826, nchunks=20)\n",
    "tvt_split = train_test_split(nT, nchunks=20)\n",
    "total_examples = sum([len(x) for x in tvt_split.values()])\n",
    "print([\"{}: {} ({:.2f}%)\".format(k, len(v), 100*len(v)/total_examples) for k,v in tvt_split.items()])\n",
    "\n",
    "\n",
    "# LOAD TIFF\n",
    "train_data = ZebraFishDataRNA(imaging,structural, shocks,tail_movements,\n",
    "                        tvt_split['train'], prev_frames,next_frames)\n",
    "\n",
    "# valid_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "#                         tvt_split['validation'], prev_frames,next_frames)\n",
    "\n",
    "# test_data = ZebraFishDataRNA(imaging,structural,shocks,tail_movements,\n",
    "test_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        tvt_split['test'], prev_frames,next_frames)\n",
    "\n",
    "# all_data = ZebraFishData(imaging,shocks,tail_movements,None,\n",
    "#                         prev_frames,next_frames)\n",
    "\n",
    "_, nZ, H, W = train_data[0][0][\"brain\"].shape\n",
    "\n",
    "\n",
    "# print(\"Number of tail movements in test: {}\".format(np.array([float(x[1][\"tail_movement\"]) for x in test_data]).sum()))\n",
    "\n",
    "\n",
    "# print(\"len(train_data): {}\".format(len(train_data)))\n",
    "\n",
    "# print(\"len(test_data): {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del imaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from volume import Vol2D\n",
    "from resnet import ResNet, BasicBlock\n",
    "from super_res import SuperResSkip\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from misc import sigmoid_schedule\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class DeepSkip(Vol2D):\n",
    "    def __init__(self, nZ=11, H=232, W=512, nEmbedding=20, prev_frames=1, next_frames=1,\n",
    "                 pred_hidden=20, tensor=T.cuda.FloatTensor):\n",
    "        super(DeepSkip, self).__init__(tensor)\n",
    "        self.tensor = tensor\n",
    "        self.nZ = nZ\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        self.lowH = 16\n",
    "        self.lowW = 16\n",
    "        self.lowFeatures = 1\n",
    "        self.prev_frames = prev_frames\n",
    "        # batch x channel x Z x H x W\n",
    "        # Encoding\n",
    "        self.resnet = ResNet(BasicBlock, [2, 2, 2, 2], prev_frames)\n",
    "        self.resOut = 64\n",
    "        self.nEmbedding = nEmbedding\n",
    "        assert nEmbedding % 2 == 0\n",
    "\n",
    "        # b x 11 x 32 x 11 x 25\n",
    "        self.encoding_mean = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        self.encoding_logvar = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        self.nhalf_embed = int(self.nEmbedding/2)\n",
    "        # Prediction\n",
    "        self.pred1 = nn.Linear(self.nhalf_embed+next_frames, pred_hidden) # add dim for shock_{t+1}\n",
    "        self.pred2 = nn.Linear(pred_hidden, self.nhalf_embed) # last 10 (context) are unused\n",
    "\n",
    "        # Prediction\n",
    "        self.predz1 = nn.Linear(self.nhalf_embed+next_frames, pred_hidden) # add dim for shock_{t+1}\n",
    "        self.predz2 = nn.Linear(pred_hidden, self.nhalf_embed) # last 10 (context) are unused\n",
    "\n",
    "        # Decoding\n",
    "        self.activation = nn.Tanh()\n",
    "        # only use 10 embeddings for frame decoding, the other 10 are context\n",
    "        self.decoding = nn.Linear(self.nhalf_embed,self.lowFeatures*nZ*self.lowH*self.lowW)\n",
    "        self.upconv1 = SuperResSkip(2,65,tensor)\n",
    "        # 11 x 16 x 32\n",
    "        self.upconv2 = SuperResSkip(2,65,tensor)\n",
    "        # 11 x 32 x 64\n",
    "        self.upconv3 = SuperResSkip(2,65,tensor)\n",
    "        # 11 x 64 x 128\n",
    "        self.upconv4 = SuperResSkip(2,65,tensor)\n",
    "        # 11 x 128 x 256\n",
    "#         self.upconv5 = SuperResSkip(2,tensor)\n",
    "        # 11 x 256 x 512\n",
    "\n",
    "        self.tail_decoding = nn.Linear(1,1)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        nn.init.xavier_normal_(self.encoding_mean.weight)\n",
    "        # TODO - make larger?\n",
    "        nn.init.xavier_normal_(self.encoding_logvar.weight,1e-3)\n",
    "\n",
    "    def sample_embedding(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = T.exp(0.5*logvar)\n",
    "            eps = T.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = x.transpose(1,2)\n",
    "        # X :: b x z x t x h x w\n",
    "        out = self.tensor(x.shape[0],x.shape[1],self.resOut)\n",
    "        layers = [\"conv1_out\", \"layer1_out\", \"layer2_out\", \"layer3_out\", \"layer4_out\"]\n",
    "        layer_outputs = {k: [] for k in layers}\n",
    "        for z in range(x.shape[1]):\n",
    "            out[:,z], layer_out = self.resnet(x[:,z])\n",
    "            for k in layers:\n",
    "#                 print(\"layer_out \"+k+\" shape: \"+ str(layer_out[k].shape))\n",
    "                layer_outputs[k].append(layer_out[k])\n",
    "        layer_outputs = {k: T.stack(v,1) for k,v in layer_outputs.items()}\n",
    "        mean = self.encoding_mean(out.reshape(x.shape[0],-1))\n",
    "        logvar = self.encoding_logvar(out.reshape(x.shape[0],-1))\n",
    "        return mean, logvar, layer_outputs\n",
    "\n",
    "    def predict(self, x, shock):\n",
    "        x = T.cat([x, shock],1)\n",
    "        x = self.activation(self.pred1(x))\n",
    "        x = self.pred2(x)\n",
    "        return x\n",
    "\n",
    "    def predictZero(self, x, shock):\n",
    "        x = T.cat([x, shock],1)\n",
    "        x = self.activation(self.predz1(x))\n",
    "        x = self.predz2(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, layer_output):\n",
    "        tail = T.sigmoid(self.tail_decoding(x[:,[0]])) # use first embedding only\n",
    "#         tail = F.sigmoid(self.tail_decoding(x[:,[0]])) # use first embedding only\n",
    "        # b x 10\n",
    "        # only use first half for brain data\n",
    "        x = self.activation(self.decoding(x[:,:int(self.nEmbedding/2)]))\n",
    "        x = x.reshape(x.shape[0],self.nZ,self.lowFeatures,self.lowH,self.lowW)\n",
    "#         print(\"upconv1\", x.shape)\n",
    "        x = self.upconv1(x, layer_output[\"layer3_out\"])\n",
    "#         print(\"upconv2\", x.shape)\n",
    "        x = self.upconv2(x, layer_output[\"layer2_out\"])\n",
    "#         print(\"upconv3\", x.shape)\n",
    "        x = self.upconv3(x, layer_output[\"layer1_out\"])\n",
    "#         print(\"upconv4\", x.shape)\n",
    "        x = self.upconv4(x, layer_output[\"conv1_out\"])\n",
    "#         x = self.upconv5(x)\n",
    "        x = self.crop(x[:,:,0])\n",
    "        # squeeze channel\n",
    "        return x, tail\n",
    "\n",
    "    def forward(self, x, shock):\n",
    "        \"Return Previous volume (denoised), next volume (prediction), latent mean and logvar.\"\n",
    "        mean, logvar, layer_outputs = self.encode(x)\n",
    "        encoded = self.sample_embedding(mean, logvar)\n",
    "        encoded_prev = self.predictZero(encoded[:,self.nhalf_embed:], shock)\n",
    "        encoded_pred = self.predict(encoded[:,:self.nhalf_embed], shock)\n",
    "        prev = self.decode(encoded_prev, layer_outputs) # force to use only skip connections for decode\n",
    "        pred = self.decode(encoded_pred, layer_outputs)\n",
    "        return prev, pred, mean, logvar # should we move variational layer? or return encoded_pred?\n",
    "\n",
    "def unit_norm_KL_divergence(mu, logvar):\n",
    "    \"Reconstruction + KL divergence losses summed over all elements and batch.\"\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    return -0.5 * T.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "\n",
    "def train(model,train_data,valid_data, nepochs=10, lr=1e-3, kl_lambda=1, kl_tail=1e2, half=False, cuda=True, batch_size=16, num_workers=8):\n",
    "    dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    kl_schedule = T.from_numpy(sigmoid_schedule(nepochs))\n",
    "    if half:\n",
    "        optimizer = apex.fp16_utils.FP16_Optimizer(T.optim.Adam(model.parameters(),lr=lr))\n",
    "    else:\n",
    "        optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "    if cuda:\n",
    "        kl_schedule = kl_schedule.cuda()\n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        cum_X_loss = 0\n",
    "        cum_Y_loss = 0\n",
    "        cum_kld_loss = 0\n",
    "        cum_tail_loss = 0\n",
    "        i = 0\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            X, Y = batch_data\n",
    "            X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "            Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                X_shock = X_shock.cuda()\n",
    "                Y_shock = Y_shock.cuda()\n",
    "                X_tail = X_tail.cuda()\n",
    "                Y_tail = Y_tail.cuda()\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "            if half:\n",
    "                X_pred = X_pred.float()\n",
    "                Y_pred = Y_pred.float()\n",
    "                mean = mean.float()\n",
    "                logvar = logvar.float()\n",
    "            kld = unit_norm_KL_divergence(mean, logvar)\n",
    "            mse_X = F.mse_loss(X_pred, Y[:,0])\n",
    "            mse_Y = F.mse_loss(Y_pred, Y[:,-1])\n",
    "            mse_tail = F.mse_loss(Y_pred_tail, Y_tail[:,[-1]])\n",
    "            loss = mse_X + mse_Y + kl_lambda*kl_schedule[e] * kld + kl_tail*mse_tail\n",
    "            if e==0:\n",
    "                print(\"MSE_X: {:.3E}, MSE_Y: {:.3E}, KLD: {:.3E}, Tail: {:.3E}\".format(float(mse_X),float(mse_Y),float(kld),float(mse_tail)))\n",
    "            optimizer.zero_grad()\n",
    "            if half:\n",
    "                optimizer.backward(loss)\n",
    "            else:\n",
    "                loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "            cum_X_loss += float(mse_X)\n",
    "            cum_Y_loss += float(mse_Y)\n",
    "            cum_kld_loss += float(kld)\n",
    "            cum_tail_loss += float(mse_tail)\n",
    "\n",
    "        avg_Y_loss = cum_Y_loss/len(train_data)\n",
    "        avg_X_loss = cum_X_loss/len(train_data)\n",
    "        print(\"avg_loss: {:3E}, X_loss: {:3E}, Y_loss: {:3E}, KLD: {:3E}, tail_loss: {:3E}\".format(\n",
    "            cum_loss/len(train_data), avg_X_loss, avg_Y_loss, cum_kld_loss/len(train_data), cum_tail_loss/len(train_data)))\n",
    "#         cum_loss = 0\n",
    "#         cum_X_loss = 0\n",
    "#         cum_Y_loss = 0\n",
    "#         cum_kld_loss = 0\n",
    "#         cum_tail_loss = 0\n",
    "#         model.eval()\n",
    "#         gc.collect()\n",
    "#         for batch_data in valid_dataloader:\n",
    "#             X, Y = batch_data\n",
    "#             X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "#             Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "#             if cuda:\n",
    "#                 X = X.cuda()\n",
    "#                 Y = Y.cuda()\n",
    "#                 X_shock = X_shock.cuda()\n",
    "#                 Y_shock = Y_shock.cuda()\n",
    "#                 X_tail = X_tail.cuda()\n",
    "#                 Y_tail = Y_tail.cuda()\n",
    "#             (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "#             if half:\n",
    "#                 X_pred = X_pred.float()\n",
    "#                 Y_pred = Y_pred.float()\n",
    "#                 mean = mean.float()\n",
    "#                 logvar = logvar.float()\n",
    "#             kld = unit_norm_KL_divergence(mean, logvar)\n",
    "#             mse_X = F.mse_loss(X_pred, Y[:,0])\n",
    "#             mse_Y = F.mse_loss(Y_pred, Y[:,-1])\n",
    "#             mse_tail = F.mse_loss(X_pred_tail, X_tail[:,[-1]])\n",
    "#             loss = mse_X + mse_Y + kl_lambda*kl_schedule[e] * kld + kl_tail*mse_tail\n",
    "#             cum_loss += float(loss)\n",
    "#             cum_X_loss += float(mse_X)\n",
    "#             cum_Y_loss += float(mse_Y)\n",
    "#             cum_kld_loss += float(kld)\n",
    "#             cum_tail_loss += float(mse_tail)\n",
    "#         model.train()\n",
    "#         avg_Y_valid_loss = cum_Y_loss/len(valid_data)\n",
    "#         print(\"VALIDATION: avg_loss: {:3E}, X_loss: {:3E}, Y_loss: {:3E}, KLD: {:3E}, tail_loss: {:3E}\".format(\n",
    "#             cum_loss/len(valid_data), cum_X_loss/len(valid_data), avg_Y_valid_loss, cum_kld_loss/len(valid_data), cum_tail_loss/len(valid_data)))\n",
    "    return avg_X_loss, avg_Y_loss, avg_Y_valid_loss\n",
    "\n",
    "\n",
    "def validation_loss(model,valid_data, kl_lambda=1, kl_tail=1e2, half=False, cuda=True, batch_size=16, num_workers=8):\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    cum_loss = 0\n",
    "    cum_X_loss = 0\n",
    "    cum_Y_loss = 0\n",
    "    cum_kld_loss = 0\n",
    "    cum_tail_loss = 0\n",
    "    with T.no_grad():\n",
    "        model.eval()\n",
    "        for batch_data in tqdm(valid_dataloader):\n",
    "            X, Y = batch_data\n",
    "            X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "            Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                X_shock = X_shock.cuda()\n",
    "                Y_shock = Y_shock.cuda()\n",
    "                X_tail = X_tail.cuda()\n",
    "                Y_tail = Y_tail.cuda()\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "            if half:\n",
    "                X_pred = X_pred.float()\n",
    "                Y_pred = Y_pred.float()\n",
    "                mean = mean.float()\n",
    "                logvar = logvar.float()\n",
    "            kld = unit_norm_KL_divergence(mean, logvar)\n",
    "            mse_X = F.mse_loss(X_pred, Y[:,0])\n",
    "            mse_Y = F.mse_loss(Y_pred, Y[:,-1])\n",
    "            mse_tail = F.mse_loss(X_pred_tail, X_tail[:,[-1]])\n",
    "            loss = mse_X + mse_Y + kl_lambda * kld + kl_tail*mse_tail\n",
    "            cum_loss += float(loss)\n",
    "            cum_X_loss += float(mse_X)\n",
    "            cum_Y_loss += float(mse_Y)\n",
    "            cum_kld_loss += float(kld)\n",
    "            cum_tail_loss += float(mse_tail)\n",
    "    model.train()\n",
    "    avg_Y_valid_loss = cum_Y_loss/len(valid_data)\n",
    "    avg_X_valid_loss = cum_X_loss/len(valid_data)\n",
    "    print(\"VALIDATION: avg_loss: {:3E}, X_loss: {:3E}, Y_loss: {:3E}, KLD: {:3E}, tail_loss: {:3E}\".format(\n",
    "    cum_loss/len(valid_data), cum_X_loss/len(valid_data), avg_Y_valid_loss, cum_kld_loss/len(valid_data), cum_tail_loss/len(valid_data)))\n",
    "    return avg_X_valid_loss, avg_Y_valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "multi_gpu = True\n",
    "\n",
    "tensorlib = T\n",
    "if cuda:\n",
    "    tensorlib = T.cuda\n",
    "\n",
    "if half:\n",
    "    tensor = tensorlib.HalfTensor\n",
    "else:\n",
    "    tensor = tensorlib.FloatTensor\n",
    "\n",
    "# conv_model = DeepSkip(nZ,H,W,nEmbedding,prev_frames + len(structural),next_frames, tensor=tensor)\n",
    "conv_model = DeepSkip(nZ,H,W,nEmbedding,prev_frames,next_frames, tensor=tensor)\n",
    "if cuda:\n",
    "    conv_model.cuda()\n",
    "if half:\n",
    "    conv_model = apex.fp16_utils.network_to_half(conv_model)\n",
    "if multi_gpu:\n",
    "    conv_model = nn.DataParallel(conv_model)\n",
    "print(\"total num params:\", np.sum([np.prod(x.shape) for x in conv_model.parameters()]))\n",
    "# conv_model(data[0][0][None,:,None].cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.load_state_dict(T.load(\"/data2/trained_models/\"+\n",
    "#                                   \"190113_f15042_notail_gad_vglut_epoch=12_xloss={avg_X_loss:g}_yloss={avg_Y_loss:g}.pt\"))\n",
    "    \"190112_f15042_notail_nostructure_epoch=12_xloss=1.11E+2_yloss=1.29E+2.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_X_valid_loss, avg_Y_valid_loss = validation_loss(conv_model,test_data, kl_lambda=1e-3, half=half, cuda=cuda, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_X_valid_loss, avg_Y_valid_loss = validation_loss(conv_model,test_data, kl_lambda=1e-3, half=half, cuda=cuda, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: TEST DATA BEING USED\n",
    "avg_X_loss, avg_Y_loss, avg_Y_valid_loss = train(conv_model,train_data,test_data,nepochs,lr=lr, kl_lambda=1e-3, half=half, cuda=cuda, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "now = datetime.datetime.today().strftime('%y%m%d-%I:%M%p')\n",
    "\n",
    "model_name = \"/data2/trained_models/{}_{}_{}_X=t-4:t_Y=t+1,t+5_epochs={}\".format(now, f.fishid, model, nepochs) +     \"_Y_MSE={:.3E}_Y_val_MSE={:.3E}\".format(avg_Y_loss, avg_Y_valid_loss)\n",
    "\n",
    "\n",
    "T.save(conv_model.state_dict(),model_name+\".pt\")\n",
    "print(\"Saved \"+model_name+\".pt\")\n",
    "\n",
    "frame = makePredVideo(conv_model,train_data,name=model_name+'_train')\n",
    "makePredVideo(conv_model,train_data,name=model_name+'_test')\n",
    "\n",
    "model_name = f\"/data2/trained_models/\" + \\\n",
    "    \"190112_f15042_notail_gad_vglut_epoch=12_xloss={avg_X_loss:g}_yloss={avg_Y_loss:g}\"\n",
    "\n",
    "T.save(conv_model.state_dict(),\n",
    "       model_name+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.today().strftime('%y%m%d-%I:%M%p')\n",
    "\n",
    "model_name = \"/data2/trained_models/{}_{}_{}_X=t-4:t_Y=t+1,t+5_epochs={}\".format(now, f.fishid, model, nepochs) +     \"_Y_MSE={:.3E}_Y_val_MSE={:.3E}\".format(avg_Y_loss, avg_Y_valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.save(conv_model.state_dict(),model_name+\".pt\")\n",
    "print(\"Saved \"+model_name+\".pt\")\n",
    "\n",
    "frame = makePredVideo(conv_model,train_data,name=model_name+'_train')\n",
    "makePredVideo(conv_model,train_data,name=model_name+'_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_X_valid_loss, avg_Y_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"/data2/trained_models/\" + \\\n",
    "    f\"190113_f15042_notail_gad_vglut_epoch=12_xloss={avg_X_loss:g}_yloss={avg_Y_loss:g}\"\n",
    "\n",
    "T.save(conv_model.state_dict(),\n",
    "       model_name+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_frame_T = T.from_numpy(mean_frame).max(0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_for_vid(arr, mymin, mymax):\n",
    "    return ((arr - mymin) * (1/(mymax - mymin)) * 255).astype('uint8')\n",
    "\n",
    "def makePredVideo(model, data, mean_frame_T, abs=False, batch_size=32, num_workers=12, name=\"test\"):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    writer = skvideo.io.FFmpegWriter(name+\".mp4\",outputdict={\n",
    "        '-b': '30000000', '-vcodec': 'libx264'})\n",
    "    mymax = float(T.cat([test_data[i][0]['brain']+mean_frame_T for i in np.arange(len(test_data))]).max())\n",
    "    mymin = float(T.cat([test_data[i][0]['brain']+mean_frame_T for i in np.arange(len(test_data))]).min())\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        with T.no_grad():\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), _, _= model(X.cuda(),Y_shock.cuda())\n",
    "        for x, x_pred, y, y_pred in zip(X,X_pred,Y,Y_pred):\n",
    "            # 7th z layer\n",
    "            zslice = x_pred[6]\n",
    "            H = zslice.shape[0]\n",
    "            W = zslice.shape[1]\n",
    "            frame = np.zeros([H*2,W*3])\n",
    "\n",
    "            frame[:H, :W] = y[0].max(0)[0] + mean_frame_T\n",
    "            if abs:\n",
    "                frame[:H, W:(2*W)] = np.abs(y[-1].max(0)[0] - y[0].max(0)[0])\n",
    "                frame[H:, W:(2*W)] = np.abs(y_pred.max(0)[0].cpu() - y[0].max(0)[0])\n",
    "            else:\n",
    "                frame[:H, W:(2*W)] = y[-1].max(0)[0] - y[0].max(0)[0]\n",
    "                frame[H:, W:(2*W)] = y_pred.max(0)[0].cpu() - y[0].max(0)[0]\n",
    "            frame[:H, (2*W):] = y[-1].max(0)[0] + mean_frame_T\n",
    "            frame[H:, :W] = x_pred.max(0)[0].cpu() + mean_frame_T\n",
    "            \n",
    "            frame[H:, (2*W):] = y_pred.max(0)[0].cpu() + mean_frame_T\n",
    "            writer.writeFrame(scale_for_vid(frame,mymin,mymax))\n",
    "    writer.close()\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_for_vid(arr, mymin, mymax):\n",
    "    return ((arr - mymin) * (1/(mymax - mymin)) * 255).astype('uint8')\n",
    "\n",
    "def makePredVideo(model, data, mean_frame_T, abs=False, batch_size=32, num_workers=12, name=\"test\"):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    writer = skvideo.io.FFmpegWriter(name+\".mp4\",outputdict={\n",
    "        '-b': '30000000', '-vcodec': 'libx264'})\n",
    "    mymax = float(T.cat([test_data[i][0]['brain']+mean_frame_T for i in np.arange(len(test_data))]).max())\n",
    "    mymin = float(T.cat([test_data[i][0]['brain']+mean_frame_T for i in np.arange(len(test_data))]).min())\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        with T.no_grad():\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), _, _= model(X.cuda(),Y_shock.cuda())\n",
    "        for x, x_pred, y, y_pred in zip(X,X_pred,Y,Y_pred):\n",
    "            # 7th z layer\n",
    "            zslice = x_pred[6]\n",
    "            H = zslice.shape[0]\n",
    "            W = zslice.shape[1]\n",
    "            frame = np.zeros([H*2,W*3])\n",
    "\n",
    "            frame[:H, :W] = y[0][13][0] + mean_frame_T\n",
    "            if abs:\n",
    "                frame[:H, W:(2*W)] = np.abs(y[-1][13][0] - y[0][13][0])\n",
    "                frame[H:, W:(2*W)] = np.abs(y_pred[13][0].cpu() - y[0][13][0])\n",
    "            else:\n",
    "                frame[:H, W:(2*W)] = y[-1][13][0] - y[0][13][0]\n",
    "                frame[H:, W:(2*W)] = y_pred[13][0].cpu() - y[0][13][0]\n",
    "            frame[:H, (2*W):] = y[-1][13][0] + mean_frame_T\n",
    "            frame[H:, :W] = x_pred[13][0].cpu() + mean_frame_T\n",
    "            \n",
    "            frame[H:, (2*W):] = y_pred[13][0].cpu() + mean_frame_T\n",
    "            writer.writeFrame(scale_for_vid(frame,mymin,mymax))\n",
    "    writer.close()\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = makePredVideo(conv_model,test_data,\n",
    "                      T.from_numpy(mean_frame)[13], False,\n",
    "                      name=model_name+'_demean_z=13_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymin, mymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scale_for_vid(mean_frame_T.numpy(), mymin, mymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del imaging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
