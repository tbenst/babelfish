{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3\"\n",
    "fidx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishIdx = [(\"e\", 2),  (\"e\", 5), (\"c\", 1),  (\"c\", 6),  (\"enp\", 1), (\"enp\", 5)]\n",
    "\n",
    "#%%\n",
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "import gc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from torchvision.transforms import Resize\n",
    "import dill\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "import resource\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import apex # https://github.com/NVIDIA/apex.git\n",
    "from apex.amp import amp\n",
    "\n",
    "\n",
    "import os, sys, datetime\n",
    "import itertools\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "sys.path.insert(0,\".\")\n",
    "from deepfish.helpers import get_frames_from_z, get_imaging_from_fish, gen_imaging, resize_volume, resize_batch, read_cnmf, no_overlap_idx, train_valid_test_split, train_test_split, pad_imaging\n",
    "\n",
    "from deepfish.stats import sampleMSE\n",
    "from deepfish.plot import interpret, plot_model_vs_real, makePredVideo, MSEbyDist, plot_embedding_over_time\n",
    "\n",
    "from deepfish.data import ZebraFishData\n",
    "# from deepfish.deep_kSVD import Deep_KSVD, train\n",
    "from deepfish.deep_skip import DeepSkip, train\n",
    "from deepfish.half_precision import network_to_half\n",
    "from deepfish.volume import volume_mse\n",
    "\n",
    "Model = DeepSkip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = False\n",
    "# gen = True\n",
    "cuda=True\n",
    "# cnmf=True\n",
    "cnmf=False\n",
    "half=True\n",
    "half=False\n",
    "multi_gpu = True\n",
    "num_workers = 16\n",
    "prev_frames = 5\n",
    "next_frames = 5\n",
    "model_name = \"180825_f01555_deep_skip_X=t-4:t_Y=t+1,t+5_epochs=15_Y_MSE=2.523E+01_Y_val_MSE=3.078E+01\"\n",
    "\n",
    "f = all_data[fishIdx[fidx][0]][fishIdx[fidx][1]]\n",
    "\n",
    "\n",
    "frame_times = T.from_numpy(f.frame_st.mean(1).astype(np.float32))\n",
    "shocks = T.FloatTensor(frame_times.shape).zero_()\n",
    "shocks[np.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1\n",
    "\n",
    "tail_movements = T.FloatTensor(frame_times.shape).zero_()\n",
    "tail_movements[np.searchsorted(f.frame_et[:,-1],\n",
    "    f.tail_movement_start_times,side=\"left\")] = 1\n",
    "\n",
    "fishpath = '/data2/Data/MPzfish/drn_hb/{}/{}_small.npz'.format(f.fishid, f.fishid)\n",
    "imaging = np.load(fishpath)['fish']\n",
    "imaging = pad_imaging(imaging, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvt_split = train_test_split(2826, nchunks=20)\n",
    "total_examples = sum([len(x) for x in tvt_split.values()])\n",
    "print([\"{}: {} ({:.2f}%)\".format(k, len(v), 100*len(v)/total_examples) for k,v in tvt_split.items()])\n",
    "\n",
    "train_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        tvt_split['train'], prev_frames,next_frames)\n",
    "\n",
    "# valid_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "#                         tvt_split['validation'], prev_frames,next_frames)\n",
    "\n",
    "test_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        tvt_split['test'], prev_frames,next_frames)\n",
    "\n",
    "total_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        None, prev_frames,next_frames)\n",
    "\n",
    "_, nZ, H, W = train_data[0][0][\"brain\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nEmbedding = 20\n",
    "batch_size = 8\n",
    "batch_size = 32\n",
    "\n",
    "conv_model = Model(nZ,H,W,nEmbedding,prev_frames,next_frames,\n",
    "                   tensor=T.cuda.FloatTensor)\n",
    "if multi_gpu:\n",
    "    conv_model = nn.DataParallel(conv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.load_state_dict(T.load(\"trained_models/\"+model_name+\".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.cuda()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses_train = sampleMSE(conv_model, train_data, 16)\n",
    "mses_test = sampleMSE(conv_model, test_data, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mses_train[\"MSE(X_pred,Y_t+5)\"]\n",
    "b = mses_train[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_train[\"MSE(X_pred,X_t-4)\"]\n",
    "b = mses_train[\"MSE(Y_pred,X_t-4)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_train[\"MSE(X_pred,X_t)\"]\n",
    "b = mses_train[\"MSE(Y_pred,X_t)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_test[\"MSE(X_pred,Y_t+5)\"]\n",
    "b = mses_test[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b), a.mean()-b.mean())\n",
    "\n",
    "a = mses_test[\"MSE(X_pred,X_t)\"]\n",
    "b = mses_test[\"MSE(Y_pred,X_t)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_test[\"MSE(X_pred,Y_t+1)\"]\n",
    "b = mses_test[\"MSE(Y_pred,Y_t+1)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishMAData(Dataset):\n",
    "    def __init__(self, imaging, ma=5, nfuture=1, index_map=None):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        self.data = T.from_numpy(data)\n",
    "        self.ma=ma\n",
    "        self.nfuture=nfuture\n",
    "        self.index_map=index_map\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.index_map:\n",
    "            return len(self.index_map)\n",
    "        else:\n",
    "            return self.data.shape[0]-self.ma-self.nfuture\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.index_map:\n",
    "            idx = self.index_map[i]\n",
    "        else:\n",
    "            idx = i\n",
    "        return self.data[(idx-self.ma+1):(idx+1)].mean(0), self.data[idx+self.nfuture]\n",
    "\n",
    "def MSE_MA(imaging, ma=5, nfuture=1, batch_size=256, index_map=None):\n",
    "    mse = []\n",
    "    with T.no_grad():\n",
    "        data = FishMAData(imaging, ma, nfuture,index_map)\n",
    "        dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            X, Y = batch_data\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            mse.append(volume_mse(X, Y).cpu())\n",
    "\n",
    "    return T.cat(mse).numpy()\n",
    "\n",
    "mses_ma_train_5 = MSE_MA(imaging, 5, 5, 256, tvt_split['train'])\n",
    "mses_ma_train_1 = MSE_MA(imaging, 5, 1, 256, tvt_split['train'])\n",
    "mses_ma_test_5 = MSE_MA(imaging, 5, 5, 256, tvt_split['test'])\n",
    "mses_ma_test_1 = MSE_MA(imaging, 5, 1, 256, tvt_split['test'])\n",
    "\n",
    "plt.hist(mse,30)\n",
    "plt.legend([\"MSE={:.4g}\".format(mse.mean())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mses_ma_train_5\n",
    "b = mses_train[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_ma_train_1\n",
    "b = mses_train[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_ma_test_5\n",
    "b = mses_test[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b), a.mean()-b.mean())\n",
    "\n",
    "# a = mses_ma_test_1\n",
    "# b = mses_test[\"MSE(Y_pred,X_t)\"]\n",
    "# print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mses_ma_test_1)\n",
    "plt.plot(mses_ma_test_5)\n",
    "plt.plot(mses_test[\"MSE(Y_pred,Y_t+1)\"])\n",
    "plt.plot(mses_test[\"MSE(Y_pred,Y_t+5)\"])\n",
    "plt.legend([\"MA1\",\"MA5\", \"Model1\", \"Model5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(mses_ma_train_1)\n",
    "plt.plot(mses_ma_train_5)\n",
    "plt.plot(mses_train[\"MSE(Y_pred,Y_t+5)\"])\n",
    "plt.legend([\"MA1\",\"MA5\", \"Model5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mses_ma_test_1)\n",
    "plt.plot(mses_ma_test_5)\n",
    "plt.plot(mses_test[\"MSE(Y_pred,Y_t+5)\"])\n",
    "plt.legend([\"MA1\",\"MA5\", \"Model5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mses_ma_test_1)\n",
    "plt.plot(mses_ma_test_5)\n",
    "plt.plot(mses_test[\"MSE(Y_pred,Y_t+5)\"])\n",
    "plt.legend([\"MA1\",\"MA5\", \"Model5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mses_ma_test)\n",
    "plt.plot(mses_test[\"MSE(Y_pred,Y_t+5)\"])\n",
    "plt.legend([\"MA\", \"Model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(2,1,1)\n",
    "mse_diff = mses_train[\"MSE(Y_pred,Y_t+1)\"]-mses_train[\"MSE(X_pred,Y_t+1)\"]\n",
    "sb.distplot(mse_diff,1000)\n",
    "plt.axvline(0,c='k')\n",
    "plt.title(\"Train\")\n",
    "plt.axvline(mse_diff.mean(),c='r')\n",
    "plt.subplot(2,1,2,sharex=ax)\n",
    "sb.distplot(mses_train[\"MSE(Y_pred,Y_t+5)\"] - \\\n",
    "            mses_train[\"MSE(X_pred,Y_t+5)\"], 1000)\n",
    "plt.axvline(0,c='k')\n",
    "# plt.xlim(-0.5e8,.5e8)\n",
    "plt.savefig(\"train_mse_diff.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(2,1,1)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,X_t)\"]-mses_test[\"MSE(X_pred,X_t)\"])\n",
    "plt.axvline(0,c='k')\n",
    "plt.title(\"X_pred is closer to t (Test)\")\n",
    "plt.subplot(2,1,2,sharex=ax)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,Y_t+5)\"]-mses_test[\"MSE(X_pred,Y_t+5)\"])\n",
    "plt.title(\"Y_pred is closer to t+5 (Test)\")\n",
    "plt.axvline(0,c='k')\n",
    "plt.savefig('test_mse_diff.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(tvt_split[\"test\"],mses_test[\"MSE(X_pred,Y_t+5)\"],'.',c='indianred',alpha=0.5)\n",
    "plt.plot(tvt_split[\"test\"],mses_test[\"MSE(Y_pred,Y_t+5)\"],'.',c='steelblue',alpha=0.5)\n",
    "plt.subplot(2,1,2)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,Y_t+5)\"]-mses_test[\"MSE(X_pred,Y_t+5)\"])\n",
    "plt.axvline(0,c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_over_time(model,data, batch_size=64, num_workers=12):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    embeddings = []\n",
    "    logvars = []\n",
    "    model.eval()\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        with T.no_grad():\n",
    "            embedding, logvar, _ = model.encode(X.cuda())\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "        logvars.append(logvar.cpu().numpy())\n",
    "    model.train()\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    logvars = np.vstack(logvars)\n",
    "    nEmbeddings = embeddings.shape[1]\n",
    "    half = int(np.ceil(nEmbeddings / 2))\n",
    "    \n",
    "    plt.figure(figsize=(15,20))\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(embeddings[:,0:half])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(embeddings[:,half:])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    \n",
    "    plt.subplot(4,1,3)\n",
    "    plt.plot(logvars[:,0:half])\n",
    "    plt.title(\"Logvars over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(logvars[:,half:])\n",
    "    plt.title(\"Logvars over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = plot_embedding_over_time(conv_model.module,total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging[500].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each latent\n",
    "    #for a sampling of vols\n",
    "#embedding = T.from_numpy(np.eye(nEmbedding)[i].astype(np.float32)).cuda()[None]\n",
    "framenum = 500\n",
    "halfembed = int(nEmbedding/2)\n",
    "model = conv_model.module\n",
    "with T.no_grad():\n",
    "    fish_vol = T.from_numpy(imaging[None,framenum:(framenum+next_frames)]).cuda()\n",
    "    encoded, logvar, skip = model.encode(fish_vol)\n",
    "    latent_state_pred = T.from_numpy(np.zeros(halfembed, dtype=np.float32)).cuda()[None]\n",
    "    #turn on latent being explored\n",
    "    shock_state = T.cuda.FloatTensor(5).zero_()[None]\n",
    "    pred_state = model.predict(latent_state_pred,shock_state)\n",
    "    pred_vol = model.decode(pred_state,skip)[0]\n",
    "\n",
    "    latent_state_prev = encoded[:,halfembed:]\n",
    "    shock_state = T.cuda.FloatTensor(5).zero_()[None]\n",
    "    prev_state = model.predictZero(latent_state_prev,shock_state)\n",
    "    prev_vol = model.decode(prev_state,skip)[0]\n",
    "plt.imshow(pred_vol[0,6]-prev_vol[0,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#WIP\n",
    "\n",
    "# def get_gradient_from_embedding(model,frame,embedding,niters=20, lr=1e-3):\n",
    "#     model.eval()\n",
    "#     frame = frame.cuda()\n",
    "#     frame.requires_grad = True\n",
    "#     embedding_pred, _ = model.encode(frame)\n",
    "#     print(embedding_pred.shape)\n",
    "#     embedding_pred.backward(gradient=embedding)\n",
    "#     model.train()\n",
    "#     return frame.grad[0]\n",
    "\n",
    "# def get_input_from_embedding(model,frame,embedding,niters=75, lr=1e-1, rand=False):\n",
    "#     \"Take an embedding vector, and use backprop to find the volume\"\n",
    "#     if rand:\n",
    "#         prev_img = T.rand_like(frame[None], requires_grad=True).cuda()\n",
    "#     else:\n",
    "#         prev_img = frame[None].cuda()\n",
    "#         prev_img.requires_grad = True\n",
    "#     optimizer = T.optim.Adam([prev_img],lr=lr)\n",
    "#     model.eval()\n",
    "#     for i in range(niters):\n",
    "#         embedding_pred, _ = model.encode(prev_img)\n",
    "#         loss = F.mse_loss(embedding_pred,embedding[None]) #+ 1e-7*T.norm(prev_img,1)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "# #         print(\"iter {} loss: \".format(i), float(loss))\n",
    "#     model.train()\n",
    "#     return prev_img[0].detach().cpu().numpy()\n",
    "\n",
    "def interpret(model,prev_vol, next_vol, nEmbedding):\n",
    "    \"Plot prev & next frame for each latent dimension\"\n",
    "    plt.figure(figsize=(10,40))\n",
    "    \n",
    "    embedding = T.from_numpy(np.zeros(nEmbedding).astype(np.float32)).cuda()[None]\n",
    "#     shock = T.FloatTensor([0,1])[:,None,None].cuda()\n",
    "    shock = T.cuda.FloatTensor(2,1,prev_frames).zero_()\n",
    "    shock[0] = T.zeros(1,prev_frames)\n",
    "    shock[1] = T.ones(1,prev_frames)\n",
    "    with T.no_grad():\n",
    "        prev_img = model.decode(embedding)[0][0] # ignore tail\n",
    "        next_img = model.decode(model.predict(embedding,shock[0]))[0][0] # ignore tail\n",
    "        next_img_shock = model.decode(model.predict(embedding,shock[1]))[0][0]\n",
    "        \n",
    "    plt.subplot(1+nEmbedding,4,1)\n",
    "    plt.imshow(prev_img[6])\n",
    "    plt.title(\"Prev (Zero Vector)\")\n",
    "    \n",
    "    plt.subplot(1+nEmbedding,4,2)\n",
    "    plt.imshow(next_img[6])\n",
    "    plt.title(\"Next (Zero Vector)\")\n",
    "    \n",
    "    plt.subplot(1+nEmbedding,4,3)\n",
    "    plt.imshow(next_img[6] - prev_img[6])\n",
    "    plt.title(\"Diff (Zero Vector)\")\n",
    "    \n",
    "    plt.subplot(1+nEmbedding,4,4)\n",
    "    plt.imshow(next_img_shock[6])\n",
    "    plt.title(\"Next (Shock)\")\n",
    "    for i in range(nEmbedding):\n",
    "        embedding = T.from_numpy(np.eye(nEmbedding)[i].astype(np.float32)).cuda()[None]\n",
    "        with T.no_grad():\n",
    "            prev_img = model.decode(embedding)[0][0]\n",
    "            next_img = model.decode(model.predict(embedding,shock[0]))[0][0]\n",
    "            next_img_shock = model.decode(model.predict(embedding,shock[0]))[0][0]\n",
    "        plt.subplot(1+nEmbedding,4,i*4+5)\n",
    "        plt.imshow(prev_img[6])\n",
    "        plt.title(\"Prev (Dim {})\".format(i))\n",
    "        \n",
    "        plt.subplot(1+nEmbedding,4,i*4+6)\n",
    "        plt.imshow(next_img[6])\n",
    "        plt.title(\"Next (Dim {})\".format(i))\n",
    "        \n",
    "        plt.subplot(1+nEmbedding,4,i*4+7)\n",
    "        plt.imshow(next_img[6]-prev_img[6])\n",
    "        plt.title(\"Diff (Dim {})\".format(i))\n",
    "        \n",
    "        plt.subplot(1+nEmbedding,4,i*4+8)\n",
    "        plt.imshow(next_img_shock[6])\n",
    "        plt.title(\"Next w/ shock (Dim {})\".format(i))\n",
    "    plt.tight_layout()\n",
    "\n",
    "x, y = data[1000]\n",
    "interpret(conv_model.module,x,y,nEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_for_vid(arr, mymin, mymax):\n",
    "    return ((arr - mymin) * (1/(mymax - mymin)) * 255).astype('uint8')\n",
    "\n",
    "import skvideo.io\n",
    "def makePredVideo(model, data, batch_size=32, num_workers=12, name=\"test\"):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    writer = skvideo.io.FFmpegWriter(model_name + \"_\"+name+\"_prediction.mp4\",outputdict={\n",
    "        '-b': '30000000', '-vcodec': 'libx264'})\n",
    "    mymax = float(T.cat([test_data[i][0]['brain'] for i in np.arange(len(test_data))]).max())\n",
    "    mymin = float(T.cat([test_data[i][0]['brain'] for i in np.arange(len(test_data))]).min())\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        with T.no_grad():\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), _, _= model(X.cuda(),Y_shock.cuda())\n",
    "        for x, x_pred, y, y_pred in zip(X,X_pred,Y,Y_pred):\n",
    "            # 7th z layer\n",
    "            zslice = x_pred[6]\n",
    "            H = zslice.shape[0]\n",
    "            W = zslice.shape[1]\n",
    "            frame = np.zeros([H*2,W*3])\n",
    "            \n",
    "            frame[:H, :W] = y[0,6]\n",
    "            frame[:H, W:(2*W)] = y[-1,6] - y[0,6]\n",
    "            frame[:H, (2*W):] = y[-1,6]\n",
    "            frame[H:, :W] = x_pred[6]\n",
    "            frame[H:, W:(2*W)] = y_pred[6] - y[0,6].cuda() #x_pred[6]\n",
    "            frame[H:, (2*W):] = y_pred[6]\n",
    "            writer.writeFrame(scale_for_vid(frame,mymin,mymax))\n",
    "    writer.close()\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = makePredVideo(conv_model,train_data,name='train')\n",
    "\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
