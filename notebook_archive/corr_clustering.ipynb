{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import torch as T\n",
    "import torch\n",
    "import os\n",
    "import skvideo\n",
    "from tqdm import tqdm\n",
    "import skvideo.io\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "f = all_data['e'][2]\n",
    "df = f.get_roi_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho_regions = [u'in_r_cerebellum', u'in_l_cerebellum', u'in_l_vthal',\n",
    "       u'in_l_tectum', u'in_l_raphe', u'in_r_hind', u'in_l_hind',\n",
    "       u'in_l_dthal', u'in_r_tectum', u'in_r_LHb', u'in_r_dthal',\n",
    "       u'in_r_raphe', u'in_r_tel',\n",
    "       u'in_l_MHb', u'in_l_tel', u'in_r_MHb', u'in_l_LHb', u'in_r_vthal']\n",
    "\n",
    "regions = df.columns[np.where([c in ortho_regions for c in df.columns])]\n",
    "df = df.assign(region_id=pd.Series(np.full(len(df),-1).astype(np.int32)).values)\n",
    "for i, region in enumerate(regions):\n",
    "    idx = np.where(df[region])[0]\n",
    "    df.loc[idx, \"region_id\"] = i\n",
    "df[regions].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = f.get_signals_raw(z=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"cnmf_f01555.npz\")\n",
    "cnmf = data['cnmf']\n",
    "raw = data['raw']\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearsonr(x, y):\n",
    "    \"\"\"\n",
    "    Mimics `scipy.stats.pearsonr`\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    x : 1D torch.Tensor\n",
    "    y : 1D torch.Tensor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r_val : float\n",
    "        pearsonr correlation coefficient between x and y\n",
    "    \n",
    "    Scipy docs ref:\n",
    "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
    "    \n",
    "    Scipy code ref:\n",
    "        https://github.com/scipy/scipy/blob/v0.19.0/scipy/stats/stats.py#L2975-L3033\n",
    "    Example:\n",
    "        >>> x = np.random.randn(100)\n",
    "        >>> y = np.random.randn(100)\n",
    "        >>> sp_corr = scipy.stats.pearsonr(x, y)[0]\n",
    "        >>> th_corr = pearsonr(torch.from_numpy(x), torch.from_numpy(y))\n",
    "        >>> np.allclose(sp_corr, th_corr)\n",
    "    \"\"\"\n",
    "    mean_x = torch.mean(x)\n",
    "    mean_y = torch.mean(y)\n",
    "    xm = x.sub(mean_x)\n",
    "    ym = y.sub(mean_y)\n",
    "    r_num = xm.dot(ym)\n",
    "    r_den = torch.norm(xm, 2) * torch.norm(ym, 2)\n",
    "    r_val = r_num / r_den\n",
    "    return r_val\n",
    "\n",
    "def corrcoef(x):\n",
    "    \"\"\"\n",
    "    Mimics `np.corrcoef`\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    x : 2D torch.Tensor\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    c : torch.Tensor\n",
    "        if x.size() = (5, 100), then return val will be of size (5,5)\n",
    "\n",
    "    Numpy docs ref:\n",
    "        https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html\n",
    "    Numpy code ref: \n",
    "        https://github.com/numpy/numpy/blob/v1.12.0/numpy/lib/function_base.py#L2933-L3013\n",
    "\n",
    "    Example:\n",
    "        >>> x = np.random.randn(5,120)\n",
    "        # result is a (5,5) matrix of correlations between rows\n",
    "        >>> np_corr = np.corrcoef(x)\n",
    "        >>> th_corr = corrcoef(torch.from_numpy(x))\n",
    "        >>> np.allclose(np_corr, th_corr.numpy())\n",
    "        # [out]: True\n",
    "    \"\"\"\n",
    "    # calculate covariance matrix of rows\n",
    "    mean_x = torch.mean(x, 1, keepdim=True)\n",
    "    xm = x.sub(mean_x.expand_as(x))\n",
    "    c = xm.mm(xm.t())\n",
    "    c = c / (x.size(1) - 1)\n",
    "\n",
    "    # normalize covariance matrix\n",
    "    d = torch.diag(c)\n",
    "    stddev = torch.pow(d, 0.5)\n",
    "    c = c.div(stddev.expand_as(c)+1e-8)\n",
    "    c = c.div(stddev.expand_as(c).t()+1e-8)\n",
    "\n",
    "    # clamp between -1 and 1\n",
    "    # probably not necessary but numpy does it\n",
    "    c = torch.clamp(c, -1.0, 1.0)\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_corr_cnmf = corrcoef(T.from_numpy(cnmf.T).cuda()).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf_linkage = hierarchy.linkage(\n",
    "    distance.pdist(neuron_corr_cnmf), method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sb.clustermap(neuron_corr_cnmf, row_linkage=cnmf_linkage, col_linkage=cnmf_linkage, method=\"ward\",\n",
    "               figsize=(16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_corr = corrcoef(T.from_numpy(M).cuda()).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_linkage = hierarchy.linkage(\n",
    "    distance.pdist(neuron_corr), method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_raw = sb.clustermap(neuron_corr, row_linkage=raw_linkage, col_linkage=raw_linkage, method=\"ward\",\n",
    "               figsize=(16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_raw.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_to_array(fig):\n",
    "    \"Convert matplotlib fig into a numpy array (rgb image)\"\n",
    "    fig.canvas.draw()\n",
    "    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsize = 250\n",
    "overlap = 0.75\n",
    "start = 0\n",
    "end = M.shape[1]-winsize\n",
    "\n",
    "# use single hierarchy\n",
    "writer = skvideo.io.FFmpegWriter(\"raw_corr_over_time.mp4\", outputdict={'-b': '30000000'})\n",
    "\n",
    "pbar = tqdm(total=end/(winsize*(1-overlap)))\n",
    "while start < end:\n",
    "    gc.collect()\n",
    "    corr = corrcoef(T.from_numpy(M[:,start:start+winsize]).cuda()).cpu().numpy()\n",
    "    cm = sb.clustermap(corr, row_linkage=raw_linkage, col_linkage=raw_linkage, method=\"ward\",\n",
    "               figsize=(15, 15))\n",
    "    del corr\n",
    "    f = fig_to_array(cm.fig)\n",
    "    del cm\n",
    "    for i in range(5):\n",
    "        writer.writeFrame(f)\n",
    "    del f\n",
    "    start += int((winsize*(1-overlap)))\n",
    "    pbar.update(1)\n",
    "    plt.close('all')\n",
    "pbar.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsize = 250\n",
    "overlap = 0.75\n",
    "start = 0\n",
    "end = cnmf.shape[0]-winsize\n",
    "\n",
    "# use single hierarchy\n",
    "writer = skvideo.io.FFmpegWriter(\"corr_over_time.mp4\", outputdict={'-b': '30000000'})\n",
    "\n",
    "pbar = tqdm(total=end/(winsize*(1-overlap)))\n",
    "while start < end:\n",
    "    corr = corrcoef(T.from_numpy(cnmf[start:start+winsize].T).cuda()).cpu().numpy()\n",
    "    cm = sb.clustermap(corr, row_linkage=cnmf_linkage, col_linkage=cnmf_linkage, method=\"ward\",\n",
    "               figsize=(15, 15))\n",
    "    f = fig_to_array(cm.fig)\n",
    "    for i in range(5):\n",
    "        writer.writeFrame(f)\n",
    "    start += int((winsize*(1-overlap)))\n",
    "    pbar.update(1)\n",
    "    plt.close('all')\n",
    "pbar.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsize = 200\n",
    "overlap = 0.75\n",
    "start = 0\n",
    "end = cnmf.shape[0]-winsize\n",
    "\n",
    "# use hierarchy per frame\n",
    "writer = skvideo.io.FFmpegWriter(\"corr_over_time_mult_hierarchy.mp4\", outputdict={'-b': '30000000'})\n",
    "\n",
    "pbar = tqdm(total=end/(winsize*(1-overlap)))\n",
    "while start < end:\n",
    "    corr = corrcoef(T.from_numpy(cnmf[start:start+winsize].T).cuda()).cpu().numpy()\n",
    "    cm = sb.clustermap(corr, method=\"ward\",\n",
    "               figsize=(15, 15))\n",
    "    f = fig_to_array(cm.fig)\n",
    "    for i in range(5):\n",
    "        writer.writeFrame(f)\n",
    "    start += int((winsize*(1-overlap)))\n",
    "    pbar.update(1)\n",
    "    plt.close('all')\n",
    "pbar.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_by_region(W, df):\n",
    "    neuron_map = np.argsort(df.where(df[\"region_id\"]>=0)[\"region_id\"]) # no region is -1\n",
    "    nHasRegion = np.sum(neuron_map!=-1) + 1 # last -1 index will be removed\n",
    "    newW = np.zeros(nHasRegion,nHasRegion)\n",
    "    new_order = neuron_map[np.arange(W.shape[0])]\n",
    "    new_order = new_order[new_order>=0]\n",
    "    newW = W[new_order]\n",
    "    newW = newW[:,new_order]\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    im = ax.imshow(newW)\n",
    "    fig.colorbar(im)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by region\n",
    "writer = skvideo.io.FFmpegWriter(\"corr_over_time_by_region.mp4\", outputdict={'-b': '30000000'})\n",
    "\n",
    "winsize = 200\n",
    "overlap = 0.75\n",
    "start = 0\n",
    "end = cnmf.shape[0]-winsize\n",
    "\n",
    "pbar = tqdm(total=end/(winsize*(1-overlap)))\n",
    "while start < end:\n",
    "    corr = corrcoef(T.from_numpy(cnmf[start:start+winsize].T).cuda()).cpu().numpy()\n",
    "    fig = plot_matrix_by_region(corr,df)\n",
    "    f = fig_to_array(fig)\n",
    "    for i in range(5):\n",
    "        writer.writeFrame(f)\n",
    "    start += int((winsize*(1-overlap)))\n",
    "    pbar.update(1)\n",
    "    plt.close('all')\n",
    "pbar.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=9\n",
    "df, sig = f.get_cnmf_roi_table_and_signals()\n",
    "\n",
    "#Create a background image by averaging 200 frames and adjusting the gamma.\n",
    "back_img = np.power(f.get_tif_rasl_as_vol(z,range(1,200)).mean(axis=2),.4)\n",
    "\n",
    "#Select rois in raphe in this slices, and get their coordinates.\n",
    "poly_coords = df[(df.z==z)].poly\n",
    "poly_coords = [np.round(poly[~np.isnan(poly).any(axis=1)])[:,(1,0)].astype(int) for poly in poly_coords]\n",
    "\n",
    "#Overlay the ROIs on the background image and display:\n",
    "img = vizutil.overlay_coords(back_img, poly_coords, [0,0,1], alpha=.5)\n",
    "plt.figure(figsize=[20,20])\n",
    "plt.imshow(img,interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf_linkage_clusters = hierarchy.fcluster(cnmf_linkage,10,criterion='maxclust')\n",
    "# includes all neurons, even those without cluster\n",
    "cluster_by_neuron = np.zeros(cnmf.shape[1]+1)\n",
    "for i,v in enumerate(cnmf_linkage_clusters):\n",
    "    cluster_by_neuron[i] = v\n",
    "cluster_by_neuron = cluster_by_neuron[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nclust = int(cluster_by_neuron.max())\n",
    "plt.subplots(nclust,1, figsize=[20,10*nclust])\n",
    "for clust in range(1,nclust+1):\n",
    "    #Select rois in raphe in this slices, and get their coordinates.\n",
    "    poly_coords = df[(cluster_by_neuron==clust) & (df.z==z)].poly\n",
    "    poly_coords = [np.round(poly[~np.isnan(poly).any(axis=1)])[:,(1,0)].astype(int) for poly in poly_coords]\n",
    "    plt.subplot(nclust,1,clust)\n",
    "    #Overlay the ROIs on the background image and display:\n",
    "    img = vizutil.overlay_coords(back_img, poly_coords, [0,0,1], alpha=.5)\n",
    "    plt.imshow(img,interpolation='nearest')\n",
    "    plt.title(\"Cluster {}\".format(clust))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(neuron_corr_cnmf)\n",
    "plt.title(\"Pearson Correlation by neuron - CNMF\")\n",
    "plt.xlabel(\"Neuron\")\n",
    "plt.ylabel(\"Neuron\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_neron_map = np.zeros(len(neuron_map)+1)\n",
    "for i,v in enumerate(neuron_map):\n",
    "    inverse_neron_map[v] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = neuron_corr\n",
    "neuron_map = np.argsort(df.where(df[\"region_id\"]>=0)[\"region_id\"]) # no region is -1\n",
    "labels = np.sort(df.where(df[\"region_id\"]>=0).dropna()[\"region_id\"])\n",
    "nHasRegion = np.sum(neuron_map!=-1) + 1 # last -1 index will be removed\n",
    "newW = np.zeros(nHasRegion,nHasRegion)\n",
    "new_order = neuron_map[np.arange(W.shape[0])]\n",
    "new_order = new_order[new_order>=0]\n",
    "newW = W[new_order]\n",
    "newW = newW[:,new_order]\n",
    "plt.imshow(newW)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward_row_linkage = hierarchy.linkage(\n",
    "    distance.pdist(newW), method='ward')\n",
    "ward_row_clusters = hierarchy.fcluster(ward_row_linkage,,criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.clustermap(newW, row_linkage=ward_row_linkage, method=\"ward\",\n",
    "               figsize=(13, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_corr = corrcoef(T.from_numpy(M.T).cuda()).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(time_corr)\n",
    "plt.title(\"Pearson Correlation by time step\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_corr_cnmf = corrcoef(T.from_numpy(cnmf).cuda()).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.frame_et.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(time_corr_cnmf)\n",
    "plt.title(\"Pearson Correlation by time step - CNMF\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_corr = corrcoef(T.from_numpy(M).cuda()).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(neuron_corr)\n",
    "plt.title(\"Pearson Correlation by neuron\")\n",
    "plt.xlabel(\"Neuron\")\n",
    "plt.ylabel(\"Neuron\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
