{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import ray\n",
    "import scipy.stats\n",
    "import os\n",
    "%pylab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(num_gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging = np.load('/home/ubuntu/f01555_small.npz')['fish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf = np.load('/home/ubuntu/f01555_cnmf_small.npz')['fish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_loss(X, Y, loss=nn.MSELoss(reduce=False),loop=False):\n",
    "    with T.no_grad():\n",
    "        if loop:\n",
    "            losses = []\n",
    "            for z in range(X.shape[1]):\n",
    "                l = loss(X[:,z],Y[:,z]).reshape(X.shape[0],-1).sum(1)\n",
    "                losses.append(l)\n",
    "            return T.stack(losses,1).sun(1)\n",
    "        losses = loss(X,Y).reshape(X.shape[0],-1).sum(1)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishDistanceData(Dataset):\n",
    "    def __init__(self, imaging, distance):\n",
    "        data = imaging\n",
    "        self.data = T.from_numpy(data)\n",
    "        self.distance=distance\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]-self.distance\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data[idx+self.distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_id = ray.put(imaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmf_id = ray.put(imaging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from math import exp\n",
    "\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()\n",
    "\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average=True, full=False):\n",
    "    padd = 0\n",
    "\n",
    "    mu1 = F.conv2d(img1, window, padding=padd, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=padd, groups=channel)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1*img1, window, padding=padd, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2*img2, window, padding=padd, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1*img2, window, padding=padd, groups=channel) - mu1_mu2\n",
    "\n",
    "    C1 = 0.01**2\n",
    "    C2 = 0.03**2\n",
    "\n",
    "    ssim_map = ((2*mu1_mu2 + C1)*(2*sigma12 + C2))/((mu1_sq + mu2_sq + C1)*(sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    v1 = 2.0 * sigma12 + C2\n",
    "    v2 = sigma1_sq + sigma2_sq + C2\n",
    "    cs = torch.mean(v1 / v2)\n",
    "\n",
    "    if size_average:\n",
    "        ret = ssim_map.mean()\n",
    "    else:\n",
    "        ret = ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "    if full:\n",
    "        return ret, cs\n",
    "    return ret\n",
    "\n",
    "\n",
    "class SSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size=11, size_average=True):\n",
    "        super(SSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = 1\n",
    "        self.window = create_window(window_size, self.channel)\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        (_, channel, _, _) = img1.size()\n",
    "\n",
    "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
    "            window = self.window\n",
    "        else:\n",
    "            window = create_window(self.window_size, channel)\n",
    "            \n",
    "            if img1.is_cuda:\n",
    "                window = window.cuda(img1.get_device())\n",
    "            window = window.type_as(img1)\n",
    "            \n",
    "            self.window = window\n",
    "            self.channel = channel\n",
    "\n",
    "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
    "\n",
    "\n",
    "def ssim(img1, img2, window_size=11, size_average=True, full=False):\n",
    "    (_, channel, height, width) = img1.size()\n",
    "\n",
    "    real_size = min(window_size, height, width)\n",
    "    window = create_window(real_size, channel)\n",
    "    \n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    \n",
    "    return _ssim(img1, img2, window, real_size, channel, size_average, full=full)\n",
    "\n",
    "\n",
    "def msssim(img1, img2, window_size=11, size_average=True):\n",
    "    # TODO: fix NAN results\n",
    "    if img1.size() != img2.size():\n",
    "        raise RuntimeError('Input images must have the same shape (%s vs. %s).' %\n",
    "                           (img1.size(), img2.size()))\n",
    "    if len(img1.size()) != 4:\n",
    "        raise RuntimeError('Input images must have four dimensions, not %d' %\n",
    "                           len(img1.size()))\n",
    "\n",
    "#     if type(img1) is not Variable or type(img2) is not Variable:\n",
    "#         raise RuntimeError('Input images must be Variables, not %s' % \n",
    "#                             img1.__class__.__name__)\n",
    "\n",
    "    weights = Variable(torch.FloatTensor([0.0448, 0.2856, 0.3001, 0.2363, 0.1333]))\n",
    "    if img1.is_cuda:\n",
    "        weights = weights.cuda(img1.get_device())\n",
    "\n",
    "    levels = weights.size()[0]\n",
    "    mssim = []\n",
    "    mcs = []\n",
    "    for _ in range(levels):\n",
    "        sim, cs = ssim(img1, img2, window_size=window_size, size_average=size_average, full=True)\n",
    "        mssim.append(sim)\n",
    "        mcs.append(cs)\n",
    "\n",
    "        img1 = F.avg_pool2d(img1, (2, 2))\n",
    "        img2 = F.avg_pool2d(img2, (2, 2))\n",
    "    mssim = torch.stack(mssim)\n",
    "    mcs = torch.stack(mcs)\n",
    "    return (torch.prod(mcs[0:levels-1] ** weights[0:levels-1]) *\n",
    "            (mssim[levels-1] ** weights[levels-1]))\n",
    "\n",
    "\n",
    "class MSSSIM(torch.nn.Module):\n",
    "    def __init__(self, window_size=11, size_average=True, channel=3):\n",
    "        super(MSSSIM, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.size_average = size_average\n",
    "        self.channel = channel\n",
    "\n",
    "    def forward(self, img1, img2):\n",
    "        # TODO: store window between calls if possible\n",
    "        return msssim(img1, img2, window_size=self.window_size, size_average=self.size_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loss_local(imaging, distance, loss_func, batch_size=256):\n",
    "    data = FishDistanceData(imaging,distance)\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    loss = []\n",
    "#     T.arange(5).cuda(gpuid)\n",
    "    with T.no_grad():\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            X, Y = batch_data\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            loss.append(loss_func(X, Y).cpu())\n",
    "    return T.cat(loss).numpy()\n",
    "\n",
    "@ray.remote(num_gpus=1)\n",
    "def data_loss(imaging, distance, loss_func, batch_size=256):\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(i) for i in ray.get_gpu_ids()])\n",
    "    data = FishDistanceData(imaging,distance)\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    loss = []\n",
    "    with T.no_grad():\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            X, Y = batch_data\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            loss.append(loss_func(X, Y).cpu())\n",
    "    return T.cat(loss).numpy()\n",
    "\n",
    "def lossByDist(imaging, maxdist=3, loss_func=volume_loss, name=\"MSE\",batch_size=256):\n",
    "    losses = []\n",
    "    \n",
    "    for d in range(1,maxdist+1):\n",
    "        losses.append(data_loss.remote(imaging, d, loss_func, batch_size))\n",
    "\n",
    "    losses = [ray.get(l) for l in losses]\n",
    "    count, bins = np.histogram(losses[0])\n",
    "    ind = np.linspace(bins[0],bins[-1],250)\n",
    "    kde = []\n",
    "    for l in losses:\n",
    "        kde.append(scipy.stats.gaussian_kde(l).evaluate(ind))\n",
    "    oc = 1 - (np.sum(kde[0]) - np.sum(np.min(kde[0:2],0)))/np.sum(kde[0])\n",
    "\n",
    "    for k in kde:\n",
    "        plt.plot(ind, k)\n",
    "    plt.legend([\"mean(distance {})={:.4g}\".format(d+1,m.mean()) for d, m in enumerate(losses)])\n",
    "    snr = np.abs((losses[1].mean() - losses[0].mean()) / losses[0].mean())\n",
    "    plt.title(name+\": SNR={:.4g}, Overlap={:.4g}\".format(snr, oc))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = lossByDist(imaging_id,4,volume_loss,\"MSE\",512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = lossByDist(cnmf_id,4,volume_loss,\"MSE\",512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(volume_loss, loss=nn.PoissonNLLLoss(log_input=False,full=False,reduce=False))\n",
    "losses = lossByDist(imaging_id,4,loss_func,\"Poisson\",512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(volume_loss, loss=nn.PoissonNLLLoss(log_input=False,full=True,reduce=False))\n",
    "losses = lossByDist(imaging_id,4,loss_func,\"Poisson (Stirling)\",256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(volume_loss, loss=nn.L1Loss(reduce=False))\n",
    "losses = lossByDist(imaging_id,4,loss_func,\"L1\",256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(volume_loss, loss=nn.L1Loss(reduce=False))\n",
    "losses = lossByDist(cnmf_id,4,loss_func,\"L1\",256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(volume_loss, loss=nn.KLDivLoss(reduce=False))\n",
    "losses = lossByDist(imaging_id,4,loss_func,\"KL Div\",256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(volume_loss, loss=nn.KLDivLoss(reduce=False))\n",
    "losses = lossByDist(cnmf_id,4,loss_func,\"KL Div\",256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(volume_loss, loss=nn.SmoothL1Loss(reduce=False))\n",
    "losses = lossByDist(imaging_id,4,loss_func,\"Huber\",256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(volume_loss, loss=nn.SmoothL1Loss(reduce=False))\n",
    "losses = lossByDist(cnmf_id,4,loss_func,\"Huber\",256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = partial(volume_loss, loss=nn.SoftMarginLoss(reduce=False))\n",
    "losses = lossByDist(imaging_id,4,loss_func,\"SoftMarginLoss\",256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ssim = SSIM()\n",
    "loss_func = lambda x,y: 1-my_ssim(x,y).view(1)\n",
    "losses = lossByDist(imaging_id,4,loss_func,\"SSIM (dissimiliarity)\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ssim = SSIM()\n",
    "loss_func = lambda x,y: 1-my_ssim(x,y).view(1)\n",
    "losses = lossByDist(imaging_id,4,loss_func,\"SSIM (dissimiliarity)\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ssim = SSIM()\n",
    "loss_func = lambda x,y: 1-my_ssim(x,y).view(1)\n",
    "losses = lossByDist(cnmf_id,4,loss_func,\"SSIM (dissimiliarity)\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mssim = MSSSIM(channel=11)\n",
    "loss_func = lambda x,y: 1-my_mssim(x,y).view(1)\n",
    "losses = lossByDist(imaging_id,4,loss_func,\"MSSIM (dissimiliarity)\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mssim = MSSSIM(channel=11)\n",
    "loss_func = lambda x,y: 1-my_mssim(x,y).view(1)\n",
    "losses = lossByDist(cnmf_id,4,loss_func,\"MSSIM (dissimiliarity)\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
