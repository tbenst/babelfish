{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from torchvision.transforms import Resize\n",
    "import dill\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "import resource\n",
    "import apex # https://github.com/NVIDIA/apex.git\n",
    "from apex.amp import amp\n",
    "\n",
    "import os, sys, datetime\n",
    "import itertools\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = False\n",
    "# gen = True\n",
    "cuda=True\n",
    "half=True\n",
    "half=False\n",
    "multi_gpu = True\n",
    "num_workers = 16\n",
    "\n",
    "# if not gen:\n",
    "#     f = all_data['e'][2]\n",
    "\n",
    "# time_fish = T.from_numpy(f.frame_st.mean(1).astype(np.float32)).cuda()\n",
    "# u_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "# p_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "# u_fish[numpy.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_gpu_memory_map():\n",
    "    \"\"\"Get the current gpu usage.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    usage: dict\n",
    "        Keys are device ids as integers.\n",
    "        Values are memory usage as integers in MB.\n",
    "    \"\"\"\n",
    "    result = subprocess.check_output(\n",
    "        [\n",
    "            'nvidia-smi', '--query-gpu=memory.used',\n",
    "            '--format=csv,nounits,noheader'\n",
    "        ])\n",
    "    # Convert lines into a dictionary\n",
    "    gpu_memory = [int(x) for x in result.strip().split('\\n')]\n",
    "    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n",
    "    return gpu_memory_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_from_z(z, fish,half=False):\n",
    "    tiff = fish.get_tif_rasl(z)\n",
    "    ntime = fish.frame_et.shape[0]\n",
    "    if half:\n",
    "        dtype = np.float16\n",
    "    else:\n",
    "        dtype = np.float32\n",
    "    frames = np.zeros((ntime, tiff.frame_shape[0],tiff.frame_shape[1])).astype(dtype)\n",
    "    for t in range(ntime):\n",
    "        frame = np.array(tiff.get_frame(t)).astype(dtype)\n",
    "        frames[t] = frame\n",
    "    return frames\n",
    "\n",
    "def get_imaging_from_fish(f,n_jobs=8, half=False):\n",
    "    nZ = f.num_zplanes\n",
    "    if half:\n",
    "        dtype = np.float16\n",
    "    else:\n",
    "        dtype = np.float32\n",
    "    # frames_by_z = pool.map(partial(get_frames_from_z, fish=f), range(nZ))\n",
    "    frames_by_z = Parallel(n_jobs=n_jobs)(delayed(get_frames_from_z)(z,fish=f) for z in range(nZ))\n",
    "    imaging = np.stack(frames_by_z).swapaxes(0,1).astype(dtype)\n",
    "    return imaging\n",
    "\n",
    "def gen_imaging(nT, nZ, H, W, half=False):\n",
    "    if half:\n",
    "        dtype = np.float16\n",
    "    else:\n",
    "        dtype = np.float32\n",
    "    return np.random.randint(0,3000,[nT,nZ,H,W]).astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_volume(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    new[0] = im\n",
    "    for i, img in enumerate(images[1:]):\n",
    "        new[i] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new\n",
    "\n",
    "def resize_batch(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0,0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],images.shape[1], im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    for b, vol in enumerate(images):\n",
    "        for z, img in enumerate(vol):\n",
    "            new[b,z] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_volume(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    new[0] = im\n",
    "    for i, img in enumerate(images[1:]):\n",
    "        new[i] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new\n",
    "\n",
    "def resize_batch(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0,0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],images.shape[1], im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    for b, vol in enumerate(images):\n",
    "        for z, img in enumerate(vol):\n",
    "            new[b,z] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gen:\n",
    "    imaging = gen_imaging(32,11,232,512)\n",
    "else:\n",
    "#     imaging = get_imaging_from_fish(f)\n",
    "# imaging = resize_batch(imaging,0.5,0.5)\n",
    "# np.savez('/home/ubuntu/f01555.npz',fish=imaging)\n",
    "# np.savez('/home/ubuntu/f01555_small.npz',fish=imaging)\n",
    "#     imaging = np.load('/home/ubuntu/f01555.npz')['fish']\n",
    "    imaging = np.load('/home/ubuntu/f01555_small.npz')['fish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishImageData(Dataset):    \n",
    "    def __init__(self, imaging):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        self.data = T.from_numpy(data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data[idx+1]\n",
    "    \n",
    "class FishDiffData(Dataset):    \n",
    "    def __init__(self, imaging):\n",
    "        X = imaging - imaging.mean(0)\n",
    "        self.X = T.from_numpy(X)\n",
    "        self.Y = T.from_numpy(np.diff(X, axis=0))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "class FishMultData(Dataset):    \n",
    "    def __init__(self, imaging, prev_frames=2, next_frames=1):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        # use channel for future / prev frames\n",
    "        self.data = T.from_numpy(data)\n",
    "        self.prev_frames = prev_frames\n",
    "        self.next_frames = next_frames\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]-self.prev_frames - self.next_frames + 1\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = i + self.prev_frames - 1 # avoid wraparound\n",
    "        X = []\n",
    "        Y = []\n",
    "        for i in reversed(range(self.prev_frames)):\n",
    "            X.append(self.data[idx-i])\n",
    "        for i in range(1,self.next_frames+1):\n",
    "            Y.append(self.data[idx+i])\n",
    "        X = T.stack(X,1)\n",
    "        Y = T.stack(Y,1)\n",
    "        return X, Y\n",
    "\n",
    "# data = FishImageData(imaging)\n",
    "# data = FishDiffData(imaging)\n",
    "prev_frames = 2\n",
    "next_frames = 2\n",
    "data = FishMultData(imaging,prev_frames,next_frames)\n",
    "\n",
    "nZ, _, H, W = data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_schedule(t,k=5):\n",
    "    t0 = t/2\n",
    "    k = k/t0\n",
    "    t = np.arange(t)\n",
    "    return (1/(1+np.exp(-k*(t-t0)))).astype(np.float32)\n",
    "\n",
    "plt.plot(sigmoid_schedule(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, prev_frames=1):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(prev_frames, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "#         self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1) # for full-size images\n",
    "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, layers[3], stride=2)\n",
    "#         self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "#         self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 232 x 512\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "#         print(x.shape)\n",
    "        # 58 x 128\n",
    "\n",
    "        x = self.layer1(x)\n",
    "#         print(x.shape)\n",
    "        # 29 x 64\n",
    "        x = self.layer2(x)\n",
    "#         print(x.shape)\n",
    "        # 15 x 32\n",
    "        x = self.layer3(x)\n",
    "#         print(x.shape)\n",
    "        # 8 x 16\n",
    "        x = self.layer4(x)\n",
    "        # 4 x 8\n",
    "        x = x.view(x.shape[0],-1).mean(1)\n",
    "        # 1 x 1\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "        return x[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(padding_type, kernel_size):\n",
    "    assert padding_type in ['SAME', 'VALID']\n",
    "    if padding_type == 'SAME':\n",
    "        return tuple((k - 1) // 2 for k in kernel_size)\n",
    "    return tuple(0 for _ in kernel_size)\n",
    "\n",
    "\n",
    "class Vol2D(nn.Module):\n",
    "    \"Use same 2D operations mapped over each z slice\"\n",
    "    def __init__(self, tensor=T.cuda.FloatTensor):\n",
    "        super(Vol2D, self).__init__()\n",
    "        self.tensor = tensor\n",
    "        \n",
    "    def vol_PixelShuffle(self, x):\n",
    "        # Helper for subpixel convolution\n",
    "        first = self.pixel_shuffle(x[:,0])\n",
    "        # b x z x H x W\n",
    "        ret = self.tensor(x.shape[0],x.shape[1],first.shape[2], first.shape[3])\n",
    "        for z in range(x.shape[1]):\n",
    "            ret[:,z] = self.pixel_shuffle(x[:,z])[:,0]\n",
    "        return ret\n",
    "        \n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def vol_MaxPool2d(self, x, kernel_size):\n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def vol_BatchNorm2d(self, x, bn):\n",
    "        activations = self.tensor(x.shape)\n",
    "        for z in range(x.shape[1]):\n",
    "            activations[:,z] = bn(x[:,z].contiguous())\n",
    "        return activations\n",
    "                \n",
    "    def vol_conv2d(self, x, weight, pad):\n",
    "        # batch x Z x C x H x W\n",
    "        activations = self.tensor(x.shape[0],x.shape[1],weight.shape[0],x.shape[3],x.shape[4])\n",
    "        for z in range(x.shape[1]):\n",
    "            activations[:,z] = F.conv2d(x[:,z], weight, padding=pad)\n",
    "        return activations\n",
    "    \n",
    "    def crop(self, x):\n",
    "        cropH = (x.shape[2] - self.H)/2\n",
    "        cropW = (x.shape[3] - self.W)/2\n",
    "        if cropH>0:\n",
    "            x = x[:,:,int(np.floor(cropH)):-int(np.ceil(cropH))]\n",
    "        if cropW>0:\n",
    "            x = x[:,:,:,int(np.floor(cropW)):-int(np.ceil(cropW))]\n",
    "        return x\n",
    "\n",
    "class SuperResBlock(Vol2D):\n",
    "    \"\"\"Upsample Volume using subpixel convolution.\n",
    "    \n",
    "    Reference: https://arxiv.org/pdf/1609.05158.pdf\"\"\"\n",
    "    def __init__(self, upscale_factor, tensor):\n",
    "        super(SuperResBlock, self).__init__(tensor=T.cuda.FloatTensor)\n",
    "        self.tensor = tensor\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dconv1 = nn.Parameter(self.tensor(64,1,5,5))\n",
    "        self.dpad1 = (2,2)\n",
    "        self.dbn1 = nn.BatchNorm2d(64)\n",
    "        self.dconv2 = nn.Parameter(self.tensor(64,64,3,3))\n",
    "        self.dpad2 = (1,1)\n",
    "        self.dbn2 = nn.BatchNorm2d(64)\n",
    "        self.dconv3 = nn.Parameter(self.tensor(32,64,3,3))\n",
    "        self.dpad3 = (1,1)\n",
    "        self.dbn3 = nn.BatchNorm2d(32)\n",
    "        self.dconv4 = nn.Parameter(self.tensor(upscale_factor**2,32,3,3))\n",
    "        self.dpad4 = (1,1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv1, self.dpad1), self.dbn1))\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv2, self.dpad2), self.dbn2))\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv3, self.dpad3), self.dbn3))\n",
    "        x = self.vol_conv2d(x, self.dconv4, self.dpad4)\n",
    "        x = self.vol_PixelShuffle(x)\n",
    "        # add back single channel\n",
    "        x = x[:,:,None]\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        if self.tensor==T.cuda.FloatTensor:\n",
    "            nn.init.orthogonal_(self.dconv1, nn.init.calculate_gain('relu'))\n",
    "            nn.init.orthogonal_(self.dconv2, nn.init.calculate_gain('relu'))\n",
    "            nn.init.orthogonal_(self.dconv3, nn.init.calculate_gain('relu'))\n",
    "            nn.init.orthogonal_(self.dconv4)\n",
    "        else:\n",
    "            for m in [self.dconv1, self.dconv2, self.dconv3, self.dconv4]:\n",
    "                nn.init.kaiming_normal_(m, mode='fan_out', nonlinearity='relu')\n",
    "        for bn in [self.dbn1,self.dbn2,self.dbn3]:\n",
    "            nn.init.constant_(bn.weight, 1)\n",
    "            nn.init.constant_(bn.bias, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tofp16(nn.Module):\n",
    "    \"\"\"\n",
    "    Model wrapper that implements::\n",
    "        def forward(self, input):\n",
    "            return input.half()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(tofp16, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input.cuda().half()\n",
    "\n",
    "\n",
    "def BN_convert_float(module):\n",
    "    '''\n",
    "    Designed to work with network_to_half.\n",
    "    BatchNorm layers need parameters in single precision.\n",
    "    Find all layers and convert them back to float. This can't\n",
    "    be done with built in .apply as that function will apply\n",
    "    fn to all modules, parameters, and buffers. Thus we wouldn't\n",
    "    be able to guard the float conversion based on the module type.\n",
    "    '''\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.float()\n",
    "    for child in module.children():\n",
    "        BN_convert_float(child)\n",
    "    return module\n",
    "\n",
    "\n",
    "def network_to_half(network):\n",
    "    \"\"\"\n",
    "    Convert model to half precision in a batchnorm-safe way.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(tofp16(), BN_convert_float(network.half()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(Vol2D):\n",
    "    def __init__(self, nZ=11, H=232, W=512, nEmbedding=20, prev_frames=1,\n",
    "                 tensor=T.cuda.FloatTensor):\n",
    "        super(Conv, self).__init__(tensor)\n",
    "        self.tensor = tensor\n",
    "        self.nZ = nZ\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        self.lowH = 8\n",
    "        self.lowW = 16\n",
    "        self.lowFeatures = 1\n",
    "        self.prev_frames = prev_frames\n",
    "        # batch x channel x Z x H x W\n",
    "        # Encoding\n",
    "        self.resnet = ResNet(BasicBlock, [2, 2, 2, 2], 1)\n",
    "        self.resOut = 1\n",
    "        \n",
    "        # b x 11 x 32 x 11 x 25\n",
    "        self.encoding_mean = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        self.encoding_logvar = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        \n",
    "        # Prediction\n",
    "        self.pred1 = nn.Linear(nEmbedding*prev_frames, nEmbedding)\n",
    "        self.pred_bn1 = nn.BatchNorm1d(nEmbedding)\n",
    "        self.pred2 = nn.Linear(nEmbedding, nEmbedding)\n",
    "        \n",
    "        # Decoding\n",
    "        self.activation = nn.Tanh()\n",
    "        self.decoding = nn.Linear(nEmbedding,self.lowFeatures*nZ*self.lowH*self.lowW)\n",
    "        self.upconv1 = SuperResBlock(2,tensor)\n",
    "        # 11 x 16 x 32\n",
    "        self.upconv2 = SuperResBlock(2,tensor)\n",
    "        # 11 x 32 x 64\n",
    "        self.upconv3 = SuperResBlock(2,tensor)\n",
    "        # 11 x 64 x 128\n",
    "        self.upconv4 = SuperResBlock(2,tensor)\n",
    "        # 11 x 128 x 256\n",
    "#         self.upconv5 = SuperResBlock(2,tensor)\n",
    "        # 11 x 256 x 512\n",
    "        \n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        nn.init.xavier_normal_(self.encoding_mean.weight)\n",
    "        # TODO - make larger?\n",
    "        nn.init.xavier_normal_(self.encoding_logvar.weight,1e-3)\n",
    "    \n",
    "    def sample_embedding(self, mu, logvar):\n",
    "        if self.training:\n",
    "            # during training so far, had this implementation which lowers logvar (until Jul 7, 2018)\n",
    "#             std = torch.exp(0.1*logvar)\n",
    "#             dist = T.distributions.normal.Normal(T.zeros_like(std),T.ones_like(std))\n",
    "#             std_z = dist.sample()\n",
    "#             return mu + std*std_z\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def encode(self, x):\n",
    "        out = self.tensor(x.shape[0],x.shape[1],self.resOut)\n",
    "        for z in range(x.shape[1]):\n",
    "            out[:,z] = self.resnet(x[:,z])\n",
    "        mean = self.encoding_mean(out.reshape(x.shape[0],-1))\n",
    "        logvar = self.encoding_logvar(out.reshape(x.shape[0],-1))\n",
    "        return mean, logvar\n",
    "     \n",
    "    def predict(self, x):\n",
    "        x = self.activation(self.pred1(x))\n",
    "        x = self.pred2(x)\n",
    "        return x\n",
    "        \n",
    "    def decode(self, x):\n",
    "        # b x 20\n",
    "        x = self.activation(self.decoding(x))\n",
    "        x = x.reshape(x.shape[0],self.nZ,self.lowFeatures,self.lowH,self.lowW)\n",
    "        x = self.upconv1(x)\n",
    "        x = self.upconv2(x)\n",
    "        x = self.upconv3(x)\n",
    "        x = self.upconv4(x)\n",
    "#         x = self.upconv5(x)\n",
    "        x = self.crop(x[:,:,0])\n",
    "        # squeeze channel\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"Return Previous volume (denoised), next volume (prediction), latent mean and logvar.\"\n",
    "        latent_means = []\n",
    "        latent_logvars = []\n",
    "        encodings = []\n",
    "        for t in range(self.prev_frames):\n",
    "            mean, logvar = self.encode(x[:,:,[t]])\n",
    "            encoded = self.sample_embedding(mean, logvar)\n",
    "            latent_means.append(mean)\n",
    "            latent_logvars.append(logvar)\n",
    "            encodings.append(encoded)\n",
    "        \n",
    "        encoded_pred = self.predict(T.cat(encodings,1))\n",
    "        prev = self.decode(encodings[-1])\n",
    "        pred = self.decode(encoded_pred)\n",
    "        return prev, pred, T.cat(latent_means), T.cat(latent_logvars)\n",
    "\n",
    "    \n",
    "def unit_norm_KL_divergence(mu, logvar):\n",
    "    \"Reconstruction + KL divergence losses summed over all elements and batch.\"\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "\n",
    "def train(model,data,nepochs=10, lr=1e-3, half=False, cuda=True):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    kl_schedule = T.from_numpy(sigmoid_schedule(nepochs))\n",
    "    if half:\n",
    "        optimizer = apex.fp16_utils.FP16_Optimizer(T.optim.Adam(model.parameters(),lr=lr))\n",
    "    else:\n",
    "        optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "        \n",
    "    if cuda:\n",
    "        kl_schedule = kl_schedule.cuda()\n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        cum_X_loss = 0\n",
    "        cum_Y_loss = 0\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            X, Y = batch_data\n",
    "            # add 1 channel\n",
    "            if cuda:\n",
    "                # half will alrea\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "            X_pred, Y_pred, mean, logvar = model(X)\n",
    "            if half:\n",
    "                X_pred = X_pred.float()\n",
    "                Y_pred = Y_pred.float()\n",
    "                mean = mean.float()\n",
    "                logvar = logvar.float()\n",
    "            kld = unit_norm_KL_divergence(mean, logvar)\n",
    "            if np.random.rand()>0.5:\n",
    "                mse_X = F.mse_loss(X_pred, X[:,:,0], size_average=False)\n",
    "            else:\n",
    "                mse_X = F.mse_loss(X_pred, X[:,:,1], size_average=False)\n",
    "            if np.random.rand()>0.5:\n",
    "                mse_Y = F.mse_loss(Y_pred, Y[:,:,0], size_average=False)\n",
    "            else:\n",
    "                mse_Y = F.mse_loss(Y_pred, Y[:,:,1], size_average=False)\n",
    "            loss = mse_X + mse_Y + kl_schedule[e] * kld\n",
    "#             if e==0:\n",
    "#                 print(\"MSE_X: {:.3E}, MSE_Y: {:.3E}, KLD: {:.3E}\".format(float(mse_X),float(mse_Y),float(kld)))\n",
    "            optimizer.zero_grad()\n",
    "            if half:\n",
    "                optimizer.backward(loss)\n",
    "            else:\n",
    "                loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "            cum_X_loss += float(mse_X)\n",
    "            cum_Y_loss += float(mse_Y)\n",
    "\n",
    "        print(\"avg_loss: {:3E}, X_loss: {:3E}, Y_loss: {:3E}\".format(\n",
    "            cum_loss/len(data), cum_X_loss/len(data), cum_Y_loss/len(data)))        \n",
    "\n",
    "nEmbedding = 10\n",
    "batch_size = 64\n",
    "tensorlib = T\n",
    "if cuda:\n",
    "    tensorlib = T.cuda\n",
    "\n",
    "if half:\n",
    "    tensor = tensorlib.HalfTensor\n",
    "else:\n",
    "    tensor = tensorlib.FloatTensor\n",
    "\n",
    "conv_model = Conv(nZ,H,W,nEmbedding,prev_frames,tensor=tensor)\n",
    "if cuda:\n",
    "    conv_model.cuda()\n",
    "if half:\n",
    "    conv_model = apex.fp16_utils.network_to_half(conv_model)\n",
    "if multi_gpu:\n",
    "    conv_model = nn.DataParallel(conv_model)\n",
    "print(\"total num params:\", np.sum([np.prod(x.shape) for x in conv_model.parameters()]))\n",
    "# conv_model(data[0][0][None,:,None].cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(conv_model,data,100,lr=1e-3, half=half, cuda=cuda)\n",
    "# 1.91E+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"180712_small_X2_Y2_X:6.08E+08_Y:6.10E+08\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.save(conv_model.state_dict(),model_name+\".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv_model.load_state_dict(T.load(model_name+\".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_mse(X, Y):\n",
    "    with T.no_grad():\n",
    "        loss = F.mse_loss(X,Y,reduce=False).reshape(X.shape[0],-1).sum(1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleMSE(model,data, batch_size=96):\n",
    "    prev_frames = data.prev_frames\n",
    "    next_frames = data.next_frames\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    xlabels = ['X_t'] + ['X_t-{}'.format(i) for i in range(1,prev_frames)] + ['X_pred']\n",
    "    ylabels = ['Y_t+{}'.format(i) for i in range(1,next_frames+1)] + ['Y_pred']\n",
    "    labels = xlabels+ylabels\n",
    "    mses = {\"MSE({},{})\".format(x,y): [] for x,y in itertools.product(labels, labels)}\n",
    "    size = len(data)\n",
    "    with T.no_grad():\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            X, Y = batch_data\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            X_pred, Y_pred, _, _ = model(X)\n",
    "            xs = [X[:,:,i] for i in reversed(range(prev_frames))] + [X_pred]\n",
    "            ys = [Y[:,:,i] for i in range(next_frames)] + [Y_pred]\n",
    "            dat = xs+ys\n",
    "            iter = itertools.product(zip(labels,dat), zip(labels,dat))\n",
    "            for (xlabel, x), (ylabel, y) in iter:\n",
    "                mse = volume_mse(x,y)\n",
    "                mses[\"MSE({},{})\".format(xlabel,ylabel)].append(mse)\n",
    "    mses = {k: T.cat(v).cpu().numpy() for k,v in mses.items()}\n",
    "    return mses\n",
    "\n",
    "mses = sampleMSE(conv_model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argsort(mses['MSE(X_t,Y_t+1)'])[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Distribution of MSE for X_pred\")\n",
    "labels = ['MSE(X_pred,X_t-1)', 'MSE(X_pred,X_t)', 'MSE(X_pred,Y_t+1)', 'MSE(X_pred,Y_t+2)']\n",
    "vals = [mses[k][idx] for k in labels]\n",
    "plt.hist(np.stack(vals,1), 20)\n",
    "plt.legend([\"{}={:.4g}\".format(k,m.mean()) for k, m in zip(labels, vals)])\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "labels = ['MSE(Y_pred,X_t-1)', 'MSE(Y_pred,X_t)', 'MSE(Y_pred,Y_t+1)', 'MSE(Y_pred,Y_t+2)']\n",
    "vals = [mses[k][idx] for k in labels]\n",
    "plt.hist(np.stack(vals,1), 20)\n",
    "plt.legend([\"{}={:.4g}\".format(k,m.mean()) for k, m in zip(labels, vals)])\n",
    "plt.title(\"Distribution of MSE for Y_pred\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "labels = ['MSE(X_t-1,X_t)', 'MSE(X_t,Y_t+1)', 'MSE(Y_t+1,Y_t+2)',\n",
    "          'MSE(X_t-1,Y_t+1)', 'MSE(X_t,Y_t+2)',\n",
    "          'MSE(X_t-1,Y_t+2)']\n",
    "vals = [mses[k][idx] for k in labels]\n",
    "plt.hist(np.stack(vals,1), 20)\n",
    "plt.legend([\"{}={:.4g}\".format(k,m.mean()) for k, m in zip(labels, vals)])\n",
    "plt.title(\"Distribution of MSE for different timesteps\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "labels = ['MSE(X_pred,Y_pred)']\n",
    "vals = [mses[k][idx] for k in labels]\n",
    "plt.hist(np.stack(vals,1), 20)\n",
    "plt.legend([\"{}={:.4g}\".format(k,m.mean()) for k, m in zip(labels, vals)])\n",
    "plt.title(\"Distribution of MSE(X_pred,Y_pred)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.mannwhitneyu(mses['MSE(Y_pred,X_t)'][idx],\n",
    "                         mses['MSE(Y_pred,Y_t+2)'][idx],\n",
    "                        alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.mannwhitneyu(mses['MSE(Y_pred,X_t-1)'][idx],\n",
    "                         mses['MSE(Y_pred,Y_t+1)'][idx],\n",
    "                        alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_vs_real(model,data):\n",
    "    plt.figure(figsize=(30,15))\n",
    "\n",
    "    with T.no_grad():\n",
    "        for i in range(4):\n",
    "            time = np.random.randint(len(data))\n",
    "            z = np.random.randint(nZ)\n",
    "            X, Y = data[time]\n",
    "            x = X[None].cuda()\n",
    "            y = Y[None].cuda()\n",
    "            X_pred, Y_pred, _, _ = model(x)\n",
    "            mse_X = float(F.mse_loss(X_pred,x[:,:,0]).cpu())\n",
    "            mse_X_pred_to_Y = float(F.mse_loss(X_pred,y[:,:,0]).cpu())\n",
    "            mse_Y_pred_to_X = float(F.mse_loss(Y_pred,x[:,:,-1]).cpu())\n",
    "            mse_Y = float(F.mse_loss(Y_pred,y[:,:,-1]).cpu())\n",
    "            prev_loss = float(F.mse_loss(x[:,:,0],y[:,:,-1]).cpu())\n",
    "#             x_zero_loss = float(F.mse_loss(x,T.zeros_like(x)).cpu())\n",
    "#             y_zero_loss = float(F.mse_loss(y,T.zeros_like(y)).cpu())\n",
    "            mymin = min(float(y[0,z].min()[0]),float(x[0,z].min()[0]),float(X_pred[0,z].min()[0]))\n",
    "            mymax = max(float(y[0,z].max()[0]),float(x[0,z].max()[0]),float(X_pred[0,z].max()[0]))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+1)\n",
    "            plt.imshow(X[z,-1].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"Time=\"+str(time) + \", z=\"+str(z))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+2)\n",
    "            plt.imshow(Y[z,0].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"Time=\"+str(time+1) + \", z=\"+str(z))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+3)\n",
    "            plt.imshow(X_pred[0,z].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"MSE: (X_pred,X)={:.0f}, (X_pred,Y)={:.0f}\".format(mse_X,mse_X_pred_to_Y))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+4)\n",
    "            plt.imshow(Y_pred[0,z].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"MSE: (Y_pred,Y)={:.0f}, (Y_pred,X)={:.0f}\".format(mse_Y,mse_Y_pred_to_X))\n",
    "\n",
    "plot_model_vs_real(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_from_embedding(model,frame,embedding,niters=20, lr=1e-3):\n",
    "    model.eval()\n",
    "    frame = frame.cuda()\n",
    "    frame.requires_grad = True\n",
    "    embedding_pred, _ = model.encode(frame)\n",
    "    print(embedding_pred.shape)\n",
    "    embedding_pred.backward(gradient=embedding)\n",
    "    return frame.grad[0]\n",
    "\n",
    "def get_input_from_embedding(model,frame,embedding,niters=75, lr=1e-1, rand=False):\n",
    "    \"Take an embedding vector, and use backprop to find the volume\"\n",
    "    if rand:\n",
    "        prev_img = T.rand_like(frame[None], requires_grad=True).cuda()\n",
    "    else:\n",
    "        prev_img = frame[None].cuda()\n",
    "        prev_img.requires_grad = True\n",
    "    optimizer = T.optim.Adam([prev_img],lr=lr)\n",
    "    model.eval()\n",
    "    for i in range(niters):\n",
    "        embedding_pred, _ = model.encode(prev_img)\n",
    "        loss = F.mse_loss(embedding_pred,embedding[None]) #+ 1e-7*T.norm(prev_img,1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(\"iter {} loss: \".format(i), float(loss))\n",
    "    model.train()\n",
    "    return prev_img[0].detach().cpu().numpy()\n",
    "\n",
    "def interpret(model,prev_vol, next_vol, nEmbedding, prev_func):\n",
    "    \"Plot prev & next frame for each latent dimension\"\n",
    "    plt.figure(figsize=(10,20))\n",
    "    \n",
    "    embedding = T.from_numpy(np.zeros(nEmbedding).astype(np.float32)).cuda()[None]\n",
    "    with T.no_grad():\n",
    "        prev_img = model.decode(embedding)[0]\n",
    "        next_img = model.decode(model.predict(embedding))[0]\n",
    "    plt.subplot(1+nEmbedding,3,1)\n",
    "    plt.imshow(prev_img[6])\n",
    "    plt.title(\"Prev (Zero Vector)\")\n",
    "    plt.subplot(1+nEmbedding,3,2)\n",
    "    plt.imshow(next_img[6])\n",
    "    plt.title(\"Next (Zero Vector)\")\n",
    "    plt.subplot(1+nEmbedding,3,3)\n",
    "    plt.imshow(next_img[6] - prev_img[6])\n",
    "    plt.title(\"Diff (Zero Vector)\")\n",
    "    for i in range(nEmbedding):\n",
    "        embedding = T.from_numpy(np.eye(nEmbedding)[i].astype(np.float32)).cuda()[None]\n",
    "        with T.no_grad():\n",
    "            prev_img = model.decode(embedding)[0]\n",
    "            next_img = model.decode(model.predict(embedding))[0]\n",
    "        plt.subplot(1+nEmbedding,3,i*3+4)\n",
    "        plt.imshow(prev_img[6])\n",
    "        plt.title(\"Prev (Dim {})\".format(i))\n",
    "        plt.subplot(1+nEmbedding,3,i*3+5)\n",
    "        plt.imshow(next_img[6])\n",
    "        plt.title(\"Next (Dim {})\".format(i))\n",
    "        plt.subplot(1+nEmbedding,3,i*3+6)\n",
    "        plt.imshow(next_img[6]-prev_img[6])\n",
    "        plt.title(\"Diff (Dim {})\".format(i))\n",
    "    plt.tight_layout()\n",
    "\n",
    "x, y = data[1000]\n",
    "interpret(conv_model,x,y,10,get_gradient_from_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_over_time(model,data, batch_size=64):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    embeddings = []\n",
    "    logvars = []\n",
    "    model.eval()\n",
    "    for batch_data in dataloader:\n",
    "        X, _ = batch_data\n",
    "        with T.no_grad():\n",
    "            embedding, logvar = model.encode(X.cuda())\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "        logvars.append(logvar.cpu().numpy())\n",
    "    model.train()\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    logvars = np.vstack(logvars)\n",
    "    nEmbeddings = embeddings.shape[1]\n",
    "    half = int(np.ceil(nEmbeddings / 2))\n",
    "    \n",
    "    plt.figure(figsize=(15,20))\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(embeddings[:,0:half])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(embeddings[:,half:])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    \n",
    "    plt.subplot(4,1,3)\n",
    "    plt.plot(logvars[:,0:half])\n",
    "    plt.title(\"Logvars over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(logvars[:,half:])\n",
    "    plt.title(\"Logvars over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return embeddings\n",
    "embeddings = plot_embedding_over_time(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo.io\n",
    "def makePredVideo(model, data, batch_size=32):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    writer = skvideo.io.FFmpegWriter(model_name + \".mp4\",outputdict={\n",
    "        '-b': '30000000', '-vcodec': 'libx264'})\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        with T.no_grad():\n",
    "            _, vol_preds, _, _= model(X.cuda())\n",
    "        for actual,pred in zip(Y,vol_preds):\n",
    "            # 7th z layer\n",
    "            f = pred[6]\n",
    "            H = f.shape[0]\n",
    "            frame = np.zeros([H*2,f.shape[1]])\n",
    "            frame[:H] = actual[6,1]\n",
    "            frame[H:] = pred[6]\n",
    "            writer.writeFrame(frame)\n",
    "            \n",
    "    writer.close()\n",
    "    return frame, actual[6], pred[6]\n",
    "frame, actual, pred = makePredVideo(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishDistanceData(Dataset):\n",
    "    def __init__(self, imaging, distance):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        self.data = T.from_numpy(data)\n",
    "        self.distance=distance\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]-self.distance\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data[idx+self.distance]\n",
    "\n",
    "def MSEbyDist(imaging, maxdist=10, batch_size=256):\n",
    "    mse = []\n",
    "    \n",
    "    with T.no_grad():\n",
    "        for d in range(1,maxdist+1):\n",
    "            data = FishDistanceData(imaging,d)\n",
    "            dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "            mse.append([])\n",
    "            for batch_data in tqdm(dataloader):\n",
    "                X, Y = batch_data\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                mse[d-1].append(volume_mse(X, Y).cpu())\n",
    "\n",
    "    mse = [T.cat(m).numpy() for m in mse]\n",
    "    return mse\n",
    "\n",
    "mse = MSEbyDist(imaging,10)\n",
    "\n",
    "plt.hist(mse)\n",
    "plt.legend([\"MSE distance {}={:.4g}\".format(d+1,m.mean()) for d, m in enumerate(mse)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.mannwhitneyu(mse[0], mse[1], alternative='two-sided')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
