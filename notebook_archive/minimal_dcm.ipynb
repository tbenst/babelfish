{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "import os, sys, datetime\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "f = all_data['e'][2]\n",
    "\n",
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a,0)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    rm = ret[n - 1:] / n\n",
    "    pad_start = np.full((n-1,rm.shape[1]), rm[0])\n",
    "    return np.vstack([pad_start, rm])\n",
    "\n",
    "def ewma(data,span):\n",
    "    df = DataFrame(data)\n",
    "    return df.ewm(span).mean().values\n",
    "\n",
    "def df_f(x,ma_window=6,span=6):\n",
    "    u = moving_average(x,ma_window)\n",
    "    return ewma((x - u)/u, span)\n",
    "\n",
    "data = np.load(\"../cnmf_f01555.npz\")\n",
    "cnmf = data['cnmf'].astype(np.float32)\n",
    "raw = data['raw'].astype(np.float32)\n",
    "del data\n",
    "neurons = T.from_numpy(df_f(raw).astype(np.float32)).cuda()\n",
    "# neurons = T.from_numpy(cnmf).cuda()\n",
    "neurons_norm = (neurons - neurons.mean(0))/(neurons.std(0)+1e-8)\n",
    "neurons = neurons_norm\n",
    "\n",
    "def corrcoef(x):\n",
    "    # calculate covariance matrix of rows\n",
    "    mean_x = torch.mean(x, 1, keepdim=True)\n",
    "    xm = x.sub(mean_x.expand_as(x))\n",
    "    c = xm.mm(xm.t())\n",
    "    c = c / (x.size(1) - 1)\n",
    "\n",
    "    # normalize covariance matrix\n",
    "    d = torch.diag(c)\n",
    "    stddev = torch.pow(d, 0.5)\n",
    "    c = c.div(stddev.expand_as(c)+1e-8)\n",
    "    c = c.div(stddev.expand_as(c).t()+1e-8)\n",
    "\n",
    "    # clamp between -1 and 1\n",
    "    # probably not necessary but numpy does it\n",
    "    c = torch.clamp(c, -1.0, 1.0)\n",
    "\n",
    "    return c\n",
    "\n",
    "neuron_corr = corrcoef(neurons)\n",
    "\n",
    "neuron_linkage = hierarchy.linkage(\n",
    "    distance.pdist(neuron_corr), method='ward')\n",
    "\n",
    "neuron_linkage_clusters = hierarchy.fcluster(neuron_linkage,4,criterion='maxclust')\n",
    "# includes all neurons, even those without cluster\n",
    "cluster_by_neuron = np.zeros(neurons.shape[0]+1)\n",
    "for i,v in enumerate(neuron_linkage_clusters):\n",
    "    cluster_by_neuron[i] = v\n",
    "cluster_by_neuron = cluster_by_neuron[:-1]\n",
    "\n",
    "# nclust = int(cluster_by_neuron.max())\n",
    "# plt.subplots(nclust,1, figsize=[10,5*nclust])\n",
    "# for clust in range(1,nclust+1):\n",
    "#     #Select rois in raphe in this slices, and get their coordinates.\n",
    "#     poly_coords = df[(cluster_by_neuron==clust) & (df.z==z)].poly\n",
    "#     poly_coords = [np.round(poly[~np.isnan(poly).any(axis=1)])[:,(1,0)].astype(int) for poly in poly_coords]\n",
    "#     plt.subplot(nclust,1,clust)\n",
    "#     #Overlay the ROIs on the background image and display:\n",
    "#     img = vizutil.overlay_coords(back_img, poly_coords, [0,0,1], alpha=.5)\n",
    "#     plt.imshow(img,interpolation='nearest')\n",
    "#     plt.title(\"Cluster {}\".format(clust))\n",
    "\n",
    "dtype = np.float32\n",
    "# x_fish = F.normalize(neurons,0)\n",
    "x_fish = neurons\n",
    "time_fish = T.from_numpy(f.frame_st.mean(1).astype(dtype)).cuda()\n",
    "if dtype==np.float16:\n",
    "    u_fish = T.cuda.HalfTensor(time_fish.shape).zero_()\n",
    "    p_fish = T.cuda.HalfTensor(time_fish.shape).zero_()\n",
    "else:\n",
    "    u_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "    p_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "u_fish[numpy.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model = T.load(\"/home/ubuntu/DCM/granger_cnmf_bz=4_3xl1=1e-0&lr=1e-1_15xl1=5e-2&lr=1e-3.pth\")\n",
    "plt.imshow(g_model['G'][0],vmin=-0.1,vmax=0.1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishSeqData(Dataset):    \n",
    "    def __init__(self, u, p, x,n_future_steps=1):\n",
    "        self.x = nn.Parameter(x,requires_grad=False)\n",
    "        self.p = nn.Parameter(p,requires_grad=False)\n",
    "        self.u = nn.Parameter(u,requires_grad=False)\n",
    "        self.nfeatures = x.shape[1]\n",
    "        self.n_future_steps = n_future_steps\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)-self.n_future_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indices = slice(idx,idx+self.n_future_steps)\n",
    "        x_true_indices = slice(idx+1,idx+self.n_future_steps+1)\n",
    "        return (self.u[indices], self.p[indices],\n",
    "                self.x[indices], self.x[x_true_indices])\n",
    "    \n",
    "# def train(model,data,nepochs=10, lambdaA=(1e-8, 1e-6), lambdaB=(1e-6, 1e-6),\n",
    "#           lambdaC=(1e-5, 1e-5), lambdaD=(1e-5, 1e-5), lr=0.1, verbose=True):\n",
    "def train(model,data,nepochs=10, lambda1=1e-5,\n",
    "      lambda2=1e-5, lr=0.1, verbose=True, optimizer=None):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    if verbose:\n",
    "        A_loss = F.mse_loss(model.A.data,A_true)\n",
    "        print(\"A_loss: {}\".format(A_loss))\n",
    "    cum_mse_loss = 0\n",
    "    with T.no_grad():\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            U,P,X, X_true = batch_data\n",
    "            X_pred = model(U,P,X)\n",
    "            cum_mse_loss += F.mse_loss(X_pred.float(),X_true.float())\n",
    "        nfeatures = X_true.shape[2]\n",
    "        print(\"mse_loss: {:3E}\".format(cum_mse_loss/nfeatures))\n",
    "        if optimizer==None:\n",
    "            # optimizer = T.optim.SGD(model.parameters(),lr=lr)\n",
    "            optimizer = T.optim.Adam(model.parameters(),lr=lr,amsgrad=True)\n",
    "    \n",
    "    for e in range(nepochs):\n",
    "        if verbose:\n",
    "            print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        cum_mse_loss = 0\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            U,P,X, X_true = batch_data\n",
    "            X_pred = model(U,P,X)\n",
    "            reg = 0\n",
    "            for param in model.parameters():\n",
    "                reg += lambda1 * param.norm(1) + lambda2 * param.norm(2)\n",
    "#             l_A = lambdaA[0] * model.A.norm(1) + lambdaA[1] * model.A.norm(2)\n",
    "#             l_B = lambdaB[0] * model.B.norm(1) + lambdaB[1] * model.B.norm(2)\n",
    "#             l_C = lambdaC[0] * model.C.norm(1) + lambdaC[1] * model.C.norm(2)\n",
    "#             l_D1 = lambdaD[0] * model.Dense1.norm(1) + lambdaD[1] * model.Dense1.norm(2)\n",
    "#             l_D2 = lambdaD[0] * model.Dense2.norm(1) + lambdaD[1] * model.Dense2.norm(2)\n",
    "            mse_loss = F.mse_loss(X_pred,X_true)\n",
    "#             loss = mse_loss + l_A + l_B + l_C + l_D1 #+ l_D2\n",
    "            loss = mse_loss + reg\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "            cum_mse_loss += float(mse_loss)\n",
    "#             del X_pred, U,P,X, X_true, mse_loss, l_A, l_B, loss\n",
    "#             gc.collect()\n",
    "#             torch.cuda.empty_cache()\n",
    "\n",
    "        if verbose:\n",
    "            A_loss = F.mse_loss(model.A.data,A_true)\n",
    "            B_loss = F.mse_loss(model.B.data,B_true)\n",
    "            C_loss = F.mse_loss(model.C.data,C_true)\n",
    "            print(\"pred_loss: {}, A_loss: {}, B_loss: {}, C_loss: {}\".format(cum_loss,A_loss,B_loss,C_loss))\n",
    "        print(\"cum_loss: {:3E}, mse_loss: {:3E}\".format(cum_loss,cum_mse_loss/nfeatures))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"pred_loss: {}, A_loss: {}, B_loss: {}, C_loss: {}\".format(cum_loss,A_loss,B_loss,C_loss))\n",
    "\n",
    "        \n",
    "class DynamicsCluster(nn.Module,):\n",
    "    def __init__(self, nfeatures, neuron_cluster_map, n_future_steps,dtype=T.float32, scale=1,std=0.1):\n",
    "        \"\"\"DCM model with dynamics between nclusters = max(neuron_cluster_map) features and dense mapping from\n",
    "        nfeatures -> nclusters\"\"\"\n",
    "        super(DynamicsCluster, self).__init__()\n",
    "        if dtype==T.float32:\n",
    "            tensor = T.cuda.FloatTensor\n",
    "        elif dtype==T.float16:\n",
    "            tensor = T.cuda.HalfTensor\n",
    "        nclusters = int(max(neuron_cluster_map))\n",
    "        self.nclusters = nclusters\n",
    "        self.cluster = []\n",
    "        for i in range(nclusters):\n",
    "            idx = np.argwhere(neuron_cluster_map==i+1)[:,0]\n",
    "            self.cluster.append(idx)\n",
    "        self.Dense1 = nn.Parameter(tensor(nfeatures).normal_(std), requires_grad=True)\n",
    "        self.Dense2 = nn.Parameter(tensor(nfeatures).normal_(std), requires_grad=True)\n",
    "        self.A = nn.Parameter(tensor(nclusters,nclusters).normal_(std),requires_grad=True)\n",
    "        self.B = nn.Parameter(tensor(nclusters,nclusters).normal_(std),requires_grad=True)\n",
    "        self.C = nn.Parameter(tensor(nclusters).normal_(std),requires_grad=True)\n",
    "#         self.P = nn.Parameter(tensor(nfeatures).fill_(0.25),requires_grad=True)\n",
    "        self.n_future_steps = n_future_steps\n",
    "        self.tensor = tensor\n",
    "        self.scale = scale\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, u, p, x_true, n_future_steps=None):\n",
    "        if n_future_steps==None:\n",
    "            n_future_steps = self.n_future_steps\n",
    "        # batch x time x feature\n",
    "        x = self.tensor(x_true.shape[0], 1+x_true.shape[1], x_true.shape[2]).zero_()\n",
    "        x[:,0] = x_true[:,0]\n",
    "        for t in range(n_future_steps):\n",
    "            X = T.cuda.FloatTensor(x_true.shape[0],self.nclusters, 1).zero_()\n",
    "            for i in range(self.nclusters):\n",
    "                idx = self.cluster[i]\n",
    "                # broadcast inner product\n",
    "                X[:,i] = T.matmul(x_true[:,t,None,idx],self.Dense1[idx])\n",
    "            dxdt = (T.matmul((self.A + p[:,t,None,None]*self.B), X).squeeze()) + u[ :,t,None]*self.C\n",
    "            for i in range(self.nclusters):\n",
    "                idx = self.cluster[i]\n",
    "                x[:,t+1,idx] = dxdt[:,i,None]*self.Dense2[idx] + x[:,t,idx]\n",
    "#                 x[:,t+1,idx] = F.prelu(dxdt[:,i,None]*self.Dense2[idx] + x[:,t,idx], self.P[idx])\n",
    "        return x[:,1:]\n",
    "\n",
    "    def predict(self, u, p, x_init,x_true=None):\n",
    "        # if given x_true, use ground truth for each timestep\n",
    "        with T.no_grad():\n",
    "            x = T.cuda.FloatTensor(1+u.shape[0], x_init.shape[0]).zero_()\n",
    "            x[0] = x_init\n",
    "            n_future_steps = u.shape[0]\n",
    "            for t in range(n_future_steps):\n",
    "                if type(x_true)!=type(None):\n",
    "                    X = x_true\n",
    "                else:\n",
    "                    X = x\n",
    "                x[t+1] = self(u[None,[t]], p[None,[t]], X[None,[t]],1)\n",
    "        return x[1:]\n",
    "    \n",
    "ntrain = int(np.floor(len(x_fish)*0.8))\n",
    "\n",
    "n_future_steps = 16\n",
    "batch_size = 64\n",
    "\n",
    "data = FishSeqData(u_fish[:ntrain],p_fish[:ntrain],x_fish[:ntrain],n_future_steps)\n",
    "train_data = (u_fish[:ntrain],p_fish[:ntrain],x_fish[:ntrain])\n",
    "test_data = (u_fish[ntrain:],p_fish[ntrain:],x_fish[ntrain:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DynamicsCluster(data.nfeatures,cluster_by_neuron,n_future_steps)\n",
    "zeroModel = DynamicsCluster(data.nfeatures,cluster_by_neuron,n_future_steps)\n",
    "zeroModel.A.data.zero_()\n",
    "zeroModel.B.data.zero_()\n",
    "zeroModel.C.data.zero_()\n",
    "zeroModel.Dense1.data.zero_()\n",
    "# zeroModel.Dense2.data.zero_()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(zeroModel,data,0,1e-4,0, lr=1e-2,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,data,10,1e-6,1e-6, lr=1e-2,verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U,P,X = test_data\n",
    "# U,P,X = train_data\n",
    "X_pred = model.predict(U,P,X[0],X)\n",
    "dx_true = X[1:] - X[:-1]\n",
    "dx_pred = X_pred[:-1] - X[:-1]\n",
    "\n",
    "ncol, nrow = (5,3)\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(19,10))\n",
    "\n",
    "# ax.set_ylabel(\"dx/dt\")\n",
    "# ax.set_xlabel(\"Time\")\n",
    "# ax.set_title(\"Training data\")\n",
    "\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        n = np.random.randint(0,len(x_fish))\n",
    "        ax[i,j].plot(dx_pred[:,n].cpu().numpy(),color='red', alpha=0.6,linewidth=1, label=\"Model\")\n",
    "        ax[i,j].plot(dx_true[:,n].cpu().numpy(),color=\"gray\", linewidth=1, alpha=0.6,label=\"Truth\")\n",
    "        ax[i,j].set_title(\"Neuron {}\".format(n))\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamics Full rank A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicsSeq(nn.Module):\n",
    "    def __init__(self, nfeatures, n_future_steps,dtype=T.float32, scale=1,std=0.1):\n",
    "        super(DynamicsSeq, self).__init__()\n",
    "        if dtype==T.float32:\n",
    "            tensor = T.cuda.FloatTensor\n",
    "        elif dtype==T.float16:\n",
    "            tensor = T.cuda.HalfTensor\n",
    "                \n",
    "        self.A = nn.Parameter(tensor(nfeatures,nfeatures).normal_(std),requires_grad=True)\n",
    "        self.B = nn.Parameter(tensor(nfeatures,nfeatures).normal_(std),requires_grad=True)\n",
    "        self.C = nn.Parameter(tensor(nfeatures).normal_(std),requires_grad=True)\n",
    "        self.n_future_steps = n_future_steps\n",
    "        self.tensor = tensor\n",
    "        self.scale = scale\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, u, p, x_true, n_future_steps=None):\n",
    "        if n_future_steps==None:\n",
    "            n_future_steps = self.n_future_steps\n",
    "        x = self.tensor(x_true.shape[0], 1+x_true.shape[1], *x_true.shape[2:]).zero_()\n",
    "        x[:,0] = x_true[:,0]\n",
    "        for t in range(n_future_steps):\n",
    "            dxdt = (T.matmul((self.A + p[:,t,None,None]*self.B), x_true[:,t,:,None]).squeeze()) + u[ :,t,None]*self.C\n",
    "            x[:,t+1] = dxdt + x[:,t]\n",
    "#             x[:,t+1] = F.tanhshrink(dxdt) + x[:,t]\n",
    "        return x[:,1:]\n",
    "\n",
    "    def predict(self, u, p, x_init,x_true=None):\n",
    "        # if given x_true, use ground truth for each timestep\n",
    "        with T.no_grad():\n",
    "            x = T.cuda.FloatTensor(1+u.shape[0], x_init.shape[0]).zero_()\n",
    "            x[0] = x_init\n",
    "            n_future_steps = u.shape[0]\n",
    "            for t in range(n_future_steps):\n",
    "                if type(x_true)!=type(None):\n",
    "                    X = x_true\n",
    "                else:\n",
    "                    X = x\n",
    "                x[t+1] = self(u[None,[t]], p[None,[t]], X[None,[t]],1)\n",
    "        return x[1:]\n",
    "\n",
    "    \n",
    "n_future_steps = 1\n",
    "batch_size = 8\n",
    "\n",
    "data = FishSeqData(u_fish[:ntrain],p_fish[:ntrain],x_fish[:ntrain],n_future_steps)\n",
    "model = DynamicsSeq(data.nfeatures,n_future_steps, std=0.01)\n",
    "model.A.data = g_model[\"G\"]\n",
    "del g_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zeroModel = DynamicsSeq(data.nfeatures,n_future_steps)\n",
    "zeroModel.A.data.zero_()\n",
    "zeroModel.B.data.zero_()\n",
    "zeroModel.C.data.zero_()\n",
    "train(zeroModel,data,0,1e-6,1e-6, lr=1e-3,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,data,2,1e-3,1e-5, lr=1e-2,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U,P,X = test_data\n",
    "U,P,X = train_data\n",
    "X_pred = model.predict(U,P,X[0],X)\n",
    "dx_true = X[1:] - X[:-1]\n",
    "dx_pred = X_pred[:-1] - X[:-1]\n",
    "\n",
    "ncol, nrow = (2,4)\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(20,40))\n",
    "\n",
    "# ax.set_ylabel(\"dx/dt\")\n",
    "# ax.set_xlabel(\"Time\")\n",
    "# ax.set_title(\"Training data\")\n",
    "\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        n = np.random.randint(0,len(x_fish))\n",
    "#         ax[i,j].plot(dx_pred[:,n].cpu().numpy(),color='red', alpha=0.6,linewidth=1, label=\"Model\")\n",
    "#         ax[i,j].plot(dx_true[:,n].cpu().numpy(),color=\"gray\", linewidth=1, alpha=0.6,label=\"Truth\")\n",
    "        ax[i,j].plot(dx_true[:,n].cpu().numpy(),color=\"gray\", linewidth=4, alpha=0.7,label=\"Truth\")\n",
    "        ax[i,j].plot(dx_pred[:,n].cpu().numpy(),color='red', alpha=1,linewidth=0.8, label=\"Model\")\n",
    "        ax[i,j].set_title(\"Neuron {}\".format(n))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
