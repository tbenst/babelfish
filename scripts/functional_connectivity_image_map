#!/usr/bin/env bash
"exec" "$(which nix-shell)" "$(dirname ${BASH_SOURCE[0]})/../shell.nix" "--run" "python $0 $*"
# create output images for a functional connectivity map for each 
# chunk of pixels, say 5x5.
# %%
# %%
import click, h5py, os, datetime, mlflow, itertools, torch, gc, dill, cv2, sys
import requests, tifffile
import babelfish
import babelfish as bf, torch as T, numpy as np
import mlflow
from mlflow.tracking import MlflowClient
from torch.utils.data import DataLoader

import babelfish_models
import babelfish_models.models
import babelfish_models.volume
import babelfish_models.resnet
import babelfish_models.super_res
import babelfish_models.misc
babelfish.model = babelfish_models.models
sys.modules['babelfish'] = babelfish # temp compatability hack TODO remove
sys.modules['babelfish.model'] = babelfish.model # temp compatability hack TODO remove
babelfish.volume = babelfish_models.volume
sys.modules['babelfish.volume'] = babelfish.volume
babelfish.resnet = babelfish_models.resnet
sys.modules['babelfish.resnet'] = babelfish.resnet
babelfish.super_res = babelfish_models.super_res
sys.modules['babelfish.super_res'] = babelfish.super_res
babelfish.misc = babelfish_models.misc
sys.modules['babelfish.misc'] = babelfish.misc


# %%
# %%
# mlflow.pytorch.load_model(

# run_id = "4bf05f808c6a4e11817b5d3048c958fa"
@click.command()
@click.argument("run_id", type=str)
@click.option("--device_id", type=str)
@click.option("--seed", type=str, default=24)
@click.option("--batch-size", type=int, default=64)
@click.option("--artifact-path", type=str, default="/models")
@click.option("--experiment-name", type=str, default="babelfish")
def main(run_id, device_id, seed, batch_size, artifact_path, experiment_name):
    """Create avg 'receptive field' for each pixel
    
    Arguments:
        run_id {str} -- i.e. 'cuda:1'
    """    
    mlflow.set_experiment(experiment_name)
    T.manual_seed(seed)
    np.random.seed(seed)
    run =  MlflowClient().get_run(run_id)
    model = bf.helpers.load_model_from_run_info(run.info,
        artifact_path=artifact_path)
    params = run.data.params
    metrics = run.data.metrics
    tyh5_path = params["tyh5_path"]
    with h5py.File(tyh5_path, 'r', swmr=True) as tyh5:
        imaging = tyh5[params["dataset"]]
        nFrames, nZ, H, W = imaging.shape
        volume_shape = imaging[0].shape
        # TODO should coordinate this with mlflow--log train ids?
        tvt_split = bf.helpers.train_test_split(nFrames, nchunks=20)
        test_data = bf.data.ZebraFishData(imaging, {},
            tvt_split['test'], int(params["prev_frames"]),int(params["next_frames"]))

        dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)
        
        
        fname, ext = os.path.splitext(tyh5_path)
        fname, ext = os.path.splitext(fname)
        tif_path = fname+'_grad.btf'
        print("creating", tif_path)
        maxT = imaging[0:5000:10].max(0)
        # TODO why can't imagej open bigtiff?
        tifffile.imsave(fname+'_maxT.btf', maxT)
        with tifffile.TiffWriter(tif_path, bigtiff=False) as tif:
            for i in range(100,H,5):
                for j in range(50,W,10):
                    grad = T.zeros(volume_shape)
                    grad[:,i:i+5,j:j+5] = 1
                    avg_mask = bf.interpret.avg_backprop_gradient_mask(model, dataloader,
                        grad, progress=True)
                    avg_mask = avg_mask.max(0)[0].cpu().numpy() # maxTime projection
                    tif.save(avg_mask)
                if j > 150:
                    break 
        # TODO: log images artifacts in MLflow run
        # with mlflow.start_run(run_id=run_id, ):
        # TODO: also add jinja template & create HTML connectivity viz with
        # Multivac

    

if __name__ == '__main__':
    main()