{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import caiman as cm\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "sys.path.insert(0,os.path.expanduser(\"/data2/Code/zebrafish_passivity\"))\n",
    "sys.path.insert(0,os.path.expanduser(\"/data2/Code/zebrafish_passivity/deepfish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "# sys.path.insert(0,os.path.expanduser(\"deepfish\"))\n",
    "from deepfish.deep_skip import DeepSkip, train\n",
    "Model = DeepSkip\n",
    "\n",
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from torchvision.transforms import Resize\n",
    "import dill\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "import resource\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "# import apex # https://github.com/NVIDIA/apex.git\n",
    "# from apex.amp import amp\n",
    "\n",
    "\n",
    "import os, sys, datetime\n",
    "import itertools\n",
    "# LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "# FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "# FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "# sys.path.insert(0,LF_CODE_PATH)\n",
    "# sys.path.insert(0,FT_CODE_PATH)\n",
    "# sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "# import passivity_2p_imaging_utils as p2putils\n",
    "# reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "# all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "# sys.path.insert(0,\".\")\n",
    "from deepfish.helpers import get_frames_from_z, get_imaging_from_fish, gen_imaging, resize_volume, resize_batch, read_cnmf, no_overlap_idx, train_valid_test_split, train_test_split, pad_imaging\n",
    "\n",
    "from deepfish.stats import sampleMSE\n",
    "from deepfish.plot import interpret, plot_model_vs_real, makePredVideo, MSEbyDist\n",
    "\n",
    "from deepfish.data import ZebraFishData\n",
    "# from deepfish.deep_kSVD import Deep_KSVD, train\n",
    "from deepfish.half_precision import network_to_half\n",
    "\n",
    "T.backends.cudnn.benchmark = True\n",
    "\n",
    "# PARAMETERS\n",
    "gen = False\n",
    "# gen = True\n",
    "cuda=True\n",
    "# cnmf=True\n",
    "cnmf=False\n",
    "half=True\n",
    "half=False\n",
    "multi_gpu = True\n",
    "num_workers = 16\n",
    "prev_frames = 5\n",
    "next_frames = 5\n",
    "kl_lambda = 5e-4\n",
    "sparse_lambda=1e-3\n",
    "lr=1e-3\n",
    "nepochs = 11\n",
    "nEmbedding = 20\n",
    "# batch_size = 6\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZebraFishDataRNA(Dataset):\n",
    "    \"B x nFrames x Z x H x W\"\n",
    "    def __init__(self, imaging, structural, shocks, tail_movements,\n",
    "                 index_map=None, prev_frames=2, next_frames=1):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        # use channel for future / prev frames\n",
    "        self.data = T.from_numpy(data)\n",
    "        self.prev_frames = prev_frames\n",
    "        self.next_frames = next_frames\n",
    "        self.shocks = shocks\n",
    "        self.tail_movements = tail_movements\n",
    "        self.index_map = index_map\n",
    "        self.structural = structural\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.index_map:\n",
    "            return len(self.index_map)\n",
    "        else:\n",
    "            return self.data.shape[0]-self.prev_frames - self.next_frames + 1\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"X[0]==X_i, X[1]==X_i-1, Y[0]==Y_i+1, Y[1]==Y_i+2\"\n",
    "        if self.index_map:\n",
    "            idx = self.index_map[i]\n",
    "        else:\n",
    "            idx = i + self.prev_frames - 1 # avoid wraparound\n",
    "        X = {\"brain\": [], \"shock\": [], \"tail_movement\": []}\n",
    "        Y = {\"brain\": [], \"shock\": [], \"tail_movement\": []}\n",
    "        for i in reversed(range(self.prev_frames)):\n",
    "            ix = idx-i\n",
    "            X[\"brain\"].append(self.data[ix])\n",
    "            X[\"shock\"].append(self.shocks[ix])\n",
    "            X[\"tail_movement\"].append(self.tail_movements[ix])\n",
    "        for i in range(1,self.next_frames+1):\n",
    "            ix = idx+i\n",
    "            Y[\"brain\"].append(self.data[ix])\n",
    "            Y[\"shock\"].append(self.shocks[ix])\n",
    "            Y[\"tail_movement\"].append(self.tail_movements[ix])\n",
    "        for s in structural:\n",
    "            X[\"brain\"].append(s)\n",
    "        X = {k: T.stack(v,0) for k,v in X.items()}\n",
    "        Y = {k: T.stack(v,0) for k,v in Y.items()}\n",
    "        return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imread\n",
    "from glob import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/data2/Data/f10542/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_num = re.compile(\".*_zplane=(\\d*).npy\")\n",
    "get_z = lambda x: int(get_num.search(x).group(1))\n",
    "# planes = glob(directory+\"functional*.npy\")\n",
    "structural = glob(directory+\"cnmf/*.npy\")\n",
    "structural = list(filter(lambda x: get_num.match(x) is None, structural))\n",
    "# planes = sorted(planes, key=lambda a: get_z(a))\n",
    "# nZ = len(planes)\n",
    "# print(f\"Number of planes: {nZ}\")\n",
    "structural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging = np.load(directory+\"cnmf/functional.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isosbestic_gcamp = np.load(structural[1])\n",
    "postfix_gcamp = np.load(structural[3])\n",
    "postfix_gad = np.load(structural[4])\n",
    "postfix_vglut = np.load(structural[5])\n",
    "\n",
    "structural = T.from_numpy(np.stack([isosbestic_gcamp, postfix_gcamp, postfix_gad, postfix_vglut]))\n",
    "structural.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_frame = imaging.mean(0)\n",
    "\n",
    "nT, nZ, H, W = imaging.shape\n",
    "nT, nZ, H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shocks = T.from_numpy(np.zeros(nT).astype(np.float32))\n",
    "tail_movements = T.from_numpy(np.zeros(nT).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del imaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del imaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from volume import Vol2D\n",
    "from resnet import ResNet, BasicBlock\n",
    "from super_res import SuperResSkip\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from misc import sigmoid_schedule\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class DeepSkip(Vol2D):\n",
    "    def __init__(self, nZ=11, H=232, W=512, nEmbedding=20, prev_frames=1, next_frames=1,\n",
    "                 pred_hidden=20, tensor=T.cuda.FloatTensor):\n",
    "        super(DeepSkip, self).__init__(tensor)\n",
    "        self.tensor = tensor\n",
    "        self.nZ = nZ\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        self.lowH = 16\n",
    "        self.lowW = 16\n",
    "        self.lowFeatures = 1\n",
    "        self.prev_frames = prev_frames\n",
    "        # batch x channel x Z x H x W\n",
    "        # Encoding\n",
    "        self.resnet = ResNet(BasicBlock, [2, 2, 2, 2], prev_frames)\n",
    "        self.resOut = 64\n",
    "        self.nEmbedding = nEmbedding\n",
    "        assert nEmbedding % 2 == 0\n",
    "\n",
    "        # b x 11 x 32 x 11 x 25\n",
    "        self.encoding_mean = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        self.encoding_logvar = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        self.nhalf_embed = int(self.nEmbedding/2)\n",
    "        # Prediction\n",
    "        self.pred1 = nn.Linear(self.nhalf_embed+next_frames, pred_hidden) # add dim for shock_{t+1}\n",
    "        self.pred2 = nn.Linear(pred_hidden, self.nhalf_embed) # last 10 (context) are unused\n",
    "\n",
    "        # Prediction\n",
    "        self.predz1 = nn.Linear(self.nhalf_embed+next_frames, pred_hidden) # add dim for shock_{t+1}\n",
    "        self.predz2 = nn.Linear(pred_hidden, self.nhalf_embed) # last 10 (context) are unused\n",
    "\n",
    "        # Decoding\n",
    "        self.activation = nn.Tanh()\n",
    "        # only use 10 embeddings for frame decoding, the other 10 are context\n",
    "        self.decoding = nn.Linear(self.nhalf_embed,self.lowFeatures*nZ*self.lowH*self.lowW)\n",
    "        self.upconv1 = SuperResSkip(2,65,tensor)\n",
    "        # 11 x 16 x 32\n",
    "        self.upconv2 = SuperResSkip(2,65,tensor)\n",
    "        # 11 x 32 x 64\n",
    "        self.upconv3 = SuperResSkip(2,65,tensor)\n",
    "        # 11 x 64 x 128\n",
    "        self.upconv4 = SuperResSkip(2,65,tensor)\n",
    "        # 11 x 128 x 256\n",
    "#         self.upconv5 = SuperResSkip(2,tensor)\n",
    "        # 11 x 256 x 512\n",
    "\n",
    "        self.tail_decoding = nn.Linear(1,1)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        nn.init.xavier_normal_(self.encoding_mean.weight)\n",
    "        # TODO - make larger?\n",
    "        nn.init.xavier_normal_(self.encoding_logvar.weight,1e-3)\n",
    "\n",
    "    def sample_embedding(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = T.exp(0.5*logvar)\n",
    "            eps = T.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = x.transpose(1,2)\n",
    "        # X :: b x z x t x h x w\n",
    "        out = self.tensor(x.shape[0],x.shape[1],self.resOut)\n",
    "        layers = [\"conv1_out\", \"layer1_out\", \"layer2_out\", \"layer3_out\", \"layer4_out\"]\n",
    "        layer_outputs = {k: [] for k in layers}\n",
    "        for z in range(x.shape[1]):\n",
    "            out[:,z], layer_out = self.resnet(x[:,z])\n",
    "            for k in layers:\n",
    "#                 print(\"layer_out \"+k+\" shape: \"+ str(layer_out[k].shape))\n",
    "                layer_outputs[k].append(layer_out[k])\n",
    "        layer_outputs = {k: T.stack(v,1) for k,v in layer_outputs.items()}\n",
    "        mean = self.encoding_mean(out.reshape(x.shape[0],-1))\n",
    "        logvar = self.encoding_logvar(out.reshape(x.shape[0],-1))\n",
    "        return mean, logvar, layer_outputs\n",
    "\n",
    "    def predict(self, x, shock):\n",
    "        x = T.cat([x, shock],1)\n",
    "        x = self.activation(self.pred1(x))\n",
    "        x = self.pred2(x)\n",
    "        return x\n",
    "\n",
    "    def predictZero(self, x, shock):\n",
    "        x = T.cat([x, shock],1)\n",
    "        x = self.activation(self.predz1(x))\n",
    "        x = self.predz2(x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, layer_output):\n",
    "        tail = T.sigmoid(self.tail_decoding(x[:,[0]])) # use first embedding only\n",
    "#         tail = F.sigmoid(self.tail_decoding(x[:,[0]])) # use first embedding only\n",
    "        # b x 10\n",
    "        # only use first half for brain data\n",
    "        x = self.activation(self.decoding(x[:,:int(self.nEmbedding/2)]))\n",
    "        x = x.reshape(x.shape[0],self.nZ,self.lowFeatures,self.lowH,self.lowW)\n",
    "#         print(\"upconv1\", x.shape)\n",
    "        x = self.upconv1(x, layer_output[\"layer3_out\"])\n",
    "#         print(\"upconv2\", x.shape)\n",
    "        x = self.upconv2(x, layer_output[\"layer2_out\"])\n",
    "#         print(\"upconv3\", x.shape)\n",
    "        x = self.upconv3(x, layer_output[\"layer1_out\"])\n",
    "#         print(\"upconv4\", x.shape)\n",
    "        x = self.upconv4(x, layer_output[\"conv1_out\"])\n",
    "#         x = self.upconv5(x)\n",
    "        x = self.crop(x[:,:,0])\n",
    "        # squeeze channel\n",
    "        return x, tail\n",
    "\n",
    "    def forward(self, x, shock):\n",
    "        \"Return Previous volume (denoised), next volume (prediction), latent mean and logvar.\"\n",
    "        mean, logvar, layer_outputs = self.encode(x)\n",
    "        encoded = self.sample_embedding(mean, logvar)\n",
    "        encoded_prev = self.predictZero(encoded[:,self.nhalf_embed:], shock)\n",
    "        encoded_pred = self.predict(encoded[:,:self.nhalf_embed], shock)\n",
    "        prev = self.decode(encoded_prev, layer_outputs) # force to use only skip connections for decode\n",
    "        pred = self.decode(encoded_pred, layer_outputs)\n",
    "        return prev, pred, mean, logvar # should we move variational layer? or return encoded_pred?\n",
    "\n",
    "def unit_norm_KL_divergence(mu, logvar):\n",
    "    \"Reconstruction + KL divergence losses summed over all elements and batch.\"\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    return -0.5 * T.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "\n",
    "def train(model,train_data,valid_data, nepochs=10, lr=1e-3, kl_lambda=1, kl_tail=1e2, half=False, cuda=True, batch_size=16, num_workers=8):\n",
    "    dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    kl_schedule = T.from_numpy(sigmoid_schedule(nepochs))\n",
    "    if half:\n",
    "        optimizer = apex.fp16_utils.FP16_Optimizer(T.optim.Adam(model.parameters(),lr=lr))\n",
    "    else:\n",
    "        optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "    if cuda:\n",
    "        kl_schedule = kl_schedule.cuda()\n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        cum_X_loss = 0\n",
    "        cum_Y_loss = 0\n",
    "        cum_kld_loss = 0\n",
    "        cum_tail_loss = 0\n",
    "        i = 0\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            X, Y = batch_data\n",
    "            X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "            Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                X_shock = X_shock.cuda()\n",
    "                Y_shock = Y_shock.cuda()\n",
    "                X_tail = X_tail.cuda()\n",
    "                Y_tail = Y_tail.cuda()\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "            if half:\n",
    "                X_pred = X_pred.float()\n",
    "                Y_pred = Y_pred.float()\n",
    "                mean = mean.float()\n",
    "                logvar = logvar.float()\n",
    "            kld = unit_norm_KL_divergence(mean, logvar)\n",
    "            mse_X = F.mse_loss(X_pred, Y[:,0])\n",
    "            mse_Y = F.mse_loss(Y_pred, Y[:,-1])\n",
    "            mse_tail = F.mse_loss(Y_pred_tail, Y_tail[:,[-1]])\n",
    "            loss = mse_X + mse_Y + kl_lambda*kl_schedule[e] * kld + kl_tail*mse_tail\n",
    "            if e==0:\n",
    "                print(\"MSE_X: {:.3E}, MSE_Y: {:.3E}, KLD: {:.3E}, Tail: {:.3E}\".format(float(mse_X),float(mse_Y),float(kld),float(mse_tail)))\n",
    "            optimizer.zero_grad()\n",
    "            if half:\n",
    "                optimizer.backward(loss)\n",
    "            else:\n",
    "                loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "            cum_X_loss += float(mse_X)\n",
    "            cum_Y_loss += float(mse_Y)\n",
    "            cum_kld_loss += float(kld)\n",
    "            cum_tail_loss += float(mse_tail)\n",
    "\n",
    "        avg_Y_loss = cum_Y_loss/len(train_data)\n",
    "        avg_X_loss = cum_X_loss/len(train_data)\n",
    "        print(\"avg_loss: {:3E}, X_loss: {:3E}, Y_loss: {:3E}, KLD: {:3E}, tail_loss: {:3E}\".format(\n",
    "            cum_loss/len(train_data), avg_X_loss, avg_Y_loss, cum_kld_loss/len(train_data), cum_tail_loss/len(train_data)))\n",
    "#         cum_loss = 0\n",
    "#         cum_X_loss = 0\n",
    "#         cum_Y_loss = 0\n",
    "#         cum_kld_loss = 0\n",
    "#         cum_tail_loss = 0\n",
    "#         model.eval()\n",
    "#         gc.collect()\n",
    "#         for batch_data in valid_dataloader:\n",
    "#             X, Y = batch_data\n",
    "#             X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "#             Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "#             if cuda:\n",
    "#                 X = X.cuda()\n",
    "#                 Y = Y.cuda()\n",
    "#                 X_shock = X_shock.cuda()\n",
    "#                 Y_shock = Y_shock.cuda()\n",
    "#                 X_tail = X_tail.cuda()\n",
    "#                 Y_tail = Y_tail.cuda()\n",
    "#             (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "#             if half:\n",
    "#                 X_pred = X_pred.float()\n",
    "#                 Y_pred = Y_pred.float()\n",
    "#                 mean = mean.float()\n",
    "#                 logvar = logvar.float()\n",
    "#             kld = unit_norm_KL_divergence(mean, logvar)\n",
    "#             mse_X = F.mse_loss(X_pred, Y[:,0])\n",
    "#             mse_Y = F.mse_loss(Y_pred, Y[:,-1])\n",
    "#             mse_tail = F.mse_loss(X_pred_tail, X_tail[:,[-1]])\n",
    "#             loss = mse_X + mse_Y + kl_lambda*kl_schedule[e] * kld + kl_tail*mse_tail\n",
    "#             cum_loss += float(loss)\n",
    "#             cum_X_loss += float(mse_X)\n",
    "#             cum_Y_loss += float(mse_Y)\n",
    "#             cum_kld_loss += float(kld)\n",
    "#             cum_tail_loss += float(mse_tail)\n",
    "#         model.train()\n",
    "#         avg_Y_valid_loss = cum_Y_loss/len(valid_data)\n",
    "#         print(\"VALIDATION: avg_loss: {:3E}, X_loss: {:3E}, Y_loss: {:3E}, KLD: {:3E}, tail_loss: {:3E}\".format(\n",
    "#             cum_loss/len(valid_data), cum_X_loss/len(valid_data), avg_Y_valid_loss, cum_kld_loss/len(valid_data), cum_tail_loss/len(valid_data)))\n",
    "    return avg_X_loss, avg_Y_loss, avg_Y_valid_loss\n",
    "\n",
    "\n",
    "def validation_loss(model,valid_data, kl_lambda=1, kl_tail=1e2, half=False, cuda=True, batch_size=16, num_workers=8):\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    cum_loss = 0\n",
    "    cum_X_loss = 0\n",
    "    cum_Y_loss = 0\n",
    "    cum_kld_loss = 0\n",
    "    cum_tail_loss = 0\n",
    "    with T.no_grad():\n",
    "        model.eval()\n",
    "        for batch_data in tqdm(valid_dataloader):\n",
    "            X, Y = batch_data\n",
    "            X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "            Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                X_shock = X_shock.cuda()\n",
    "                Y_shock = Y_shock.cuda()\n",
    "                X_tail = X_tail.cuda()\n",
    "                Y_tail = Y_tail.cuda()\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "            if half:\n",
    "                X_pred = X_pred.float()\n",
    "                Y_pred = Y_pred.float()\n",
    "                mean = mean.float()\n",
    "                logvar = logvar.float()\n",
    "            kld = unit_norm_KL_divergence(mean, logvar)\n",
    "            mse_X = F.mse_loss(X_pred, Y[:,0])\n",
    "            mse_Y = F.mse_loss(Y_pred, Y[:,-1])\n",
    "            mse_tail = F.mse_loss(X_pred_tail, X_tail[:,[-1]])\n",
    "            loss = mse_X + mse_Y + kl_lambda * kld + kl_tail*mse_tail\n",
    "            cum_loss += float(loss)\n",
    "            cum_X_loss += float(mse_X)\n",
    "            cum_Y_loss += float(mse_Y)\n",
    "            cum_kld_loss += float(kld)\n",
    "            cum_tail_loss += float(mse_tail)\n",
    "    model.train()\n",
    "    avg_Y_valid_loss = cum_Y_loss/len(valid_data)\n",
    "    avg_X_valid_loss = cum_X_loss/len(valid_data)\n",
    "    print(\"VALIDATION: avg_loss: {:3E}, X_loss: {:3E}, Y_loss: {:3E}, KLD: {:3E}, tail_loss: {:3E}\".format(\n",
    "    cum_loss/len(valid_data), cum_X_loss/len(valid_data), avg_Y_valid_loss, cum_kld_loss/len(valid_data), cum_tail_loss/len(valid_data)))\n",
    "    return avg_X_valid_loss, avg_Y_valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "multi_gpu = True\n",
    "\n",
    "tensorlib = T\n",
    "if cuda:\n",
    "    tensorlib = T.cuda\n",
    "\n",
    "if half:\n",
    "    tensor = tensorlib.HalfTensor\n",
    "else:\n",
    "    tensor = tensorlib.FloatTensor\n",
    "\n",
    "# conv_model = DeepSkip(nZ,H,W,nEmbedding,prev_frames + len(structural),next_frames, tensor=tensor)\n",
    "conv_model = DeepSkip(nZ,H,W,nEmbedding,prev_frames,next_frames, tensor=tensor)\n",
    "if cuda:\n",
    "    conv_model.cuda()\n",
    "if half:\n",
    "    conv_model = apex.fp16_utils.network_to_half(conv_model)\n",
    "if multi_gpu:\n",
    "    conv_model = nn.DataParallel(conv_model)\n",
    "print(\"total num params:\", np.sum([np.prod(x.shape) for x in conv_model.parameters()]))\n",
    "# conv_model(data[0][0][None,:,None].cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.load_state_dict(T.load(\"/data2/trained_models/\"+\n",
    "#                                   \"190113_f15042_notail_gad_vglut_epoch=12_xloss={avg_X_loss:g}_yloss={avg_Y_loss:g}.pt\"))\n",
    "#     \"190112_f15042_notail_nostructure_epoch=12_xloss=1.11E+2_yloss=1.29E+2.pt\"))\n",
    "    \"190114_f15042_notail_nostructure_cnmf_folder_epoch=6_xloss=1.250E+02_yloss=1.447E+02.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caiman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cnmf results\n",
    "get_num = re.compile(\".*_zplane=(\\d*).*\")\n",
    "get_z = lambda x: int(get_num.search(x).group(1))\n",
    "planes = glob(directory + \"cnmf/*cnmf.npz\")\n",
    "planes = sorted(planes, key=lambda a: get_z(a))\n",
    "\n",
    "cnmf_results = []\n",
    "for file in planes:\n",
    "    cnmf_results.append(np.load(file))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cnmf results\n",
    "get_num = re.compile(\".*_zplane=(\\d*).*\")\n",
    "get_z = lambda x: int(get_num.search(x).group(1))\n",
    "vid_planes = glob(directory + \"cnmf/*.mmap\")\n",
    "vid_planes = sorted(vid_planes, key=lambda a: get_z(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct neuron x T matrix\n",
    "neurons = []\n",
    "\n",
    "for res in cnmf_results:\n",
    "    neurons.append(res['C'])\n",
    "\n",
    "def slice_neurons(neurons):\n",
    "    indices = []\n",
    "    start = 0\n",
    "    for n in neurons:\n",
    "        N = n.shape[0]\n",
    "        indices.append(slice(start, start+N))\n",
    "        start += N\n",
    "    return indices\n",
    "\n",
    "neuron_plane = slice_neurons(neurons)\n",
    "neurons = np.vstack(neurons)\n",
    "\n",
    "    \n",
    "\n",
    "# construct pixels x neuron matrix\n",
    "spatial = []\n",
    "\n",
    "# startNeuron = 0\n",
    "for res in cnmf_results:\n",
    "#     n_pixels, n_comps = res['A'].shape\n",
    "#     plane_spatial = np.zeros([n_pixels, nNeurons])\n",
    "#     plane_spatial[:,startNeuron:startNeuron+n_comps] = res['A']\n",
    "#     spatial.append(plane_spatial.copy())\n",
    "    spatial.append(res['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nNeurons, nT  = neurons.shape\n",
    "nNeurons, nT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames_ahead = 5\n",
    "X = []\n",
    "Y = []\n",
    "for idx in tvt_split['train']:\n",
    "    X.append(neurons[:,[idx]])\n",
    "    Y.append(neurons[:,[idx+n_frames_ahead]])\n",
    "X = np.hstack(X)\n",
    "Y = np.hstack(Y)\n",
    "\n",
    "X_valid = []\n",
    "Y_valid = []\n",
    "for idx in tvt_split['test']:\n",
    "    X_valid.append(neurons[:,[idx]])\n",
    "    Y_valid.append(neurons[:,[idx+n_frames_ahead]])\n",
    "X_valid = np.hstack(X_valid)\n",
    "Y_valid = np.hstack(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_lstsq = np.linalg.lstsq(np.transpose(X),np.transpose(Y))\n",
    "A = np.transpose(A_lstsq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = A @ X\n",
    "yloss = np.sum((Y - y_pred)**2)\n",
    "yloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = A @ X_valid\n",
    "y_valid_loss = np.sqrt(np.sum((Y_valid - y_valid_pred)**2))\n",
    "y_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A is spatial\n",
    "# C are components\n",
    "# f @ b is background\n",
    "list(cnmf_results[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane = np.array(cm.load(directory + \"cnmf/f10542_zplane=10_els__d1_352_d2_512_d3_1_order_F_frames_5437_.mmap\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H, W = plane[0].shape\n",
    "plane_spatial = res[\"A\"][:,]\n",
    "plane_spatial = np.transpose(spatial.reshape(W,H,-1))\n",
    "plane_spatial.shape\n",
    "all_spatial = plane_spatial.sum(0)\n",
    "plt.matshow(all_spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nT, H, W = plane.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corners = np.load(directory+\"corners.npy\")\n",
    "corners_cnmf = np.load(directory+\"cnmf/corners.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caiman_vec_to_2D(x):\n",
    "    return np.transpose(x.reshape(W,H))\n",
    "\n",
    "def caiman_loss(pred, spatial, frame, bg, mask):\n",
    "    \"\"\" Calculate loss for apples-to-apples comparison with deep-skip\n",
    "    pred: vector of ncomponents\n",
    "    spatial: npixels x ncomponents ['A']\n",
    "    frame: (T x) H x W\n",
    "    \"\"\"\n",
    "    pred_frame = spatial @ pred + bg\n",
    "    pred_frame = caiman_vec_to_2D(pred_frame)\n",
    "    # make same dimensions as deep-skip training\n",
    "    mask_dl_px = caiman_px_to_dl_px(mask, corners_cnmf)\n",
    "    frame_dl_px = caiman_px_to_dl_px(frame, corners_cnmf)\n",
    "    pred_frame_dl_px = caiman_px_to_dl_px(pred_frame, corners_cnmf)\n",
    "    return np.sqrt(np.sum((frame_dl_px*mask_dl_px-pred_frame_dl_px*mask_dl_px)**2))\n",
    "\n",
    "def deep_skip_predict(model, batch, mask, plane):\n",
    "    with T.no_grad():\n",
    "        model.eval()\n",
    "        X, Y = batch\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        X = X[None]\n",
    "        X_shock = X_shock[None]\n",
    "        X_tail = X_tail[None]\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        Y = Y[None]\n",
    "        Y_shock = Y_shock[None]\n",
    "        Y_tail = Y_tail[None]\n",
    "        if cuda:\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            X_shock = X_shock.cuda()\n",
    "            Y_shock = Y_shock.cuda()\n",
    "            X_tail = X_tail.cuda()\n",
    "            Y_tail = Y_tail.cuda()\n",
    "        (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "        if half:\n",
    "            X_pred = X_pred.float()\n",
    "            Y_pred = Y_pred.float()\n",
    "            mean = mean.float()\n",
    "            logvar = logvar.float()\n",
    "        tmask = T.from_numpy(mask).cuda()\n",
    "#         mse_Y = F.mse_loss(Y_pred[0,p]*tmask, Y[0,-1,p]*tmask, size_average=False)\n",
    "        mse_Y = T.sqrt(T.sum((Y_pred[0,plane]*tmask - Y[0,-1,plane]*tmask)**2))\n",
    "        model.train()\n",
    "        return mse_Y, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image, H, W):\n",
    "    try:\n",
    "        assert image.shape[0] <= H and image.shape[1] <= W\n",
    "    except Exception as e:\n",
    "        print(\"H ({}) and W ({}) must be less than {} and {}\".format(H, W, image.shape[0], image.shape[1]))\n",
    "        raise e\n",
    "    new_image = np.zeros([H,W])\n",
    "    if image.shape[0]==H:\n",
    "        pad_top = False\n",
    "    else:\n",
    "        pad_top = int(np.floor((H-image.shape[0])/2))\n",
    "        pad_bottom = int(np.ceil((H-image.shape[0])/2))\n",
    "    if image.shape[0]==W:\n",
    "        pad_left = False\n",
    "    else:\n",
    "        pad_left = int(np.floor((W-image.shape[1])/2))\n",
    "        pad_right = int(np.ceil((W-image.shape[1])/2))\n",
    "    if not pad_left and not pad_top:\n",
    "        return image\n",
    "    elif pad_right and not pad_bottom:\n",
    "        new_image[:,pad_left:(-pad_right)] = image\n",
    "    elif pad_bottom and not pad_right:\n",
    "        new_image[pad_top:(-pad_bottom),:] = image\n",
    "    else:\n",
    "        new_image[pad_top:(-pad_bottom),pad_left:(-pad_right)] = image\n",
    "    return new_image.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caiman_px_to_dl_px(image, corners):\n",
    "    \"\"\"Convert from Caiman image space, to DL image space\n",
    "    ie 0.5 downsample, crop, pad to 256 x 256 \n",
    "    \"\"\"\n",
    "    cropped = image[corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]]\n",
    "    resized = cv2.resize(cropped, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR)\n",
    "    padded = pad_image(resized, 256, 256)\n",
    "    return padded\n",
    "\n",
    "def load_vol(t):\n",
    "    vol = None\n",
    "    for z,p in enumerate(vid_planes):\n",
    "        plane = np.array(cm.load(p)[t])\n",
    "        if vol is None:\n",
    "            vol = np.zeros([len(planes), *plane.shape])\n",
    "        vol[z] = plane\n",
    "    return vol\n",
    "\n",
    "def proj_components(spatial, vol):\n",
    "    proj = []\n",
    "    for p,sp in enumerate(spatial):\n",
    "        plane_proj = np.linalg.lstsq(sp,vol[p].reshape(-1))[0]\n",
    "        proj.append(plane_proj)\n",
    "    return np.hstack(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane0_bg = caiman_vec_to_2D(\n",
    "    (cnmf_results[10][\"b\"] @ cnmf_results[10][\"f\"][:, tvt_split['train']]).mean(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 10\n",
    "t = 0\n",
    "plane_t = tvt_split['train'][t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = load_vol(plane_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = proj_components(spatial, vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = caiman_vec_to_2D(spatial[p].sum(1))\n",
    "batch = train_data[t]\n",
    "mse_Y, conv_Y_pred_train = deep_skip_predict(conv_model, batch, caiman_px_to_dl_px(mask, corners_cnmf), p)\n",
    "mse_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = A @ X[:,t]\n",
    "caiman_loss(est[neuron_plane[p]],spatial[p],plane[plane_t+5], plane0_bg.reshape(-1), mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "est = A @ proj\n",
    "caiman_loss(est[neuron_plane[p]],spatial[p],plane[plane_t+5], plane0_bg.reshape(-1), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(20,20))\n",
    "actual = caiman_px_to_dl_px(plane[plane_t], corners_cnmf)\n",
    "ax1 = ax[0].matshow(actual)\n",
    "clim=ax1.properties()['clim']\n",
    "ax[0].set_title(\"Actual\")\n",
    "CaImAn = caiman_px_to_dl_px(caiman_vec_to_2D(spatial[p] @ est[neuron_plane[p]])+ plane0_bg, corners_cnmf)\n",
    "ax[1].matshow(CaImAn, clim=clim)\n",
    "ax[1].set_title(\"CaImAn\")\n",
    "dl = (conv_Y_pred[0,p].cpu().numpy()+mean_frame[p])#*caiman_px_to_dl_px(mask)\n",
    "ax[2].matshow(dl, clim=clim)\n",
    "ax[2].set_title(\"Deep Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((actual-CaImAn)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((actual-dl)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 10\n",
    "t = 0\n",
    "plane_t = tvt_split['test'][t]\n",
    "batch = test_data[t]\n",
    "mask = caiman_vec_to_2D(spatial[p].sum(1))\n",
    "mse_Y, conv_Y_pred_test = deep_skip_predict(conv_model, batch, caiman_px_to_dl_px(mask, corners_cnmf), p)\n",
    "mse_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = load_vol(plane_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = proj_components(spatial, vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = A @ X_valid[:,t]\n",
    "caiman_loss(est[neuron_plane[p]],spatial[p],plane[plane_t+5], plane0_bg.reshape(-1), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = A @ proj\n",
    "caiman_loss(est[neuron_plane[p]],spatial[p],plane[plane_t+5], plane0_bg.reshape(-1), mask)\n",
    "# 832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(20,20))\n",
    "actual = caiman_px_to_dl_px(plane[plane_t], corners_cnmf)\n",
    "ax1 = ax[0].matshow(actual)\n",
    "clim=ax1.properties()['clim']\n",
    "ax[0].set_title(\"Actual\")\n",
    "CaImAn = caiman_px_to_dl_px(caiman_vec_to_2D(spatial[p] @ est[neuron_plane[p]])+ plane0_bg, corners_cnmf)\n",
    "ax[1].matshow(CaImAn, clim=clim)\n",
    "ax[1].set_title(\"CaImAn\")\n",
    "dl = (conv_Y_pred[0,p].cpu().numpy()+mean_frame[p])#*caiman_px_to_dl_px(mask)\n",
    "ax[2].matshow(dl, clim=clim)\n",
    "ax[2].set_title(\"Deep Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((actual-CaImAn)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((actual-dl)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dl_px = caiman_px_to_dl_px(mask, corners_cnmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=(20,20))\n",
    "actual = caiman_px_to_dl_px(plane[t], corners_cnmf)*mask_dl_px\n",
    "ax1 = ax[0].matshow(actual)\n",
    "clim=ax1.properties()['clim']\n",
    "ax[0].set_title(\"Actual\")\n",
    "CaImAn = caiman_px_to_dl_px((caiman_vec_to_2D(spatial[p] @ est[neuron_plane[p]])+ plane0_bg), corners_cnmf)*mask_dl_px\n",
    "ax[1].matshow(CaImAn, clim=clim)\n",
    "ax[1].set_title(\"CaImAn\")\n",
    "dl = (conv_Y_pred[0,p].cpu().numpy()+mean_frame[p])*mask_dl_px\n",
    "ax[2].matshow(dl, clim=clim)\n",
    "ax[2].set_title(\"Deep Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((actual-CaImAn)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((actual-dl)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caiman_loss_volume(pred, spatial, frame, bg, mask):\n",
    "    \"\"\" Calculate loss for apples-to-apples comparison with deep-skip\n",
    "    pred: vector of ncomponents\n",
    "    spatial: npixels x ncomponents ['A']\n",
    "    frame: (T x) H x W\n",
    "    \"\"\"\n",
    "    pred_frame = spatial @ pred + bg\n",
    "    pred_frame = caiman_vec_to_2D(pred_frame)\n",
    "    # make same dimensions as deep-skip training\n",
    "    mask_dl_px = caiman_px_to_dl_px(mask, corners_cnmf)\n",
    "    frame_dl_px = caiman_px_to_dl_px(frame, corners_cnmf)\n",
    "    pred_frame_dl_px = caiman_px_to_dl_px(pred_frame, corners_cnmf)\n",
    "    return np.sqrt(np.sum((frame_dl_px*mask_dl_px-pred_frame_dl_px*mask_dl_px)**2))\n",
    "\n",
    "def deep_skip_predict_volume(model, t, mask, plane):\n",
    "    with T.no_grad():\n",
    "        model.eval()\n",
    "        X, Y = test_data[t]\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        X = X[None]\n",
    "        X_shock = X_shock[None]\n",
    "        X_tail = X_tail[None]\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        Y = Y[None]\n",
    "        Y_shock = Y_shock[None]\n",
    "        Y_tail = Y_tail[None]\n",
    "        if cuda:\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            X_shock = X_shock.cuda()\n",
    "            Y_shock = Y_shock.cuda()\n",
    "            X_tail = X_tail.cuda()\n",
    "            Y_tail = Y_tail.cuda()\n",
    "        (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "        if half:\n",
    "            X_pred = X_pred.float()\n",
    "            Y_pred = Y_pred.float()\n",
    "            mean = mean.float()\n",
    "            logvar = logvar.float()\n",
    "        tmask = T.from_numpy(mask).cuda()\n",
    "#         mse_Y = F.mse_loss(Y_pred[0,p]*tmask, Y[0,-1,p]*tmask, size_average=False)\n",
    "        mse_Y = T.sqrt(T.sum((Y_pred[0,p]*tmask - Y[0,-1,p]*tmask)**2))\n",
    "        model.train()\n",
    "        return mse_Y, Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_model\n",
    "t = 0\n",
    "with T.no_grad():\n",
    "    model.eval()\n",
    "    X, Y = test_data[t]\n",
    "    X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "    X = X[None]\n",
    "    X_shock = X_shock[None]\n",
    "    X_tail = X_tail[None]\n",
    "    Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "    Y = Y[None]\n",
    "    Y_shock = Y_shock[None]\n",
    "    Y_tail = Y_tail[None]\n",
    "    if cuda:\n",
    "        X = X.cuda()\n",
    "        Y = Y.cuda()\n",
    "        X_shock = X_shock.cuda()\n",
    "        Y_shock = Y_shock.cuda()\n",
    "        X_tail = X_tail.cuda()\n",
    "        Y_tail = Y_tail.cuda()\n",
    "    (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "    if half:\n",
    "        X_pred = X_pred.float()\n",
    "        Y_pred = Y_pred.float()\n",
    "        mean = mean.float()\n",
    "        logvar = logvar.float()\n",
    "    mse_Y = F.mse_loss(Y_pred, Y[:,-1],size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y[0,4,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y_pred[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['A'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_plane[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_num = 3000\n",
    "p = 10\n",
    "signal = cnmf_results[p]['A'] @ cnmf_results[p]['C'][:,frame_num]\n",
    "bg =  cnmf_results[p]['b'] @ cnmf_results[p]['f'][:,frame_num]\n",
    "denoised = signal + bg\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(30,10))\n",
    "ax[0].matshow(plane[frame_num])\n",
    "ax[0].set_title(\"Actual plane\")\n",
    "ax[2].matshow(caiman_vec_to_2D(signal))\n",
    "ax[2].set_title(\"Signal (AC)\")\n",
    "ax[3].matshow(caiman_vec_to_2D(bg))\n",
    "ax[3].set_title(\"Background (bf)\")\n",
    "ax[1].matshow(caiman_vec_to_2D(denoised))\n",
    "ax[1].set_title(\"Denoised (AC+bf)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
