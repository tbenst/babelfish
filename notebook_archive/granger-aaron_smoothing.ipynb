{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "import visualization_utils as vizutil\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "f = all_data['e'][2]\n",
    "\n",
    "data = np.load(\"../cnmf_f01555.npz\")\n",
    "cnmf = data['cnmf'].astype(np.float32)\n",
    "raw = data['raw'].astype(np.float32)\n",
    "del data\n",
    "# cnmf_t = T.from_numpy(raw).cuda()\n",
    "neurons = raw\n",
    "# threshold = np.sort(neurons.std(0))[-5001] # delete me\n",
    "\n",
    "neuron_ids = np.sort(np.argsort(neurons.std(0))[-5000:])\n",
    "neurons = neurons[:,neuron_ids]\n",
    "\n",
    "# df, sig = f.get_cnmf_roi_table_and_signals()\n",
    "df = f.get_roi_table()\n",
    "df = df.iloc[neuron_ids]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "ortho_regions = [u'in_l_cerebellum', u'in_r_cerebellum', \n",
    "    u'in_l_vthal', u'in_r_vthal', u'in_l_tectum', u'in_r_tectum', \n",
    "    u'in_l_raphe', u'in_r_raphe', u'in_l_hind', u'in_r_hind', \n",
    "    u'in_l_dthal', u'in_r_dthal', u'in_l_LHb', u'in_r_LHb', \n",
    "    u'in_l_tel', u'in_r_tel', u'in_l_MHb',  u'in_r_MHb']\n",
    "\n",
    "regions = []\n",
    "for r in ortho_regions:\n",
    "    if r in df.columns:\n",
    "        regions.append(r)\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    # a is a signal\n",
    "    ret = np.cumsum(a,0) # sum over time\n",
    "    ret[n:] = ret[n:] - ret[:-n] # diff of n samples back\n",
    "    rm = ret[n - 1:] / n\n",
    "    pad_start = np.full((n-1,rm.shape[1]), rm[0])\n",
    "    return np.vstack([pad_start, rm])\n",
    "\n",
    "def ewma(data,span):\n",
    "    \"exponential weighted moving average.\"\n",
    "    df = DataFrame(data)\n",
    "    return df.ewm(span).mean().values\n",
    "\n",
    "def df_f(x,ma_window=6,span=6):\n",
    "    u = moving_average(x,ma_window)\n",
    "    return ewma((x - u)/u, span)\n",
    "\n",
    "neurons = T.from_numpy(df_f(neurons,1000,6).astype(np.float32)).cuda()\n",
    "# neurons = T.from_numpy(df_f(neurons).astype(np.float32)).cuda()\n",
    "neurons_norm = (neurons - neurons.mean(0))/(neurons.std(0)+1e-8)\n",
    "neurons = neurons_norm\n",
    "print(neurons.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[np.where([c in ortho_regions for c in df.columns])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(raw[:500,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(raw[:,[30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 120\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(df_f(raw[:,[i]],2000,3))\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(df_f(raw[:,[i]],1000,6))\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(df_f(raw[:,[i]],100,6))\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(df_f(raw[:,[i]],6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrcoef(x):\n",
    "    \"cross-correlation with pytorch\"\n",
    "    # calculate covariance matrix of rows\n",
    "    mean_x = torch.mean(x, 1, keepdim=True)\n",
    "    xm = x.sub(mean_x.expand_as(x))\n",
    "    c = xm.mm(xm.t())\n",
    "    c = c / (x.size(1) - 1)\n",
    "\n",
    "    # normalize covariance matrix\n",
    "    d = torch.diag(c)\n",
    "    stddev = torch.pow(d, 0.5)\n",
    "    c = c.div(stddev.expand_as(c)+1e-8)\n",
    "    c = c.div(stddev.expand_as(c).t()+1e-8)\n",
    "\n",
    "    # clamp between -1 and 1\n",
    "    # probably not necessary but numpy does it\n",
    "    c = torch.clamp(c, -1.0, 1.0)\n",
    "\n",
    "    return c\n",
    "\n",
    "# cluster on cross-correlation\n",
    "\n",
    "neuron_corr = corrcoef(neurons.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_nclust = 5\n",
    "neuron_linkage = hierarchy.linkage(\n",
    "    distance.pdist(neuron_corr), method='ward')\n",
    "neuron_linkage_clusters = hierarchy.fcluster(neuron_linkage,neuron_nclust,criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = np.float32\n",
    "# x_fish = F.normalize(neurons,0)\n",
    "x_fish = neurons\n",
    "time_fish = T.from_numpy(f.frame_st.mean(1).astype(dtype)).cuda()\n",
    "if dtype==np.float16:\n",
    "    u_fish = T.cuda.HalfTensor(time_fish.shape).zero_()\n",
    "    p_fish = T.cuda.HalfTensor(time_fish.shape).zero_()\n",
    "else:\n",
    "    u_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "    p_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "u_fish[numpy.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c, coph_dists = hierarchy.cophenet(neuron_linkage, distance.pdist(neurons))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Granger(nn.Module):\n",
    "    def __init__(self, nfeatures, n_past_steps, std=0.1, dtype=T.float32,bias=True):\n",
    "        # we will perform nfeatures x nfeatures regressions\n",
    "        super(Granger, self).__init__()\n",
    "        if dtype==T.float32:\n",
    "            tensor = T.cuda.FloatTensor\n",
    "        elif dtype==T.float16:\n",
    "            tensor = T.cuda.HalfTensor\n",
    "        # Granger coefficient\n",
    "        self.G = nn.Parameter(tensor(n_past_steps,nfeatures,nfeatures).normal_(std),\n",
    "                              requires_grad=True)\n",
    "        self.auto = nn.Parameter(tensor(n_past_steps,nfeatures,nfeatures).normal_(std),\n",
    "                              requires_grad=True)\n",
    "        self.bias = bias\n",
    "        # Bias matrix\n",
    "        if self.bias:\n",
    "            self.B = nn.Parameter(tensor(nfeatures, nfeatures).normal_(std),requires_grad=True)\n",
    "\n",
    "        self.n_past_steps = n_past_steps\n",
    "        self.tensor = tensor\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, x_true, n_past_steps=None):\n",
    "        if n_past_steps==None:\n",
    "            n_past_steps = self.n_past_steps\n",
    "        # nfeatures is n neurons & n_past_steps is lag\n",
    "        # adding dim to make broadcast work\n",
    "        # x_true is batch x lag x nfeatures x         1\n",
    "        # G is          1 x lag x nfeatures x nfeatures\n",
    "        y = self.G[None] * x_true[:,:,:,None]+ self.auto[None] * x_true[:,:,None,:]\n",
    "        # sum lag so y is batch x nfeatures x nfeatures\n",
    "        if self.bias:\n",
    "            return y.sum(1) + self.B[None]\n",
    "        else:\n",
    "            return y.sum(1)\n",
    "\n",
    "def train(model,data,nepochs=1, l1p=1e-8, l2=0, lr=1e-3,batch_size=16, verbose=True):\n",
    "    # l1 per parameter\n",
    "    l1 = l1p / np.prod(T.tensor(model.G.shape).numpy())\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    if verbose:\n",
    "        epochs = range(nepochs)\n",
    "    else:\n",
    "        loader = dataloader\n",
    "        epochs = tqdm(range(nepochs))\n",
    "    for epoch in epochs:\n",
    "        if verbose:\n",
    "            loader = tqdm(dataloader)\n",
    "        for X,Y in loader:\n",
    "            Y_pred = model.forward(X)\n",
    "            l = 0\n",
    "#             for param in model.parameters():\n",
    "#                 l += l1* param.norm(1) + l2 *param.norm(2)\n",
    "            if model.bias:\n",
    "                l = l1*model.G.norm(1) + l1*model.B.norm(1)\n",
    "            else:\n",
    "                l = l1*model.G.norm(1)\n",
    "            loss = F.mse_loss(Y[:,None,:], Y_pred) + l\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()# back props\n",
    "            optimizer.step()# update the parameters\n",
    "        if verbose:\n",
    "            print('epoch {}, loss {}'.format(epoch,loss.data))\n",
    "\n",
    "# nfeatures = 100\n",
    "# r = np.array([2,3,5,7,11])\n",
    "# i = 10\n",
    "# j = 13\n",
    "# model = Granger(nfeatures,1)\n",
    "# model.G.data.zero_()\n",
    "# model.G.data[0,i,j] = r[0]\n",
    "# model.auto.data.zero_()\n",
    "# model.auto.data[0,i,j] = r[1]\n",
    "# model.B.data.zero_()\n",
    "# model.B.data[i,j] = r[2]\n",
    "# xt = T.cuda.FloatTensor(1,nfeatures).zero_()\n",
    "# xt[0,i] = r[3]\n",
    "# xt[0,j] = r[4]\n",
    "\n",
    "# r_true = 2*7+3*11+5\n",
    "# try:\n",
    "#     assert model(xt[None,[0]])[0,i,j] == r_true\n",
    "# except:\n",
    "#     print(model(xt[None,[0]])[0,i,j], r_true)\n",
    "#     raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Granger(x_fish.shape[1],1,bias=False)\n",
    "# trunc_fish = x_fish[0:400]\n",
    "# trunc_fish = x_fish[440:840]\n",
    "# trunc_fish = x_fish[840:1240]\n",
    "# trunc_fish = x_fish[1240:1640]\n",
    "# trunc_fish = x_fish[1640:2040]\n",
    "trunc_fish = x_fish[1640:2440]\n",
    "# trunc_fish = x_fish[640:840]\n",
    "# trunc_fish = x_fish[2400:2800]\n",
    "# trunc_fish = x_fish[2600:2800]\n",
    "# trunc_fish = x_fish\n",
    "X = trunc_fish[:-1,None]\n",
    "Y = trunc_fish[1:,None]\n",
    "data = T.utils.data.TensorDataset(X,Y)\n",
    "l1 = 5e-6\n",
    "# train(model,data,10,l1=l1,batch_size=4) # max(bz)==4 for all neurons\n",
    "train(model,data,3,l1p=1e-0,lr=1e-1,batch_size=1,verbose=False)\n",
    "train(model,data,15,l1p=5e-2,lr=1e-3,batch_size=1,verbose=False)\n",
    "G = model.G.data[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.auto[0,:100,:100].data.detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T.save(model.state_dict(), \"granger_15k_raw_all_time.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering Granger\n",
    "\n",
    "g_linkage = hierarchy.linkage(\n",
    "    distance.pdist(G), method='ward')\n",
    "\n",
    "g_nclust = 5\n",
    "g_clusters = hierarchy.fcluster(g_linkage,g_nclust,criterion='maxclust')\n",
    "# see question for code prior to \"color mapping\"\n",
    "cm_cycle = plt.get_cmap(\"tab10\")\n",
    "g_cmap = [cm_cycle(i) for i in range(g_nclust)]\n",
    "neuron_cmap = [cm_cycle(i) for i in range(g_nclust,g_nclust+neuron_nclust)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_linkage_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_linkage = g_linkage.copy()\n",
    "\n",
    "all_clusters = hierarchy.fcluster(g_linkage,g_nclust,criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resting_linkage = g_linkage.copy()\n",
    "\n",
    "resting_clusters = hierarchy.fcluster(g_linkage,g_nclust,criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passivity_linkage = g_linkage.copy()\n",
    "\n",
    "passivity_clusters = hierarchy.fcluster(g_linkage,g_nclust,criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_passivity_linkage = g_linkage.copy()\n",
    "\n",
    "long_passivity_clusters = hierarchy.fcluster(g_linkage,g_nclust,criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho_region_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df.region).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_linkage_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neuron_region_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_cmap = sns.color_palette(\"Paired\",12)\n",
    "# region_map = {r: i for i,r in enumerate(regions)}\n",
    "neuron_region_cmap = []\n",
    "for r in df.region_id:\n",
    "    if r==-1:\n",
    "        neuron_region_cmap.append((0.5,0.5,0.5))\n",
    "    else:\n",
    "        neuron_region_cmap.append(region_cmap[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.palplot(sns.color_palette(\"Paired\",12))\n",
    "plt.xticks(np.arange(12),regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = sb.clustermap(G, row_linkage=g_linkage, row_colors=[g_cmap[x-1] for x in g_clusters],\n",
    "#         col_linkage=neuron_linkage, col_colors=[neuron_cmap[x-1] for x in neuron_linkage_clusters],\n",
    "#         method=\"ward\", figsize=(20, 20),cmap=\"RdBu_r\", vmin=-0.1,vmax=0.1)\n",
    "cm = sb.clustermap(G, row_linkage=g_linkage, row_colors=[[g_cmap[x-1] for x in g_clusters],neuron_region_cmap],\n",
    "        col_linkage=neuron_linkage, col_colors=[[neuron_cmap[x-1] for x in neuron_linkage_clusters], neuron_region_cmap],\n",
    "        method=\"ward\", figsize=(20, 20),cmap=\"RdBu_r\", vmin=-0.1,vmax=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = [0,2,4,6,8,10]\n",
    "# Z = [2,6,10]\n",
    "nZ = len(Z)\n",
    "back_img = []\n",
    "for z in Z:\n",
    "    back_img.append(np.power(f.get_tif_rasl_as_vol(z,range(1,200)).mean(axis=2),.4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(g_nclust,nZ, figsize=[8*nZ,4*g_nclust])\n",
    "for c in range(g_nclust):\n",
    "    clust = c + 1\n",
    "    for iz, z in enumerate(Z):\n",
    "        #Select rois in raphe in this slices, and get their coordinates.\n",
    "        coords = df[(g_clusters==clust) & (df.z==z)].coords\n",
    "#         coords = [np.round(poly[~np.isnan(poly).any(axis=1)])[:,(1,0)].astype(int) for poly in poly_coords]\n",
    "        plt.subplot(g_nclust,nZ,c*nZ+iz+1)\n",
    "        #Overlay the ROIs on the background image and display:\n",
    "        img = vizutil.overlay_coords(back_img[iz], coords, list(g_cmap[c][:3]), alpha=1)\n",
    "        plt.imshow(img,interpolation='nearest')\n",
    "        plt.title(\"Cluster {}, z={}\".format(clust,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og2 = neuron_cmap[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_cmap[2] = (og2[0],og2[1], og2[2]+0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_cmap[2]\n",
    "plt.subplots(neuron_nclust,nZ, figsize=[8*nZ,4*neuron_nclust])\n",
    "for c in range(neuron_nclust):\n",
    "    clust = c + 1\n",
    "    for iz, z in enumerate(Z):\n",
    "        #Select rois in raphe in this slices, and get their coordinates.\n",
    "        coords = df[(neuron_linkage_clusters==clust) & (df.z==z)].coords\n",
    "#         coords = [np.round(poly[~np.isnan(poly).any(axis=1)])[:,(1,0)].astype(int) for poly in poly_coords]\n",
    "        plt.subplot(neuron_nclust,nZ,c*nZ+iz+1)\n",
    "        #Overlay the ROIs on the background image and display:\n",
    "        img = vizutil.overlay_coords(back_img[iz], coords, list(neuron_cmap[c][:3]), alpha=1)\n",
    "        plt.imshow(img,interpolation='nearest')\n",
    "        plt.title(\"Cluster {}, z={}\".format(clust,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_fish.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(u_fish.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.suptitle(\"G-causality params with L1={}\".format(l1))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(model.G[0,0:100,0:100].cpu().detach().numpy(),vmin=0.02,vmax=0.02)\n",
    "plt.title(\"Granger \")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(model.auto[0,0:100,0:100].cpu().detach().numpy())\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "plt.title(\"Autocorrelation\")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "# plt.subplot(1,3,3)\n",
    "# plt.imshow(model.B[0:100,0:100].cpu().detach().numpy())\n",
    "# plt.colorbar(fraction=0.046, pad=0.04)\n",
    "# plt.title(\"Bias\")\n",
    "# plt.tick_params(\n",
    "#     axis='y',          # changes apply to the x-axis\n",
    "#     which='both',      # both major and minor ticks are affected\n",
    "#     left=False,      # ticks along the bottom edge are off\n",
    "#     right=False,         # ticks along the top edge are off\n",
    "#     labelleft=False) # labels along the bottom edge are off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12*5,4*5))\n",
    "plt.suptitle(\"G-causality params with L1={}\".format(l1))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(model.G[0].cpu().detach().numpy())\n",
    "plt.title(\"Granger \")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(model.auto[0].cpu().detach().numpy())\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "plt.title(\"Autocorrelation\")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "# plt.subplot(1,3,3)\n",
    "# plt.imshow(model.B.cpu().detach().numpy(),vmin=-0.02,vmax=0.02)\n",
    "# plt.colorbar(fraction=0.046, pad=0.04)\n",
    "# plt.title(\"Bias\")\n",
    "# plt.tick_params(\n",
    "#     axis='y',          # changes apply to the x-axis\n",
    "#     which='both',      # both major and minor ticks are affected\n",
    "#     left=False,      # ticks along the bottom edge are off\n",
    "#     right=False,         # ticks along the top edge are off\n",
    "#     labelleft=False) # labels along the bottom edge are off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.save(model.state_dict(), \"granger_raw__TV5000_bz=1_3xl1=1e-0&lr=1e-1_15xl1=5e-2&lr=1e-3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_by_region(W, df, vmin=-0.02, vmax=0.02):\n",
    "    neuron_map = np.argsort(df.where(df[\"region_id\"]>=0)[\"region_id\"]) # no region is -1\n",
    "    nHasRegion = np.sum(neuron_map!=-1) + 1 # last -1 index will be removed\n",
    "    newW = np.zeros(nHasRegion,nHasRegion)\n",
    "    new_order = neuron_map[np.arange(W.shape[0])]\n",
    "    new_order = new_order[new_order>=0]\n",
    "    newW = W[new_order]\n",
    "    newW = newW[:,new_order]\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    im = ax.imshow(newW,vmin=vmin,vmax=vmax)\n",
    "    fig.colorbar(im)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(region_id=pd.Series(np.full(len(df),-1).astype(np.int32)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, region in enumerate(regions):\n",
    "    idx = np.where(df[region])[0]\n",
    "    df.loc[idx, \"region_id\"] = i\n",
    "df[regions].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix_by_region(model.G.data[0].detach().cpu().numpy(),df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(model.G[0].cpu().detach().numpy(),vmin=-0.02,vmax=0.02)\n",
    "plt.title(\"Granger \")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster granger by neuron correlation\n",
    "cm = sb.clustermap(model.G.data[0].detach().cpu().numpy(), row_linkage=neuron_linkage,\n",
    "                   col_linkage=neuron_linkage, method=\"ward\", figsize=(20, 20),vmin=-0.02,vmax=0.02,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering Granger\n",
    "G = model.G.data[0].detach().cpu().numpy()\n",
    "g_linkage = hierarchy.linkage(\n",
    "    distance.pdist(G), method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, coph_dists = hierarchy.cophenet(g_linkage, distance.pdist(G))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sb.clustermap(G, row_linkage=g_linkage,\n",
    "                   col_linkage=neuron_linkage, method=\"ward\", figsize=(20, 20),vmin=-0.2,vmax=0.2, cmap=\"RdBu_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sb.clustermap(G, row_linkage=g_linkage,\n",
    "                   col_linkage=g_linkage, method=\"ward\", figsize=(20, 20),vmin=-0.2,vmax=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_linkage_clusters = hierarchy.fcluster(g_linkage,5,criterion='maxclust')\n",
    "# includes all neurons, even those without cluster\n",
    "cluster_by_g = np.zeros(cnmf.shape[1]+1)\n",
    "for i,v in enumerate(g_linkage_clusters):\n",
    "    cluster_by_g[i] = v\n",
    "cluster_by_g = cluster_by_g[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=9\n",
    "df, sig = f.get_cnmf_roi_table_and_signals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 10\n",
    "#Create a background image by averaging 200 frames and adjusting the gamma.\n",
    "back_img = np.power(f.get_tif_rasl_as_vol(z,range(1,200)).mean(axis=2),.4)\n",
    "\n",
    "#Select rois in raphe in this slices, and get their coordinates.\n",
    "poly_coords = df[(df.z==z)].poly\n",
    "poly_coords = [np.round(poly[~np.isnan(poly).any(axis=1)])[:,(1,0)].astype(int) for poly in poly_coords]\n",
    "\n",
    "#Overlay the ROIs on the background image and display:\n",
    "img = vizutil.overlay_coords(back_img, poly_coords, [0,0,1], alpha=.5)\n",
    "plt.figure(figsize=[20,20])\n",
    "plt.imshow(img,interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_linkage_clusters = hierarchy.fcluster(g_linkage,4,criterion='maxclust')\n",
    "# g_linkage_clusters = hierarchy.fcluster(g_linkage, 11, depth=10)\n",
    "# g_linkage_clusters = hierarchy.fcluster(g_linkage, 5, criterion='distance')\n",
    "# includes all neurons, even those without cluster\n",
    "cluster_by_g = np.zeros(cnmf.shape[1]+1)\n",
    "for i,v in enumerate(g_linkage_clusters):\n",
    "    cluster_by_g[i] = v\n",
    "cluster_by_g = cluster_by_g[:-1]\n",
    "count, hist,_ = plt.hist(cluster_by_g,np.arange(0.5,int(max(cluster_by_g)+1),1))\n",
    "clusters = np.argwhere(count>100)[:,0]+1\n",
    "nclust = len(clusters)\n",
    "print(nclust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_by_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = [0,2,4,6,8,10]\n",
    "Z = [3,6,9]\n",
    "nZ = len(Z)\n",
    "back_img = []\n",
    "for z in Z:\n",
    "    back_img.append(np.power(f.get_tif_rasl_as_vol(z,range(1,200)).mean(axis=2),.4))\n",
    "    \n",
    "plt.subplots(nclust,nZ, figsize=[8*nZ,4*nclust])\n",
    "for c, clust in enumerate(clusters):\n",
    "    for iz, z in enumerate(Z):\n",
    "        #Select rois in raphe in this slices, and get their coordinates.\n",
    "        poly_coords = df[(cluster_by_g==clust) & (df.z==z)].poly\n",
    "        poly_coords = [np.round(poly[~np.isnan(poly).any(axis=1)])[:,(1,0)].astype(int) for poly in poly_coords]\n",
    "        plt.subplot(nclust,nZ,c*nZ+iz+1)\n",
    "        #Overlay the ROIs on the background image and display:\n",
    "        img = vizutil.overlay_coords(back_img[iz], poly_coords, [0,0,1], alpha=.5)\n",
    "        plt.imshow(img,interpolation='nearest')\n",
    "        plt.title(\"Cluster {}, z={}\".format(clust,z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nfeatures = x_fish.shape[1]\n",
    "nfeatures = 100\n",
    "model = Granger(nfeatures,1)\n",
    "X = x_fish[:-1,None,0:nfeatures]\n",
    "Y = x_fish[1:,0:nfeatures]\n",
    "data = T.utils.data.TensorDataset(X,Y)\n",
    "train(model,data,3,l1p=1e-0,lr=1e-1,batch_size=4,verbose=False)\n",
    "train(model,data,15,l1p=5e-2,lr=1e-3,batch_size=4,verbose=False)\n",
    "\n",
    "plt.figure(figsize=(12*5,4*5))\n",
    "plt.suptitle(\"G-causality params with L1={}\".format(l1))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(model.G[0].cpu().detach().numpy())#,vmin=-0.2,vmax=0.2)\n",
    "plt.title(\"Granger \")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(model.auto[0].cpu().detach().numpy())#,vmin=0.25,vmax=1.5)\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "plt.title(\"Autocorrelation\")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(model.B.cpu().detach().numpy())#,vmin=-0.1,vmax=0.1)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title(\"Bias\")\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nfeatures = x_fish.shape[1]\n",
    "nfeatures = 100\n",
    "model = Granger(nfeatures,1)\n",
    "X = x_fish[:-1,None,0:nfeatures]\n",
    "Y = x_fish[1:,0:nfeatures]\n",
    "data = T.utils.data.TensorDataset(X,Y)\n",
    "l1 = 1e-6\n",
    "print(\"1e-1\")\n",
    "train(model,data,100,l1=l1,batch_size=80,verbose=False)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.suptitle(\"G-causality params with L1={}\".format(l1))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(model.G[0,0:100,0:100].cpu().detach().numpy())\n",
    "plt.title(\"Granger \")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(model.auto[0,0:100,0:100].cpu().detach().numpy())\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "plt.title(\"Autocorrelation\")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(model.B[0:100,0:100].cpu().detach().numpy())\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title(\"Bias\")\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nfeatures = x_fish.shape[1]\n",
    "nfeatures = 100\n",
    "model = Granger(nfeatures,1)\n",
    "X = x_fish[:-1,None,0:nfeatures]\n",
    "Y = x_fish[1:,0:nfeatures]\n",
    "data = T.utils.data.TensorDataset(X,Y)\n",
    "l1 = 1e-4\n",
    "print(\"1e-1\")\n",
    "train(model,data,3,l1=l1,lr=1e-1,batch_size=80,verbose=True)\n",
    "# print(\"1e-2\")\n",
    "# train(model,data,10,l1=l1,lr=1e-2,batch_size=80,verbose=True)\n",
    "print(\"1e-4\")\n",
    "train(model,data,20,l1=1e-5,lr=1e-3,batch_size=80,verbose=True)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.suptitle(\"G-causality params with L1={}\".format(l1))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(model.G[0,0:100,0:100].cpu().detach().numpy())\n",
    "plt.title(\"Granger \")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(model.auto[0,0:100,0:100].cpu().detach().numpy())\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "plt.title(\"Autocorrelation\")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(model.B[0:100,0:100].cpu().detach().numpy())\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title(\"Bias\")\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.suptitle(\"G-causality params with L1={}\".format(l1))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(model.G[0,0:100,0:100].cpu().detach().numpy())\n",
    "plt.title(\"Granger \")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(model.auto[0,0:100,0:100].cpu().detach().numpy())\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "plt.title(\"Autocorrelation\")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(model.B[0:100,0:100].cpu().detach().numpy())\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title(\"Bias\")\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nfeatures = x_fish.shape[1]\n",
    "nfeatures = 100\n",
    "model = Granger(nfeatures,1)\n",
    "X = x_fish[:-1,None,0:nfeatures]\n",
    "Y = x_fish[1:,0:nfeatures]\n",
    "data = T.utils.data.TensorDataset(X,Y)\n",
    "l1 = 1e-3\n",
    "print(\"1e-1\")\n",
    "train(model,data,3,l1=l1,lr=1e-1,batch_size=80,verbose=True)\n",
    "# print(\"1e-2\")\n",
    "# train(model,data,10,l1=l1,lr=1e-2,batch_size=80,verbose=True)\n",
    "print(\"1e-4\")\n",
    "train(model,data,20,l1=1e-6,lr=1e-3,batch_size=80,verbose=True)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.suptitle(\"G-causality params with L1={}\".format(l1))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(model.G[0,0:100,0:100].cpu().detach().numpy())\n",
    "plt.title(\"Granger \")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(model.auto[0,0:100,0:100].cpu().detach().numpy())\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off\n",
    "plt.title(\"Autocorrelation\")\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(model.B[0:100,0:100].cpu().detach().numpy())\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "plt.title(\"Bias\")\n",
    "plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    left=False,      # ticks along the bottom edge are off\n",
    "    right=False,         # ticks along the top edge are off\n",
    "    labelleft=False) # labels along the bottom edge are off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.data = np.zeros([5000,5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.fig.set_canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo.io\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsize = 250\n",
    "overlap = 0.9\n",
    "start = 0\n",
    "end = neurons.shape[0]-winsize\n",
    "print(end/(winsize*(1-overlap))*4/25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_corr_colors = [neuron_cmap[x-1] for x in neuron_linkage_clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_to_array(fig):\n",
    "    \"Convert matplotlib fig into a numpy array (rgb image)\"\n",
    "    fig.canvas.draw()\n",
    "    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
    "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winsize = 250\n",
    "overlap = 0.9\n",
    "start = 0\n",
    "end = neurons.shape[0]-winsize\n",
    "neuron_corr_colors = [neuron_cmap[x-1] for x in neuron_linkage_clusters]\n",
    "# use single hierarchy\n",
    "writer = skvideo.io.FFmpegWriter(\"long_color_corr_over_time.mp4\", outputdict={'-b': '30000000'})\n",
    "\n",
    "pbar = tqdm(total=end/(winsize*(1-overlap)))\n",
    "while start < end:\n",
    "    corr = corrcoef(neurons[start:start+winsize].t()).cpu().numpy()\n",
    "    cm = sb.clustermap(corr, row_linkage=neuron_linkage, col_linkage=neuron_linkage, method=\"ward\",\n",
    "            col_colors=neuron_corr_colors, row_colors=neuron_corr_colors,\n",
    "            figsize=(15, 15))\n",
    "    f = fig_to_array(cm.fig)\n",
    "    for i in range(4):\n",
    "        writer.writeFrame(f)\n",
    "    start += int((winsize*(1-overlap)))\n",
    "    pbar.update(1)\n",
    "    plt.close('all')\n",
    "    gc.collect()\n",
    "pbar.close()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = corrcoef(neurons.t()).cpu().numpy()\n",
    "cm = sb.clustermap(corr, row_linkage=neuron_linkage, col_linkage=neuron_linkage, method=\"ward\",\n",
    "            col_colors=neuron_corr_colors, row_colors=neuron_corr_colors,\n",
    "            figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
