{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "import skimage as sk\n",
    "import skimage.io\n",
    "import skvideo\n",
    "import skvideo.io\n",
    "import torch\n",
    "import torch as T\n",
    "import scipy\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import normalize\n",
    "import torchvision as tv\n",
    "from tqdm import tqdm\n",
    "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral,\n",
    "                                 denoise_wavelet, estimate_sigma)\n",
    "import skimage.transform\n",
    "from importlib import reload\n",
    "import fish_track as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/ubuntu/\"\n",
    "# filename = \"20180410_1.mp4\"\n",
    "filename = \"20180109_2.mp4\"\n",
    "vid_file = directory+filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstFrame = ft.get_first_frame(vid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = ft.get_n_frames(vid_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.imshow(firstFrame)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# find a good frame for ROI\n",
    "plt.imshow(frames[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 70\n",
    "maxThreshold = 30\n",
    "minThreshold = 7\n",
    "downsample = lambda x: skimage.transform.resize(x,np.array(firstFrame.shape[:2])/4)\n",
    "frame = downsample(firstFrame)\n",
    "frame = np.full([pad*2+frame.shape[0],pad*2+frame.shape[1]], 1)\n",
    "fishroiframe = downsample(firstFrame)\n",
    "frame[pad:-pad,pad:-pad] = downsample(denoise_tv_chambolle(frames[11,:,:,0]).copy()*255)\n",
    "frame[frame>maxThreshold] = maxThreshold\n",
    "frame[frame<minThreshold] = 0\n",
    "# plt.imshow(frame)\n",
    "# plt.colorbar()\n",
    "\n",
    "# fishCenter = (pad+117,pad+95)\n",
    "fishCenter = (pad+59,pad+47)\n",
    "pad = 50\n",
    "\n",
    "fishROI = ft.selectROI(frame,fishCenter, pad)\n",
    "\n",
    "# fishROI = normalize(fishROI, norm='l2')\n",
    "fishROI = fishROI - fishROI.mean()\n",
    "# fishROI = (fishROI - fishROI.mean())/fishROI.std()\n",
    "# fishROI = fishROI - fishROI.sum()/len(fishROI)\n",
    "fishROI = fishROI.astype(float32)\n",
    "\n",
    "fishROI[pad,pad] = np.max(fishROI)*2\n",
    "plt.imshow(fishROI)\n",
    "plt.colorbar()\n",
    "imageW, imageH = frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = np.float32\n",
    "filters = ft.ROI_to_filters(frame, fishCenter, pad, imageW, imageH, 32,dtype=dtype)\n",
    "filters_fft = ft.ROI_to_filters(frame, fishCenter, pad, imageW, imageH, 32, fft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 6\n",
    "ncol = 6\n",
    "plt.subplots(nrow,ncol,figsize=(12,12))\n",
    "for i in range(filters.shape[0]):\n",
    "    plt.subplot(nrow,ncol,1+i)\n",
    "    plt.imshow(filters[i].cpu().numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_find_position(img, filters, fft=False,dtype=np.float32):\n",
    "    nrow = int(np.ceil(np.sqrt(filters.shape[0])))\n",
    "    ncol = nrow\n",
    "    plt.imshow(img)\n",
    "    if fft:\n",
    "        hm = ft.heatmap_fft(img[:,:,0].astype(dtype),filters)\n",
    "    else:\n",
    "        hm = ft.heatmap(img[:,:,0].astype(dtype),filters)\n",
    "    print(\"Best: filter={}, x={}, y={}\".format(*np.unravel_index(np.argmax(hm),hm.shape)))\n",
    "    plt.subplots(nrow,ncol,figsize=(15,15))\n",
    "    for i in range(hm.shape[0]):\n",
    "        plt.subplot(nrow,ncol,1+i)\n",
    "        h = hm[i].cpu().numpy().astype(np.float32)\n",
    "        m = np.unravel_index(np.argmax(h),h.shape)\n",
    "        image = ft.drawROI(ft.scale_range(h[:,:,None],0,1).repeat(3,2),m[0],m[1],7,80,5,use_float=True)\n",
    "        plt.imshow(image)\n",
    "        plt.title(\"filter {}\".format(i))\n",
    "\n",
    "    plt.subplots(nrow,ncol,figsize=(12,12))\n",
    "    for i in range(hm.shape[0]):\n",
    "        plt.subplot(nrow,ncol,1+i)\n",
    "        f = filters[i].cpu().numpy().astype(np.float32)\n",
    "        if fft:\n",
    "            f = f[:,:,0]\n",
    "        plt.imshow(f)\n",
    "        plt.title(\"filter {}\".format(i))\n",
    "\n",
    "viz_find_position(frames[7], filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = frames[0]\n",
    "img = downsample(f[:,:,0].astype(np.float64)).astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = ft.find_position(img,filters)\n",
    "plt.figure(figsize=(17,17))\n",
    "plt.imshow(ft.drawROI(downsample(f),*pos,1,45,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.write_video(filters, vid_file, directory + \"track_close_32filters_\" + filename,nframes=1e4,nskip=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "pos = heatmap_fft(img,filters_fft,shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "# for some reason, pytorch argmax is performing very slowly.\n",
    "pos = find_position_fft(img,filters_fft,shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "# numpy's argmax is performing much better, but this is suboptimal\n",
    "# as must transfer entire image back to CPU\n",
    "pos = ft.find_position_fft_np_argmax(img,filters_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "pos = ft.heatmap(img,filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "pos = ft.find_position(img,filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "pos = find_position_threshold(img,filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(img.shape)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 3\n",
    "x = scipy.signal.convolve(img,filters[0])\n",
    "np.argmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT conv validation (failing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_fft(img, w):\n",
    "    fimg = T.cuda.FloatTensor(*w.shape[1:]).zero_()\n",
    "    fimg[:,:,0] = T.from_numpy(img).cuda()\n",
    "    conv = T.ifft(T.fft(fimg,2)*w,2)\n",
    "    return conv[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ft.heatmap(img, filters).cpu().numpy()[0].astype(np.float64))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(heatmap_fft(img, filters_fft)[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_find_position(frames[0], filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_find_position(frames[7], filters_fft, fft=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tracking video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_position_scipy(img, w, parallel):\n",
    "    conv = delayed(lambda i: scipy.signal.convolve(img,w[i]))\n",
    "    hm = np.array(parallel(conv(i) for i in range(w.shape[0])))\n",
    "    idx = hm.argmax()\n",
    "    y, x = np.unravel_index(idx, hm.shape)[1:]\n",
    "    return y, x\n",
    "\n",
    "def write_video_scipy(filters, input_vid_filename, output_vid_filename,nframes=1e4,nskip=1e1, downsample=4):\n",
    "    vid_gen = skvideo.io.vreader(input_vid_filename)\n",
    "    writer = skvideo.io.FFmpegWriter(output_vid_filename)\n",
    "    with Parallel(n_jobs=8) as parallel:\n",
    "        for t, frame in tqdm(enumerate(vid_gen)):\n",
    "            if t % 10 ==0:\n",
    "                img = frame[:,:,0].astype(np.float32)\n",
    "                pos = find_position(img,filters)\n",
    "                f = drawROI(frame,*pos,2,90,1)\n",
    "                writer.writeFrame(f)\n",
    "            if t > 1000*10:\n",
    "                break\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_position_scipy(img, w, parallel):\n",
    "    hm = np.array(parallel(\n",
    "        delayed(scipy.signal.convolve)(img,w[i])\n",
    "        for i in range(w.shape[0])))\n",
    "    idx = hm.argmax()\n",
    "    y, x = np.unravel_index(idx, hm.shape)[1:]\n",
    "    return y, x\n",
    "\n",
    "with Parallel(n_jobs=8) as parallel:\n",
    "    hm = find_position_scipy(img, filters, parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
