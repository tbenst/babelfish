{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3\"\n",
    "fidx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishIdx = [(\"e\", 2),  (\"e\", 5), (\"c\", 1),  (\"c\", 6),  (\"enp\", 1), (\"enp\", 5)]\n",
    "\n",
    "#%%\n",
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "import gc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from torchvision.transforms import Resize\n",
    "import dill\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "import resource\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import apex # https://github.com/NVIDIA/apex.git\n",
    "from apex.amp import amp\n",
    "import gc\n",
    "\n",
    "\n",
    "import os, sys, datetime\n",
    "import itertools\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "sys.path.insert(0,\".\")\n",
    "from deepfish.helpers import get_frames_from_z, get_imaging_from_fish, gen_imaging, resize_volume, resize_batch, read_cnmf, no_overlap_idx, train_valid_test_split, train_test_split, pad_imaging\n",
    "\n",
    "from deepfish.stats import sampleMSE\n",
    "from deepfish.plot import interpret, plot_model_vs_real, makePredVideo, MSEbyDist, plot_embedding_over_time\n",
    "\n",
    "from deepfish.data import ZebraFishData\n",
    "# from deepfish.deep_kSVD import Deep_KSVD, train\n",
    "from deepfish.deep_skip import DeepSkip, train\n",
    "from deepfish.half_precision import network_to_half\n",
    "from deepfish.volume import volume_mse\n",
    "\n",
    "Model = DeepSkip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = False\n",
    "# gen = True\n",
    "cuda=True\n",
    "# cnmf=True\n",
    "cnmf=False\n",
    "half=True\n",
    "half=False\n",
    "multi_gpu = True\n",
    "num_workers = 16\n",
    "prev_frames = 5\n",
    "next_frames = 5\n",
    "if fidx==0:\n",
    "    model_name = \"180825_f01555_deep_skip_X=t-4:t_Y=t+1,t+5_epochs=15_Y_MSE=2.523E+01_Y_val_MSE=3.078E+01\"\n",
    "elif fidx==1:\n",
    "    model_name = \"180906-09:22PM_f01575_skip_X=t-4:t_Y=t+1,t+5_epochs=15_Y_MSE=2.482E+01_Y_val_MSE=2.938E+01\"\n",
    "\n",
    "f = all_data[fishIdx[fidx][0]][fishIdx[fidx][1]]\n",
    "\n",
    "\n",
    "frame_times = T.from_numpy(f.frame_st.mean(1).astype(np.float32))\n",
    "shocks = T.FloatTensor(frame_times.shape).zero_()\n",
    "shocks[np.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1\n",
    "\n",
    "tail_movements = T.FloatTensor(frame_times.shape).zero_()\n",
    "tail_movements[np.searchsorted(f.frame_et[:,-1],\n",
    "    f.tail_movement_start_times,side=\"left\")] = 1\n",
    "\n",
    "fishpath = '/data2/Data/MPzfish/drn_hb/{}/{}_small.npz'.format(f.fishid, f.fishid)\n",
    "imaging = np.load(fishpath)['fish']\n",
    "imaging = pad_imaging(imaging, 128, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvt_split = train_test_split(2826, nchunks=20)\n",
    "total_examples = sum([len(x) for x in tvt_split.values()])\n",
    "print([\"{}: {} ({:.2f}%)\".format(k, len(v), 100*len(v)/total_examples) for k,v in tvt_split.items()])\n",
    "\n",
    "train_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        tvt_split['train'], prev_frames,next_frames)\n",
    "\n",
    "# valid_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "#                         tvt_split['validation'], prev_frames,next_frames)\n",
    "\n",
    "test_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        tvt_split['test'], prev_frames,next_frames)\n",
    "\n",
    "total_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        None, prev_frames,next_frames)\n",
    "\n",
    "_, nZ, H, W = train_data[0][0][\"brain\"].shape\n",
    "\n",
    "nEmbedding = 20\n",
    "batch_size = 8\n",
    "batch_size = 32\n",
    "\n",
    "conv_model = Model(nZ,H,W,nEmbedding,prev_frames,next_frames,\n",
    "                   tensor=T.cuda.FloatTensor)\n",
    "if multi_gpu:\n",
    "    conv_model = nn.DataParallel(conv_model)\n",
    "\n",
    "conv_model.load_state_dict(T.load(\"/data2/trained_models/\"+model_name+\".pt\"))\n",
    "\n",
    "conv_model.cuda()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cnmf = f.get_cnmf_roi_table_and_signals()\n",
    "cnmf = cnmf.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = df.loc[np.logical_or(df['in_r_LHb'], df['in_l_LHb'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = imaging.max(0)\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(maxi.max(0))\n",
    "plt.colorbar()\n",
    "hab_mask = T.zeros(maxi.shape)\n",
    "raphe_mask = T.zeros(maxi.shape)\n",
    "if fidx==0:\n",
    "    hab_mask[:,:,190:235] = T.from_numpy(maxi[:,:,190:235])>300\n",
    "    raphe_mask[:,52:62,0:80] = T.from_numpy(maxi[:,52:62,0:80])>300\n",
    "elif fidx==1:\n",
    "    hab_mask[:,:,198:248] = T.from_numpy(maxi[:,:,198:248])>700\n",
    "    raphe_mask[:,52:62,0:80] = T.from_numpy(maxi[:,52:62,0:80])>300\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(hab_mask.max(0)[0])\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(raphe_mask.max(0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop_gradient_mask(model, batch, grad):\n",
    "    \"\"\"For one batch, backprop gradient mask.\"\"\"    \n",
    "    gc.collect()\n",
    "    T.cuda.empty_cache()\n",
    "    (X,Y) = batch\n",
    "    model.zero_grad()\n",
    "    model = conv_model.module\n",
    "    xb = X['brain'].cuda()\n",
    "    xb.requires_grad=True\n",
    "    (prev_vol, _), (pred_vol, _), _, _ = model(xb, X['shock'].cuda())\n",
    "    T.autograd.backward(pred_vol,grad)\n",
    "    xb_grad = xb.grad.detach()\n",
    "    return xb_grad\n",
    "\n",
    "dataloader = DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "for i,x in enumerate(dataloader):\n",
    "    if i==0:\n",
    "        sample = x\n",
    "        break\n",
    "\n",
    "bg = backprop_gradient_mask(conv_model.module, sample, hab_mask)\n",
    "plt.imshow(bg[0].max(0)[0].max(0)[0]) # max over prev frames, max over Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(total_data[711][1]['brain'][-1].max(0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging[0,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a fish object f...\n",
    "#specify a condition to define a set of rois you want in the mask (could be based on activity)\n",
    "\n",
    "z = 4; region_col = 'in_l_LHb'\n",
    "\n",
    "#extract the roi coords\n",
    "\n",
    "df = f.get_roi_table()\n",
    "\n",
    "coords = df[df[region_col]].coords\n",
    "\n",
    "#create a boolean mask\n",
    "vol_size = imaging[0].shape\n",
    "mask = np.zeros([vol_size[0], vol_size[1], vol_size[2]], dtype=np.bool)\n",
    "\n",
    "small_idx = lambda X: list(map(lambda x: int(np.floor(x/2)), X))\n",
    "\n",
    "for c in coords:\n",
    "    mask[small_idx(c[:,:,0]),small_idx(c[:,:,1])] = True\n",
    "\n",
    "plt.imshow(mask)\n",
    "left_hab_mask = T.from_numpy(mask.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 455\n",
    "prev_vol = train_data[i][0]['brain'][-1]\n",
    "next_vol = train_data[i][1]['brain'][-1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(3,2,1)\n",
    "plt.imshow(prev_vol.max(0)[0].numpy())\n",
    "plt.title(\"Prev vol\")\n",
    "plt.subplot(3,2,2)\n",
    "plt.imshow(next_vol.max(0)[0].numpy())\n",
    "plt.title(\"Next vol\")\n",
    "\n",
    "line_mask = T.zeros_like(next_vol)\n",
    "line_mask[:,100:120,80:90] = next_vol[:,100:120,80:90] > 300\n",
    "\n",
    "mask = left_hab_mask\n",
    "# ugly hack for collation\n",
    "dataloader = DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "for j,x in enumerate(dataloader):\n",
    "    if j==i:\n",
    "        batch = x\n",
    "        break\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "(X,Y) = batch\n",
    "xb = X['brain'].cuda()\n",
    "with T.no_grad():\n",
    "    (prev, _), (pred, _), _, _ = conv_model(xb, X['shock'].cuda())\n",
    "plt.imshow(prev[0].max(0)[0].cpu().numpy())\n",
    "plt.title(\"Model denoised\")\n",
    "plt.subplot(3,2,4)\n",
    "plt.imshow(pred[0].max(0)[0].cpu().numpy())\n",
    "plt.title(\"Model prediction\")\n",
    "        \n",
    "plt.subplot(3,2,5)\n",
    "bg = backprop_gradient_mask(conv_model.module, batch, mask)\n",
    "plt.imshow(bg[0].max(0)[0].max(0)[0])\n",
    "plt.title(\"Backpropped\")\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "plt.imshow(mask.max(0)[0])\n",
    "plt.title(\"Mask\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((pred-prev)[0].max(0)[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = backprop_gradient_mask(conv_model.module, sample, hab_mask)\n",
    "plt.imshow(bg[0].max(0)[0].max(0)[0]) # max over prev frames, max over Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_backprop_gradient_mask(model, data, grad,batch_size=16, progress=False):\n",
    "    \"\"\"For all batch, backprop gradient mask.\"\"\"    \n",
    "    dl = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    if progress:\n",
    "        dl = tqdm(dl)\n",
    "    else:\n",
    "        dl = dl\n",
    "    res = []\n",
    "    for batch in dl:\n",
    "        res.append(backprop_gradient_mask(model, batch, grad))\n",
    "    return T.cat(res).mean(0)\n",
    "\n",
    "bg_hab = avg_backprop_gradient_mask(conv_model.module, test_data, hab_mask, progress=True)\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(bg_hab.max(0)[0].max(0)[0])  # max over prev frames, max over Z\n",
    "bg_rap = avg_backprop_gradient_mask(conv_model.module, test_data, raphe_mask, progress=True)\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(bg_rap.max(0)[0].max(0)[0])  # max over prev frames, max over Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bg = avg_backprop_gradient_mask(conv_model.module, train_data, hab_mask, progress=True)\n",
    "plt.imshow(train_bg[0,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_force_embedding(model, func, data, no_shock=False, batch_size=16, progress=False):\n",
    "    \"\"\"For all data, for each dim, map embedding and return vol x nDim.\n",
    "    \n",
    "    func :: (i, embedding) -> embedding\"\"\"\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    vols_by_dim = []\n",
    "    halfembed = int(model.nEmbedding/2)\n",
    "    \n",
    "    with T.no_grad():\n",
    "        for i in range(halfembed):\n",
    "            res = []\n",
    "            if progress:\n",
    "                dl = tqdm(dataloader)\n",
    "            else:\n",
    "                dl = dataloader\n",
    "            for (X,Y) in dl:\n",
    "                encoded, logvar, skip = model.encode(X['brain'].cuda())\n",
    "                # call func on latent being explored\n",
    "                # map over batch\n",
    "                latent_state_pred = T.cuda.FloatTensor(encoded.shape[0],halfembed).zero_()\n",
    "                for b in range(encoded.shape[0]):\n",
    "                    latent_state_pred[b] = func(i, encoded[b])\n",
    "                if not no_shock:\n",
    "                    x_shock = X['shock'].cuda()\n",
    "                else:\n",
    "                    x_shock = T.zeros(encoded.shape[0],prev_frames).cuda()\n",
    "                pred_state = model.predict(latent_state_pred,x_shock)\n",
    "                actual_pred_state = model.predict(encoded[:,:halfembed],x_shock)\n",
    "                actual_pred_vol = model.decode(actual_pred_state,skip)[0] # ignore tail\n",
    "                pred_vol = model.decode(pred_state,skip)[0] # ignore tail\n",
    "                res.append((pred_vol-actual_pred_vol).cpu())\n",
    "            if len(res)==1:\n",
    "                vols_by_dim.append(res[0])\n",
    "            else:\n",
    "                vols_by_dim.append(T.cat(res))\n",
    "            gc.collect()\n",
    "            T.cuda.empty_cache()\n",
    "    return T.stack(vols_by_dim)\n",
    "    \n",
    "def avg_vol_interpret(model, data, prev_frames):\n",
    "    \"Plot average prev & next frame for each latent dimension\"\n",
    "    plt.figure(figsize=(10,40))\n",
    "    halfembed = int(model.nEmbedding/2)\n",
    "    with T.no_grad():\n",
    "\n",
    "        func = lambda i, embedding: T.from_numpy(np.eye(halfembed)[i].astype(np.float32)).cuda()[None]\n",
    "        pred_vols = model_force_embedding(model, func, data, no_shock=True, progress=True)\n",
    "        vmax = np.percentile(pred_vols.abs().numpy(), 99)\n",
    "#         vmin = np.percentile(pred_vols.numpy(), 1)\n",
    "        for i in range(halfembed):\n",
    "            plt.subplot(1+nEmbedding,3,i*3+5)\n",
    "            plt.imshow(pred_vols[i].mean(0)[6],vmin=-vmax, vmax=vmax)\n",
    "            plt.title(\"Pred (Dim {})\".format(i))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "avg_vol_interpret(conv_model.module, test_data, prev_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vol_interpret(model, fish_vol, prev_frames, nEmbedding):\n",
    "    \"Plot prev & next frame for each latent dimension\"\n",
    "    plt.figure(figsize=(10,40))\n",
    "    \n",
    "    plt.subplot(1+nEmbedding,3,1)\n",
    "    plt.imshow(fish_vol[0,4,6])\n",
    "    plt.title(\"Seed frame\")\n",
    "    \n",
    "    with T.no_grad():\n",
    "        halfembed = int(nEmbedding/2)\n",
    "        embedding = T.from_numpy(np.zeros(nEmbedding).astype(np.float32)).cuda()[None]\n",
    "        shock = T.cuda.FloatTensor(2,1,prev_frames).zero_()\n",
    "        shock[0] = T.zeros(1,prev_frames)\n",
    "        shock[1] = T.ones(1,prev_frames)\n",
    "\n",
    "        (actual_prev_vol, _), (actual_pred_vol, _), _, _ = model(fish_vol, shock[0])\n",
    "\n",
    "        plt.subplot(1+nEmbedding,3,1)\n",
    "        plt.imshow(actual_prev_vol[0,6])\n",
    "        plt.title(\"Prev (Actual)\")\n",
    "\n",
    "        plt.subplot(1+nEmbedding,3,2)\n",
    "        plt.imshow(actual_pred_vol[0,6])\n",
    "        plt.title(\"Pred (Actual)\")\n",
    "\n",
    "        plt.subplot(1+nEmbedding,3,3)\n",
    "        plt.imshow(actual_pred_vol[0,6]-actual_prev_vol[0,6])\n",
    "        plt.title(\"Diff (Dim {})\")\n",
    "\n",
    "    \n",
    "        func = lambda i, embedding: T.from_numpy(np.eye(halfembed)[i].astype(np.float32)).cuda()[None]\n",
    "        pred_vols = model_force_embedding(model, func, fish_vol)\n",
    "        for i in range(halfembed):\n",
    "            plt.subplot(1+nEmbedding,3,i*3+5)\n",
    "            plt.imshow(pred_vols[i][0,6])\n",
    "            plt.title(\"Pred (Dim {})\".format(i))\n",
    "\n",
    "            plt.subplot(1+nEmbedding,3,i*3+6)\n",
    "            plt.imshow(pred_vols[i][0,6]-actual_pred_vol[0,6])\n",
    "            plt.title(\"Diff (Dim {})\".format(i))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "framenum = 500\n",
    "fish_vol = T.from_numpy(imaging[None,framenum:(framenum+next_frames)]).cuda()\n",
    "one_vol_interpret(conv_model.module,fish_vol, prev_frames, nEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret(model, fish_vol, prev_frames, nEmbedding):\n",
    "    \"Plot prev & next frame for each latent dimension\"\n",
    "    plt.figure(figsize=(10,40))\n",
    "    \n",
    "    plt.subplot(1+nEmbedding,3,1)\n",
    "    plt.imshow(fish_vol[0,4,6])\n",
    "    plt.title(\"Seed frame\")\n",
    "    \n",
    "    with T.no_grad():\n",
    "    \n",
    "        halfembed = int(nEmbedding/2)\n",
    "        embedding = T.from_numpy(np.zeros(nEmbedding).astype(np.float32)).cuda()[None]\n",
    "        shock = T.cuda.FloatTensor(2,1,prev_frames).zero_()\n",
    "        shock[0] = T.zeros(1,prev_frames)\n",
    "        shock[1] = T.ones(1,prev_frames)\n",
    "\n",
    "        encoded, logvar, skip = model.encode(fish_vol)\n",
    "        actual_latent_state_pred = encoded[:,:halfembed]\n",
    "        actual_pred_state = model.predict(actual_latent_state_pred,shock[0])\n",
    "        actual_pred_vol = model.decode(actual_pred_state,skip)[0]\n",
    "        actual_latent_state_prev = encoded[:,halfembed:]\n",
    "        actual_prev_state = model.predictZero(actual_latent_state_prev,shock[0])\n",
    "        actual_prev_vol = model.decode(actual_prev_state,skip)[0]\n",
    "\n",
    "        vol_vmax = np.percentile(actual_pred_vol.cpu().numpy(),99)\n",
    "        \n",
    "        plt.subplot(1+nEmbedding,3,1)\n",
    "        plt.imshow(actual_prev_vol[0,6], vmin=-vol_vmax, vmax=vol_vmax)\n",
    "        plt.title(\"Prev (Actual)\")\n",
    "\n",
    "        plt.subplot(1+nEmbedding,3,2)\n",
    "        plt.imshow(actual_pred_vol[0,6], vmin=-vol_vmax, vmax=vol_vmax)\n",
    "        plt.title(\"Pred (Actual)\")\n",
    "\n",
    "        plt.subplot(1+nEmbedding,3,3)\n",
    "        plt.imshow(actual_pred_vol[0,6]-actual_prev_vol[0,6])\n",
    "        plt.title(\"Diff (Dim {})\")\n",
    "        \n",
    "        diff_vmax=None\n",
    "    \n",
    "        for i in range(halfembed):\n",
    "            encoded, logvar, skip = model.encode(fish_vol)\n",
    "            #turn on latent being explored\n",
    "            latent_state_pred = 10*T.from_numpy(np.eye(halfembed)[i].astype(np.float32)).cuda()[None]\n",
    "            pred_state = model.predict(latent_state_pred,shock[0])\n",
    "            pred_vol = model.decode(pred_state,skip)[0]\n",
    "\n",
    "            latent_state_prev = encoded[:,halfembed:]\n",
    "            prev_state = model.predictZero(latent_state_prev,shock[0])\n",
    "            prev_vol = model.decode(prev_state,skip)[0]\n",
    "\n",
    "    #         prev_img = model.decode(embedding)[0][0] # ignore tail\n",
    "    #         next_img = model.decode(model.predict(embedding,shock[0]))[0][0] # ignore tail\n",
    "    #         next_img_shock = model.decode(model.predict(embedding,shock[1]))[0][0]\n",
    "\n",
    "#             plt.subplot(1+nEmbedding,3,i*3+4)\n",
    "#             plt.imshow(prev_vol[0,6])\n",
    "#             plt.title(\"Prev (Dim {})\".format(i))\n",
    "\n",
    "            plt.subplot(1+nEmbedding,3,i*3+5)\n",
    "            plt.imshow(pred_vol[0,6], vmin=-vol_vmax, vmax=vol_vmax)\n",
    "            plt.title(\"Pred (Dim {})\".format(i))\n",
    "            if not diff_vmax:\n",
    "                diff_vmax = (pred_vol[0,6]-actual_pred_vol[0,6]).max()\n",
    "            plt.subplot(1+nEmbedding,3,i*3+6)\n",
    "            plt.imshow(pred_vol[0,6]-actual_pred_vol[0,6],vmin=-diff_vmax, vmax=diff_vmax)\n",
    "            plt.title(\"Diff (Dim {})\".format(i))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "framenum = 500\n",
    "fish_vol = T.from_numpy(imaging[None,framenum:(framenum+next_frames)]).cuda()\n",
    "interpret(conv_model.module,fish_vol, prev_frames, nEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "T.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus1_vol_interpret(model, data, prev_frames):\n",
    "    \"Plot average prev & next frame for each latent dimension\"\n",
    "    plt.figure(figsize=(10,40))\n",
    "    halfembed = int(model.nEmbedding/2)\n",
    "    with T.no_grad():\n",
    "        shock = T.cuda.FloatTensor(2,1,prev_frames).zero_()\n",
    "        shock[0] = T.zeros(1,prev_frames)\n",
    "        shock[1] = T.ones(1,prev_frames)\n",
    "\n",
    "        func = lambda i, embedding: (embedding + T.from_numpy(np.eye(halfembed)[i].astype(np.float32)).cuda())[None]\n",
    "        pred_vols = model_force_embedding(model, func, data, progress=True)\n",
    "        vmax = np.percentile(pred_vols.abs().numpy(), 99)\n",
    "#         vmin = pred_vols.min()\n",
    "        for i in range(halfembed):\n",
    "            plt.subplot(1+nEmbedding,3,i*3+5,vmin=-vmax, vmax=vmax)\n",
    "            plt.imshow(pred_vols[i].mean(0)[6])\n",
    "            plt.title(\"Pred (Dim {})\".format(i))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "avg_vol_interpret(conv_model.module, test_data, prev_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses_train = sampleMSE(conv_model, train_data, 16)\n",
    "mses_test = sampleMSE(conv_model, test_data, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mses_train[\"MSE(X_pred,Y_t+5)\"]\n",
    "b = mses_train[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_train[\"MSE(X_pred,X_t-4)\"]\n",
    "b = mses_train[\"MSE(Y_pred,X_t-4)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_train[\"MSE(X_pred,X_t)\"]\n",
    "b = mses_train[\"MSE(Y_pred,X_t)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_test[\"MSE(X_pred,Y_t+5)\"]\n",
    "b = mses_test[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b), a.mean()-b.mean())\n",
    "\n",
    "a = mses_test[\"MSE(X_pred,X_t)\"]\n",
    "b = mses_test[\"MSE(Y_pred,X_t)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_test[\"MSE(X_pred,Y_t+1)\"]\n",
    "b = mses_test[\"MSE(Y_pred,Y_t+1)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishMAData(Dataset):\n",
    "    def __init__(self, imaging, ma=5, nfuture=1, index_map=None):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        self.data = T.from_numpy(data)\n",
    "        self.ma=ma\n",
    "        self.nfuture=nfuture\n",
    "        self.index_map=index_map\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.index_map:\n",
    "            return len(self.index_map)\n",
    "        else:\n",
    "            return self.data.shape[0]-self.ma-self.nfuture+1\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.index_map:\n",
    "            idx = self.index_map[i]\n",
    "        else:\n",
    "            idx = i\n",
    "        return self.data[(idx-self.ma+1):(idx+1)].mean(0), self.data[idx+self.nfuture]\n",
    "    \n",
    "def MSE_MA(data, batch_size=256):\n",
    "    mse = []\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    with T.no_grad():\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            X, Y = batch_data\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            mse.append(volume_mse(X, Y).cpu())\n",
    "\n",
    "    return T.cat(mse).numpy()\n",
    "\n",
    "mse_prev_train_1 = MSE_MA(FishMAData(imaging, 1, 1, tvt_split['train']), 256)\n",
    "mses_ma_train_5 = MSE_MA(FishMAData(imaging, 5, 5, tvt_split['train']), 256)\n",
    "mses_ma_train_1 = MSE_MA(FishMAData(imaging, 5, 1, tvt_split['train']), 256)\n",
    "mses_ma_test_5 = MSE_MA(FishMAData(imaging, 5, 5, tvt_split['test']), 256)\n",
    "mses_ma_test_1 = MSE_MA(FishMAData(imaging, 5, 1, tvt_split['test']), 256)\n",
    "mse_prev_test_1 = MSE_MA(FishMAData(imaging, 1, 1, tvt_split['test']), 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishMeanData(Dataset):\n",
    "    def __init__(self, imaging, nfuture=1, index_map=None):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        self.data = T.from_numpy(data)\n",
    "        self.meanfish = imaging.mean(0)\n",
    "        self.nfuture=nfuture\n",
    "        self.index_map=index_map\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.index_map:\n",
    "            return len(self.index_map)\n",
    "        else:\n",
    "            return self.data.shape[0]-self.nfuture+1\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.index_map:\n",
    "            idx = self.index_map[i]\n",
    "        else:\n",
    "            idx = i\n",
    "        return self.meanfish, self.data[idx+self.nfuture]\n",
    "\n",
    "mse_meanfish_train_1 = MSE_MA(FishMeanData(imaging, 1, tvt_split['train']), 256)\n",
    "mse_meanfish_train_5 = MSE_MA(FishMeanData(imaging, 5, tvt_split['train']), 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mses_ma_train_5\n",
    "b = mses_train[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_ma_train_1\n",
    "b = mses_train[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n",
    "\n",
    "a = mses_ma_test_5\n",
    "b = mses_test[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),stats.ttest_rel(a,b), a.mean()-b.mean())\n",
    "\n",
    "# a = mses_ma_test_1\n",
    "# b = mses_test[\"MSE(Y_pred,X_t)\"]\n",
    "# print(stats.wilcoxon(a,b),stats.ttest_rel(a,b),a.mean()-b.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_prev_1 = []\n",
    "for i in range(len(imaging)-1):\n",
    "    mse_prev_1.append(F.mse_loss(T.from_numpy(imaging[i]),\n",
    "                                 T.from_numpy(imaging[i+1])))\n",
    "mse_prev_1 = np.array(mse_prev_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(mse_meanfish_train_1)\n",
    "plt.plot(mse_prev_train_1)\n",
    "plt.plot(mses_ma_train_1)\n",
    "plt.legend([\"Mean fish\", \"Previous frame\", \"Moving Average (5)\"])\n",
    "plt.title(\"t+1\")\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(mses_ma_train_5)\n",
    "plt.plot(mses_train[\"MSE(Y_pred,Y_t+5)\"])\n",
    "plt.title(\"t+5\")\n",
    "plt.legend([\"Moving Average (5)\", \"Model prediction\"])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"train_mse_t_vs_t+5.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(mse_prev_test_1)\n",
    "plt.plot(mses_ma_test_1)\n",
    "plt.legend([\"Previous frame\", \"Moving Average (5)\"])\n",
    "plt.title(\"t+1\")\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(mses_ma_test_5)\n",
    "plt.plot(mses_test[\"MSE(Y_pred,Y_t+5)\"])\n",
    "plt.title(\"t+5\")\n",
    "plt.legend([\"Moving Average (5)\", \"Model prediction\"])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"test_mse_t_vs_t+5.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(2,1,1)\n",
    "mse_diff = mses_train[\"MSE(Y_pred,Y_t+1)\"]-mses_train[\"MSE(X_pred,Y_t+1)\"]\n",
    "sb.distplot(mse_diff,1000)\n",
    "plt.axvline(0,c='k')\n",
    "plt.title(\"Train\")\n",
    "plt.axvline(mse_diff.mean(),c='r')\n",
    "plt.subplot(2,1,2,sharex=ax)\n",
    "sb.distplot(mses_train[\"MSE(Y_pred,Y_t+5)\"] - \\\n",
    "            mses_train[\"MSE(X_pred,Y_t+5)\"], 1000)\n",
    "plt.axvline(0,c='k')\n",
    "# plt.xlim(-0.5e8,.5e8)\n",
    "plt.savefig(\"train_mse_diff.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(2,1,1)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,X_t)\"]-mses_test[\"MSE(X_pred,X_t)\"])\n",
    "plt.axvline(0,c='k')\n",
    "plt.title(\"X_pred is closer to t (Test)\")\n",
    "plt.subplot(2,1,2,sharex=ax)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,Y_t+5)\"]-mses_test[\"MSE(X_pred,Y_t+5)\"])\n",
    "plt.title(\"Y_pred is closer to t+5 (Test)\")\n",
    "plt.axvline(0,c='k')\n",
    "plt.savefig('test_mse_diff.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(tvt_split[\"test\"],mses_test[\"MSE(X_pred,Y_t+5)\"],'.',c='indianred',alpha=0.5)\n",
    "plt.plot(tvt_split[\"test\"],mses_test[\"MSE(Y_pred,Y_t+5)\"],'.',c='steelblue',alpha=0.5)\n",
    "plt.subplot(2,1,2)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,Y_t+5)\"]-mses_test[\"MSE(X_pred,Y_t+5)\"])\n",
    "plt.axvline(0,c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_over_time(model,data, batch_size=64, num_workers=12):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    embeddings = []\n",
    "    logvars = []\n",
    "    model.eval()\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        with T.no_grad():\n",
    "            embedding, logvar, _ = model.encode(X.cuda())\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "        logvars.append(logvar.cpu().numpy())\n",
    "    model.train()\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    logvars = np.vstack(logvars)\n",
    "    nEmbeddings = embeddings.shape[1]\n",
    "    half = int(np.ceil(nEmbeddings / 2))\n",
    "    \n",
    "    plt.figure(figsize=(15,20))\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(embeddings[:,0:half])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(embeddings[:,half:])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    \n",
    "    plt.subplot(4,1,3)\n",
    "    plt.plot(logvars[:,0:half])\n",
    "    plt.title(\"Logvars over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(logvars[:,half:])\n",
    "    plt.title(\"Logvars over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = plot_embedding_over_time(conv_model.module,total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging[500].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_for_vid(arr, mymin, mymax):\n",
    "    return ((arr - mymin) * (1/(mymax - mymin)) * 255).astype('uint8')\n",
    "\n",
    "import skvideo.io\n",
    "def makePredVideo(model, data, batch_size=32, num_workers=12, name=\"test\"):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    writer = skvideo.io.FFmpegWriter(name+\".mp4\",outputdict={\n",
    "        '-b': '30000000', '-vcodec': 'libx264'})\n",
    "    mymax = float(T.cat([test_data[i][0]['brain'] for i in np.arange(len(test_data))]).max())\n",
    "    mymin = float(T.cat([test_data[i][0]['brain'] for i in np.arange(len(test_data))]).min())\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        with T.no_grad():\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), _, _= model(X.cuda(),Y_shock.cuda())\n",
    "        for x, x_pred, y, y_pred in zip(X,X_pred,Y,Y_pred):\n",
    "            # 7th z layer\n",
    "            zslice = x_pred[6]\n",
    "            H = zslice.shape[0]\n",
    "            W = zslice.shape[1]\n",
    "            frame = np.zeros([H*2,W*3])\n",
    "            \n",
    "            frame[:H, :W] = y[0,6]\n",
    "            frame[:H, W:(2*W)] = y[-1,6] - y[0,6]\n",
    "            frame[:H, (2*W):] = y[-1,6]\n",
    "            frame[H:, :W] = x_pred[6]\n",
    "            frame[H:, W:(2*W)] = y_pred[6] - y[0,6].cuda() #x_pred[6]\n",
    "            frame[H:, (2*W):] = y_pred[6]\n",
    "            writer.writeFrame(scale_for_vid(frame,mymin,mymax))\n",
    "    writer.close()\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = makePredVideo(conv_model,train_data,name=model_name+'_train')\n",
    "\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
