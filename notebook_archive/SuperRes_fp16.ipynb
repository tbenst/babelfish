{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "class SuperResBlock(nn.Module):\n",
    "    \"\"\"Upsample Volume using subpixel convolution.\n",
    "    \n",
    "    Reference: https://arxiv.org/pdf/1609.05158.pdf\"\"\"\n",
    "    def __init__(self, upscale_factor):\n",
    "        super(SuperResBlock, self).__init__()\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dconv1 = nn.Parameter(T.FloatTensor(64,8,5,5))\n",
    "        self.dbias1 = nn.Parameter(T.FloatTensor(64))\n",
    "        self.dpad1 = (2,2)\n",
    "        self.dbn1 = nn.BatchNorm2d(64)\n",
    "        self.dconv2 = nn.Parameter(T.FloatTensor(64,64,3,3))\n",
    "        self.dbias2 = nn.Parameter(T.FloatTensor(64))\n",
    "        self.dpad2 = (1,1)\n",
    "        self.dbn2 = nn.BatchNorm2d(64)\n",
    "        self.dconv3 = nn.Parameter(T.FloatTensor(32,64,3,3))\n",
    "        self.dbias3 = nn.Parameter(T.FloatTensor(32))\n",
    "        self.dpad3 = (1,1)\n",
    "        self.dbn3 = nn.BatchNorm2d(32)\n",
    "        self.dconv4 = nn.Parameter(T.FloatTensor(upscale_factor**2,32,3,3))\n",
    "        self.dbias4 = nn.Parameter(T.FloatTensor(upscale_factor**2))\n",
    "        self.dpad4 = (1,1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = self.activation(self.dbn1(F.conv2d(x, self.dconv1, self.dbias1, padding=self.dpad1)))\n",
    "        x = self.activation(self.dbn2(F.conv2d(x, self.dconv2, self.dbias2, padding=self.dpad2)))\n",
    "        x = self.activation(self.dbn3(F.conv2d(x, self.dconv3, self.dbias3, padding=self.dpad3)))\n",
    "        x = F.conv2d(x, self.dconv4, self.dbias4, padding=self.dpad4)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        # add back single channel\n",
    "#         x = x[:,:,None]\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        nn.init.orthogonal_(self.dconv1, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv2, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv3, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv4)\n",
    "        for bn in [self.dbn1,self.dbn2,self.dbn3]:\n",
    "            nn.init.constant_(bn.weight, 1)\n",
    "            nn.init.constant_(bn.bias, 0)\n",
    "            \n",
    "class SuperResBlockNotFunctional(nn.Module):\n",
    "    \"\"\"Upsample Volume using subpixel convolution.\n",
    "    \n",
    "    Reference: https://arxiv.org/pdf/1609.05158.pdf\"\"\"\n",
    "    def __init__(self, upscale_factor):\n",
    "        super(SuperResBlockNotFunctional, self).__init__()\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dpad1 = (2,2)\n",
    "        self.dconv1 = nn.Conv2d(8,64,(5,5),padding=self.dpad1)\n",
    "        self.dbn1 = nn.BatchNorm2d(64)\n",
    "        self.dpad2 = (1,1)\n",
    "        self.dconv2 = nn.Conv2d(64,64,(3,3),padding=self.dpad2)\n",
    "        self.dbn2 = nn.BatchNorm2d(64)\n",
    "        self.dpad3 = (1,1)\n",
    "        self.dconv3 = nn.Conv2d(64,32,(3,3),padding=self.dpad3)\n",
    "        self.dbn3 = nn.BatchNorm2d(32)\n",
    "        self.dpad4 = (1,1)\n",
    "        self.dconv4 = nn.Conv2d(32,upscale_factor**2,(3,3),padding=self.dpad4)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = self.activation(self.dbn1(self.dconv1(x)))\n",
    "        x = self.activation(self.dbn2(self.dconv2(x)))\n",
    "        x = self.activation(self.dbn3(self.dconv3(x)))\n",
    "        x = self.dconv4(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        nn.init.orthogonal_(self.dconv1.weight, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv2.weight, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv3.weight, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv4.weight)\n",
    "        for bn in [self.dbn1,self.dbn2,self.dbn3]:\n",
    "            nn.init.constant_(bn.weight, 1)\n",
    "            nn.init.constant_(bn.bias, 0)\n",
    "\n",
    "\n",
    "class tofp16(nn.Module):\n",
    "    \"\"\"\n",
    "    Model wrapper that implements::\n",
    "        def forward(self, input):\n",
    "            return input.half()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(tofp16, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input.half()\n",
    "\n",
    "\n",
    "def BN_convert_float(module):\n",
    "    '''\n",
    "    Designed to work with network_to_half.\n",
    "    BatchNorm layers need parameters in single precision.\n",
    "    Find all layers and convert them back to float. This can't\n",
    "    be done with built in .apply as that function will apply\n",
    "    fn to all modules, parameters, and buffers. Thus we wouldn't\n",
    "    be able to guard the float conversion based on the module type.\n",
    "    '''\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.float()\n",
    "    for child in module.children():\n",
    "        BN_convert_float(child)\n",
    "    return module\n",
    "\n",
    "\n",
    "def network_to_half(network):\n",
    "    \"\"\"\n",
    "    Convert model to half precision in a batchnorm-safe way.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(tofp16(), BN_convert_float(network.half()))\n",
    "            \n",
    "input_c = 8\n",
    "W = 256\n",
    "H = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functional convolution FP32 Iterations per second:  2.993901670164117\n",
      "FP32 Iterations per second:  2.998001570069859\n"
     ]
    }
   ],
   "source": [
    "net = SuperResBlock(2).cuda()\n",
    "inp = T.randn(64, input_c, 256, 256, requires_grad=True).cuda()\n",
    "\n",
    "for i in range(5):\n",
    "    net.zero_grad()\n",
    "    out = net.forward(inp)\n",
    "    loss = out.sum()\n",
    "    loss.backward()\n",
    "\n",
    "T.cuda.synchronize()\n",
    "start=time.time()\n",
    "for i in range(100):\n",
    "    net.zero_grad()\n",
    "    out = net.forward(inp)\n",
    "    loss = out.sum()\n",
    "    loss.backward()\n",
    "T.cuda.synchronize()\n",
    "end=time.time()\n",
    "\n",
    "print(\"Functional convolution FP32 Iterations per second: \", 100/(end-start))\n",
    "\n",
    "\n",
    "net = SuperResBlockNotFunctional(2).cuda()\n",
    "# inp = T.randn(64, input_c, 256, 256, requires_grad=True).cuda()\n",
    "\n",
    "for i in range(5):\n",
    "    net.zero_grad()\n",
    "    out = net.forward(inp)\n",
    "    loss = out.sum()\n",
    "    loss.backward()\n",
    "\n",
    "T.cuda.synchronize()\n",
    "start=time.time()\n",
    "for i in range(100):\n",
    "    net.zero_grad()\n",
    "    out = net.forward(inp)\n",
    "    loss = out.sum()\n",
    "    loss.backward()\n",
    "T.cuda.synchronize()\n",
    "end=time.time()\n",
    "\n",
    "print(\"FP32 Iterations per second: \", 100/(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functional convolution FP16 Iterations per second:  5.623211761576424\n"
     ]
    }
   ],
   "source": [
    "net = network_to_half(SuperResBlock(2).cuda())\n",
    "inp = T.cuda.HalfTensor(64, input_c, 256, 256).normal_()\n",
    "inp.requires_grad = True\n",
    "\n",
    "T.cuda.synchronize()\n",
    "start=time.time()\n",
    "for i in range(100):\n",
    "    net.zero_grad()\n",
    "    out = net.forward(inp)\n",
    "    loss = out.float().sum()\n",
    "    loss.backward()\n",
    "T.cuda.synchronize()\n",
    "end=time.time()\n",
    "\n",
    "print(\"Functional convolution FP16 Iterations per second: \", 100/(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functional convolution FP16 Iterations per second:  5.647740691780046\n",
      "FP16 Iterations per second:  2.3371556989932443\n"
     ]
    }
   ],
   "source": [
    "net = network_to_half(SuperResBlockNotFunctional(2).cuda())\n",
    "inp = T.randn(64, input_c, 256, 256, requires_grad=True).half().cuda()\n",
    "\n",
    "T.cuda.synchronize()\n",
    "start=time.time()\n",
    "for i in range(100):\n",
    "    net.zero_grad()\n",
    "    out = net.forward(inp)\n",
    "    loss = out.float().sum()\n",
    "    loss.backward()\n",
    "T.cuda.synchronize()\n",
    "end=time.time()\n",
    "\n",
    "print(\"FP16 Iterations per second: \", 100/(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functional convolution FP16 Iterations per second:  5.236900899320723\n"
     ]
    }
   ],
   "source": [
    "net = network_to_half(SuperResBlock(2).cuda())\n",
    "inp = T.cuda.HalfTensor(64, input_c, 255, 255).normal_()\n",
    "inp.requires_grad = True\n",
    "\n",
    "T.cuda.synchronize()\n",
    "start=time.time()\n",
    "for i in range(100):\n",
    "    net.zero_grad()\n",
    "    out = net.forward(inp)\n",
    "    loss = out.float().sum()\n",
    "    loss.backward()\n",
    "T.cuda.synchronize()\n",
    "end=time.time()\n",
    "\n",
    "print(\"Functional convolution FP16 Iterations per second: \", 100/(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
