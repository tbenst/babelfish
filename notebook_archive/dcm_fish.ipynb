{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "plt.ioff()\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_{t+1} = (A + pB)x_t + Cu_{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passivity(t,k=0.05,t0=400):\n",
    "    return 1/(1+np.exp(-k*(t-t0)))\n",
    "\n",
    "def diag_idx(n):\n",
    "    return [i for i in range(n)],[i for i in range(n)]\n",
    "\n",
    "def makeStableMatrix(n, density=0.1):\n",
    "    # TODO: implement on GPU?\n",
    "    eig = np.diag(np.random.uniform(-1,0,n))\n",
    "    v = scipy.linalg.orth(np.random.uniform(-1,1,(n,n)))\n",
    "    A = np.matmul(np.matmul(v.T, eig), v)\n",
    "    # need to make A sparse\n",
    "    indices = np.reshape(np.indices((n,n)),[2,-1])\n",
    "    mask = np.eye(n)\n",
    "    # may create density slightly less than desired if choice is on diagonal\n",
    "    idx = indices[:,np.random.choice(np.arange(indices.shape[1]),int(np.ceil(density*n**2-n)),replace=False)]\n",
    "    mask[idx[0], idx[1]] = 1\n",
    "    A[np.logical_not(mask)] = 0\n",
    "    return A\n",
    "\n",
    "def step(A,B,C,u,p,x,dt=1):\n",
    "    dxdt = T.matmul((A + p*B), x) + C * u\n",
    "    return dxdt + x\n",
    "\n",
    "def step_batch(A,B,C,u,p,x,dt=1):\n",
    "    dxdt = (T.matmul((A + p[:,None,None]*B), x[:,:,None])).squeeze() + u[:,None]*C\n",
    "    return dxdt + x\n",
    "\n",
    "def sim(A,B,C,u,p,x0,e=0.05):\n",
    "    ntime = u.shape[0]\n",
    "    nfeatures = x0.shape[0]\n",
    "    time = T.arange(ntime,dtype=T.int32)\n",
    "    x = T.zeros(ntime, x0.shape[0]).cuda()\n",
    "    z = T.zeros(nfeatures).cuda()\n",
    "    x[0] = x0\n",
    "    for t in range(1,ntime):\n",
    "        if e==0:\n",
    "            x[t] = step(A,B,C,u[t],p[t],x[t-1])\n",
    "        else:\n",
    "            x[t] = step(A,B,C,u[t],p[t],x[t-1]) + T.normal(z,e).cuda()\n",
    "    return x\n",
    "\n",
    "def generate_data(sim_time, nstim,nfeatures, burn_in=400, test_time=200, e=0.01, k=0.05, t0=400, density=0.2):\n",
    "    ntime = sim_time+burn_in+test_time\n",
    "    time = T.from_numpy(np.arange(ntime)).cuda()\n",
    "    A_true = T.from_numpy(makeStableMatrix(nfeatures,density).astype(np.float32)).cuda()\n",
    "    B_true = T.from_numpy(makeStableMatrix(nfeatures,density).astype(np.float32)).cuda()\n",
    "    C_true = T.from_numpy(np.random.normal(0,0.05,nfeatures).astype(np.float32)).cuda()\n",
    "    # C_true = T.from_numpy(makeStableMatrix(nfeatures).astype(np.float32)).cuda()\n",
    "    x0 = T.from_numpy(np.random.normal(0,0.05,nfeatures).astype(np.float32)).cuda()\n",
    "    u = T.zeros(ntime).cuda()\n",
    "    u[np.arange(4,ntime,ntime/nstim)] = 1\n",
    "\n",
    "    p1 = np.vectorize(partial(passivity,k=k,t0=t0))\n",
    "    time = np.arange(ntime)\n",
    "    p_true = p1(time).astype(np.float32)\n",
    "    p_true = T.from_numpy(p_true).cuda()\n",
    "#     p_true = T.zeros(ntime).cuda() # TODO remove me\n",
    "    x_true = sim(A_true,B_true,C_true,u,p_true,x0,e)\n",
    "    train = (time[burn_in:-test_time], u[burn_in:-test_time],\n",
    "             p_true[burn_in:-test_time], x_true[burn_in:-test_time])\n",
    "    test = (time[-test_time:], u[-test_time:], p_true[-test_time:], x_true[-test_time:])\n",
    "    return A_true, B_true, C_true, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishSeqData(Dataset):    \n",
    "    def __init__(self, u, p, x,n_future_steps=1):\n",
    "        self.x = nn.Parameter(x,requires_grad=False)\n",
    "        self.p = nn.Parameter(p,requires_grad=False)\n",
    "        self.u = nn.Parameter(u,requires_grad=False)\n",
    "        self.nfeatures = x.shape[1]\n",
    "        self.n_future_steps = n_future_steps\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)-self.n_future_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indices = slice(idx,idx+self.n_future_steps)\n",
    "        x_true_indices = slice(idx+1,idx+self.n_future_steps+1)\n",
    "        return (self.u[indices], self.p[indices],\n",
    "                self.x[indices], self.x[x_true_indices])\n",
    "\n",
    "class DynamicsSeq(nn.Module):\n",
    "    def __init__(self, nfeatures, n_future_steps,dtype=T.float32, scale=1,std=0.1):\n",
    "        super(DynamicsSeq, self).__init__()\n",
    "        if dtype==T.float32:\n",
    "            tensor = T.cuda.FloatTensor\n",
    "        elif dtype==T.float16:\n",
    "            tensor = T.cuda.HalfTensor\n",
    "                \n",
    "        self.A = nn.Parameter(tensor(nfeatures,nfeatures).normal_(std),requires_grad=True)\n",
    "        self.B = nn.Parameter(tensor(nfeatures,nfeatures).normal_(std),requires_grad=True)\n",
    "        self.C = nn.Parameter(tensor(nfeatures).normal_(std),requires_grad=True)\n",
    "        self.n_future_steps = n_future_steps\n",
    "        self.tensor = tensor\n",
    "        self.scale = scale\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, u, p, x_true, n_future_steps=None):\n",
    "        if n_future_steps==None:\n",
    "            n_future_steps = self.n_future_steps\n",
    "        x = self.tensor(x_true.shape[0], 1+x_true.shape[1], *x_true.shape[2:]).zero_()\n",
    "        x[:,0] = x_true[:,0]\n",
    "        for t in range(n_future_steps):\n",
    "            u[ :,t,None]*self.C\n",
    "            dxdt = (T.matmul((self.A + p[:,t,None,None]*self.B), x_true[:,t,:,None]).squeeze()) + u[ :,t,None]*self.C\n",
    "            x[:,t+1] = dxdt + x[:,t]\n",
    "        return x[:,1:]\n",
    "\n",
    "class Dynamics(nn.Module):\n",
    "    def __init__(self, nfeatures):\n",
    "        super(Dynamics, self).__init__()\n",
    "        self.A = nn.Parameter(T.normal(T.zeros(nfeatures,nfeatures),0.5),requires_grad=True)\n",
    "        self.B = nn.Parameter(T.normal(T.zeros(nfeatures,nfeatures),0.5),requires_grad=True)\n",
    "        self.C = nn.Parameter(T.normal(T.zeros(nfeatures),0.5),requires_grad=True)\n",
    "\n",
    "    def forward(self, u, p, x):\n",
    "        return (x[:,0] + (T.matmul((self.A + p[:,0,None,None]*self.B), x[:,0,:,None]).squeeze()) + u[:,0,None] * self.C)[:,None]\n",
    "\n",
    "\n",
    "def train(model,data,nepochs=10, lambdaA=(1e-8, 1e-6), lambdaB=(1e-6, 1e-6), lr=0.1, verbose=True):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    if verbose:\n",
    "        A_loss = F.mse_loss(model.A.data,A_true)\n",
    "        print(\"A_loss: {}\".format(A_loss))\n",
    "    cum_mse_loss = 0\n",
    "    with T.no_grad():\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            U,P,X, X_true = batch_data\n",
    "            X_pred = model(U,P,X)\n",
    "            cum_mse_loss += F.mse_loss(X_pred.float(),X_true.float())\n",
    "    print(\"mse_loss: {}\".format(cum_mse_loss/len(dataloader)))\n",
    "    optimizer = T.optim.SGD(model.parameters(),lr=lr)\n",
    "#     optimizer = T.optim.Adam(model.parameters(),lr=lr,amsgrad=True)\n",
    "    for e in range(nepochs):\n",
    "        if verbose:\n",
    "            print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        cum_mse_loss = 0\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            U,P,X, X_true = batch_data\n",
    "            X_pred = model(U,P,X)\n",
    "            l_A = lambdaA[0] * model.A.norm(1) + lambdaA[1] * model.A.norm(2)\n",
    "            l_B = lambdaB[0] * model.B.norm(1) + lambdaB[1] * model.B.norm(2)\n",
    "            mse_loss = F.mse_loss(X_pred,X_true)\n",
    "            loss = mse_loss + l_A + l_B\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "            cum_mse_loss += float(mse_loss)\n",
    "            del X_pred, U,P,X, X_true, mse_loss, l_A, l_B, loss\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        if verbose:\n",
    "            A_loss = F.mse_loss(model.A.data,A_true)\n",
    "            B_loss = F.mse_loss(model.B.data,B_true)\n",
    "            C_loss = F.mse_loss(model.C.data,C_true)\n",
    "            print(\"pred_loss: {}, A_loss: {}, B_loss: {}, C_loss: {}\".format(cum_loss,A_loss,B_loss,C_loss))\n",
    "        print(\"cum_loss: {}, mse_loss: {}\".format(cum_loss,cum_mse_loss/len(dataloader)))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"pred_loss: {}, A_loss: {}, B_loss: {}, C_loss: {}\".format(cum_loss,A_loss,B_loss,C_loss))\n",
    "\n",
    "def set_grad(params, params_with_grad):\n",
    "\n",
    "    for param, param_w_grad in zip(params, params_with_grad):\n",
    "        if param.grad is None:\n",
    "            param.grad = torch.nn.Parameter(param.data.new().resize_(*param.data.size()))\n",
    "        param.grad.data.copy_(param_w_grad.grad.data)\n",
    "    \n",
    "def train_fp16(model,data,nepochs=10, lambdaA=(1e-8, 1e-6), lambdaB=(1e-6, 1e-6), lr=0.1, verbose=True,loss_scale=1):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    param_copy = [param.clone().type(torch.cuda.FloatTensor).detach() for param in model.parameters()]\n",
    "    for batch_data in tqdm(dataloader):\n",
    "            U,P,X, X_true = batch_data\n",
    "            X_pred = model(U,P,X)\n",
    "            mse_loss = F.mse_loss(X_pred.float(),X_true.float())\n",
    "            print(\"pred loss: {}\".format(mse_loss))\n",
    "            break\n",
    "    \n",
    "    if verbose:\n",
    "        A_loss = F.mse_loss(param_copy[0].data/model.scale,A_true)\n",
    "        print(\"A_loss: {}\".format(A_loss))\n",
    "#         optimizer = T.optim.SGD(model.parameters(),lr=lr)\n",
    "    for param in param_copy:\n",
    "        param.requires_grad = True\n",
    "    optimizer = torch.optim.SGD(param_copy, lr)\n",
    "#     optimizer = T.optim.Adam(param_copy,lr=lr)\n",
    "    nfeatures = model.A.shape[0]\n",
    "#     nondiagonal = ~T.eye(nfeatures,dtype=T.uint8)\n",
    "    for e in range(nepochs):\n",
    "        if verbose:\n",
    "            print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            U,P,X, X_true = batch_data\n",
    "            X_pred = model(U,P,X)\n",
    "            l_A = lambdaA[0] * model.A.float().norm(1) + lambdaA[1] * model.A.float().norm(2)\n",
    "            l_B = lambdaB[0] * model.B.float().norm(1) + lambdaB[1] * model.B.float().norm(2)\n",
    "#             l_A = lambdaA[0] * model.A[nondiagonal].float().norm(1) + lambdaA[1] * model.A[nondiagonal].float().norm(2)\n",
    "#             l_B = lambdaB[0] * model.B.float().norm(1) + lambdaB[1] * model.B.float().norm(2)\n",
    "\n",
    "            mse_loss = F.mse_loss(X_pred,X_true).float()\n",
    "            loss = (mse_loss + l_A + l_B) * loss_scale\n",
    "\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            set_grad(param_copy, list(model.parameters()))\n",
    "            if loss_scale != 1:\n",
    "                for param in param_copy:\n",
    "                    param.grad.data = param.grad.data/loss_scale\n",
    "            optimizer.step()\n",
    "            params = list(model.parameters())\n",
    "            for i in range(len(params)):\n",
    "                params[i].data.copy_(param_copy[i].data)\n",
    "\n",
    "            cum_loss += float(loss)/loss_scale\n",
    "    #             del X_pred, U,P,X, X_true, mse_loss, l_A, l_B, loss\n",
    "    #             gc.collect()\n",
    "    #             torch.cuda.empty_cache()\n",
    "\n",
    "        if verbose:\n",
    "            A_loss = F.mse_loss(param_copy[0].data/model.scale,A_true)\n",
    "            B_loss = F.mse_loss(param_copy[1].data/model.scale,B_true)\n",
    "            C_loss = F.mse_loss(param_copy[2].data/model.scale,C_true)\n",
    "            print(\"pred_loss: {}, A_loss: {}, B_loss: {}, C_loss: {}\".format(cum_loss,A_loss,B_loss,C_loss))\n",
    "        print(\"pred_loss: {}\".format(cum_loss))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"pred_loss: {}, A_loss: {}, B_loss: {}, C_loss: {}\".format(cum_loss,A_loss,B_loss,C_loss))\n",
    "\n",
    "\n",
    "def model_v_truth(model,u,p,x_true,A_true, B_true):\n",
    "    if model.dtype==T.float16:\n",
    "        A = model.A.data.float()*model.scale\n",
    "        B = model.B.data.float()*model.scale\n",
    "    else:\n",
    "        A = model.A.data\n",
    "        B = model.B.data\n",
    "    with T.no_grad():\n",
    "        x_pred = T.squeeze(model(u[:-1,None],p[:-1,None],x_true[:-1,None],n_future_steps=1))\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    spec = gridspec.GridSpec(ncols=2, nrows=3)\n",
    "    anno_opts = dict(xy=(0.5, 0.5), xycoords='axes fraction',\n",
    "                     va='center', ha='center')\n",
    "\n",
    "    ax1 = fig.add_subplot(spec[0,0:])\n",
    "    ax2 = fig.add_subplot(spec[1, 0])\n",
    "    ax3 = fig.add_subplot(spec[1, 1])\n",
    "    ax4 = fig.add_subplot(spec[2, 0])\n",
    "    ax5 = fig.add_subplot(spec[2, 1])\n",
    "    \n",
    "    dx_pred = x_pred - x_true[:-1]\n",
    "    ax1.plot(dx_pred.mean(1).cpu().numpy(),color='red', label=\"Model\")\n",
    "#     ax1.plot(x_pred[:,2].cpu().numpy(),color='red', label=\"Model\")\n",
    "    ax1.set_ylabel(\"dx/dt\")\n",
    "    ax1.set_xlabel(\"Time\")\n",
    "    ax1.set_title(\"Witheld test data\")\n",
    "    dx_true = x_true[1:] - x_true[:-1]\n",
    "    ax1.plot(dx_true.mean(1).cpu().numpy(),color=\"gray\",linewidth=5, alpha=0.7,label=\"Truth\")\n",
    "    ax1.legend()\n",
    "    \n",
    "    mymax = max(A_true.max(), A.max())\n",
    "    mymin = min(A_true.min(), A.min())\n",
    "    im = ax2.imshow(A_true.cpu(),vmin=mymin,vmax=mymax)\n",
    "    ax2.set_title(\"A true\")\n",
    "    ax3.imshow(A.cpu(),vmin=mymin,vmax=mymax)\n",
    "    ax3.set_title(\"A model\")\n",
    "#     cax,kw = mpl.colorbar.make_axes([ax2, ax3])\n",
    "#     fig.colorbar(im, cax=cax, **kw)\n",
    "    \n",
    "    mymax = max(B_true.max(), B.max())\n",
    "    mymin = min(B_true.min(), B.min())\n",
    "    im2 = ax4.imshow(B_true.cpu(),vmin=mymin,vmax=mymax)\n",
    "    ax4.set_title(\"B true\")\n",
    "    ax5.imshow(B.cpu(),vmin=mymin,vmax=mymax)\n",
    "    ax5.set_title(\"B model\")\n",
    "#     cax,kw = mpl.colorbar.make_axes([ax4, ax5])\n",
    "#     fig.colorbar(im2, cax=cax, **kw)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fish code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment the PythonPath so python can find necessary code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import useful python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pims\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import skimage.io\n",
    "import visualization_utils as vizutil\n",
    "import seaborn as sns\n",
    "from skimage.filters import gaussian_filter\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "passivity_2p_imaging_utils provides a list of all the datasets and provides a helper class to make loading the data easy.\n",
    "\n",
    "The data_sets are split into three conditions... (the keynames are wierd for historical reasons)   \n",
    "'enp': control group - no shocks at all.  \n",
    "'c': experimental group - fish experience behavioral challenge (repeated shocks) while being imaged  \n",
    "'e': reexposed group - first fish experience free-swimming behavioral challenge... then are imaged during behavioral challenge\n",
    "  \n",
    "all_data is a dictionary keyed by the condition.  \n",
    "all_data[condition] contains a list of Passivity_2p_Fish objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "print('controls, n =', len(all_data['enp']))\n",
    "print('experimental, n =', len(all_data['c']))\n",
    "print('reexposed, n =', len(all_data['e']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ideal example fish for modeling\n",
    "(see 2p_Fish_Figure3_Accumulation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('experimental', all_data['c'][6].fishid)\n",
    "print('reexposed', all_data['e'][2].fishid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passivity_2p_Fish Class\n",
    "\n",
    "The `Passivity_2p_Fish` class offers various members and methods for loading data associated with each fish.  \n",
    "  \n",
    "Lets demo these methods using an example fish:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = all_data['e'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time of all volumes, tail_movements, and shocks are stored in the following variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The first shock started at t=', fish.shock_st[0], 's') #shock start times\n",
    "print('The first slice of the frame began being imaged at t=', fish.frame_st[0,0], 's') #time at which each slice was imaged [#samples X #slices]\n",
    "print('The first tail movement started at=', fish.tail_movement_start_times[0], 's') #tail movement times - movements separted into forward swims, turns and escapes.\n",
    "print('Num z-planes imaged:', fish.num_zplanes)\n",
    "print('Volume-Rate:', 1/np.diff(fish.frame_st[:,0]).mean()) #frame_st is #frames x #slices, we examine interval between imaging first slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo code for examining movie of tail (slowed by factor of 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_ndx = 10\n",
    "clip = fish.get_tail_movie_clip(fish.tail_movement_start_times[movement_ndx]-.1, \n",
    "                             fish.tail_movement_end_times[movement_ndx]+.1, \n",
    "                             playback_speed_factor=.1)\n",
    "clip.ipython_display(width=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo code to plot tail movement rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_window_starts = np.arange(-300,31*60,60) + fish.shock_st[0] #1 minutes windows around start of shock\n",
    "rate_window_centers = rate_window_starts + 30\n",
    "rate_windows_adj = rate_window_starts - fish.td_time[0] #corrected for the fact that get_movement_rate wants time relative to start of tail imaging.\n",
    "plt.plot(rate_window_centers - fish.shock_st[0], [fish.get_movement_rate([x,x+60], bExcShockResp=False) for x in rate_windows_adj])\n",
    "plt.axvline(0,c='r')\n",
    "plt.ylabel('Movement Rate (Hz)')\n",
    "plt.xlabel('Time Relative to First Shock (s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_roi_table` method returns a dataframe of all the rois for teh fish.  Each row of this table represents an ROI and specified the place the ROI is in, the pixels that are included in the ROI, the centroid of the ROI, and which brain regions the ROI is in.  \n",
    "\n",
    "Note, this data is older and was processed by simply segmenting the anatomical images.  Thus the data is does not look as clean as data that is cleaned up and processed using CNMF, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fish.get_roi_table() #this can be slow to run the first time as data is loaded from files\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'get_signals_raw' returns a matrix containing the raw fluorescent signal associated with each ROI.  Each row of this matrix is associated with the corresponding row of the ROI table.  \n",
    "\n",
    "Note, I only use the second half of the signal matrix, because the agarose had not fully hardened during the first of imaging which cause the fish to drift in z slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = fish.get_signals_raw(z=None)\n",
    "#M = hbutils.df_over_f(M)\n",
    "print('Num ROIs:', df.shape[0])\n",
    "print('Shape of signal matrix', M.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also various methods for grabbing the raw imaging data:  \n",
    "get_tif_as_vol  \n",
    "get_tif_rasl\n",
    "\n",
    "We can use this to visualize a few ROIs in particular plane/slice and brain region:\n",
    "\n",
    "(**This won't work on AWS unless you upload tif stacks**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a,0)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    rm = ret[n - 1:] / n\n",
    "    pad_start = np.full((n-1,rm.shape[1]), rm[0])\n",
    "    return np.vstack([pad_start, rm])\n",
    "\n",
    "def ewma(data,span):\n",
    "    df = DataFrame(data)\n",
    "    return df.ewm(span).mean().values\n",
    "\n",
    "def df_f(x,ma_window=6,span=6):\n",
    "    u = moving_average(x,ma_window)\n",
    "    return ewma((x - u)/u, span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mdf = df_f(M.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = np.float32\n",
    "x_fish = T.from_numpy(Mdf.astype(dtype)).cuda()\n",
    "time_fish = T.from_numpy(fish.frame_st.mean(1).astype(dtype)).cuda()\n",
    "if dtype==np.float16:\n",
    "    u_fish = T.cuda.HalfTensor(time_fish.shape).zero_()\n",
    "    p_fish = T.cuda.HalfTensor(time_fish.shape).zero_()\n",
    "else:\n",
    "    u_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "    p_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "u_fish[numpy.searchsorted(fish.frame_et[:,-1], fish.shock_st,side=\"left\")] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future_steps = 1\n",
    "batch_size = 1\n",
    "\n",
    "# data = FishSeqData(u_fish,p_fish,x_fish,n_future_steps)\n",
    "# model = DynamicsSeq(data.nfeatures,n_future_steps,T.float16)\n",
    "# train_fp16(model,data,15,(1e-4,1e-5),(1e-3,1e-4),lr=1e-3,verbose=False, loss_scale=512)\n",
    "\n",
    "data = FishSeqData(u_fish,p_fish,x_fish,n_future_steps)\n",
    "model = DynamicsSeq(data.nfeatures,n_future_steps)\n",
    "train(model,data,20,(1e-3,1e-4),(1e-1,1e-2),lr=1e-2,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loss if A=B=C=zeros: {}\".format(T.abs(x_fish[1:])/(x_fish.shape[0]-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.save(model.state_dict(),\"fish_dcm_fp32_sgd_epoch=20,lA=(1e-3,1e-4),lB=(1e-1,1e-2),lr=1e-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.A[:100,:100].cpu().detach().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fish[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fish[0,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(u_fish[None,None,0],p_fish[None,None,0],x_fish[None,[0]],1).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fish[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.B[:100,:100].cpu().detach().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Half precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntime = 2826\n",
    "nstim = 30\n",
    "nfeatures = 15888\n",
    "\n",
    "u_train = T.cuda.HalfTensor(ntime).uniform_()\n",
    "p_train = T.cuda.HalfTensor(ntime).uniform_()\n",
    "time_train = T.arange(ntime).half().cuda()\n",
    "x_train = T.cuda.HalfTensor(ntime,nfeatures).uniform_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ntime*3+ntime*nfeatures)*16/1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future_steps = 1\n",
    "batch_size = 1\n",
    "\n",
    "data = FishSeqData(u_train,p_train,x_train,n_future_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DynamicsSeq(data.nfeatures,n_future_steps,T.float16,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fp16(model,data,15,(1e-4,1e-5),(1e-3,0),lr=1e-3,verbose=False, loss_scale=512)\n",
    "time_test, u_test, p_test, x_test = test_data\n",
    "model_v_truth(model, u_test, p_test, x_test, A_true.data, B_true.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntime = 2826\n",
    "nstim = 30\n",
    "nfeatures = 15888\n",
    "\n",
    "u_train = T.cuda.FloatTensor(ntime).uniform_()\n",
    "p_train = T.cuda.FloatTensor(ntime).uniform_()\n",
    "time_train = T.arange(ntime).cuda()\n",
    "x_train = T.cuda.FloatTensor(ntime,nfeatures).uniform_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future_steps = 1\n",
    "batch_size = 1\n",
    "\n",
    "data = FishSeqData(u_train,p_train,x_train,n_future_steps)\n",
    "model = DynamicsSeq(data.nfeatures,n_future_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,data,1,(1e-4,1e-5),(1e-3,1e-4),lr=0.1,verbose=False)\n",
    "# time_test, u_test, p_test, x_test = test_data\n",
    "# model_v_truth(model, u_test, p_test, x_test, A_true.data, B_true.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntime = 3000\n",
    "nstim = 30\n",
    "nfeatures = 10\n",
    "A_true, B_true, C_true, train_data, test_data = generate_data(ntime, nstim,nfeatures,burn_in=200, e=0.1,k=1,t0=1e10)\n",
    "\n",
    "time_train, u_train, p_train, x_train = train_data\n",
    "time_test, u_test, p_test, x_test = test_data\n",
    "\n",
    "scale = 8\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].plot(time_train,p_train.cpu().numpy())\n",
    "ax[0].set_ylabel(\"Passivity\")\n",
    "ax[0].set_xlabel(\"Time\")\n",
    "\n",
    "ax[1].plot(x_train[:,2].cpu().numpy())\n",
    "ax[1].set_title(\"Ground Truth\")\n",
    "ax[1].set_ylabel(\"df/f\")\n",
    "ax[1].set_xlabel(\"Time\")\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future_steps = 1\n",
    "batch_size = 10\n",
    "\n",
    "data = FishSeqData(u_train,p_train,x_train,n_future_steps)\n",
    "model = DynamicsSeq(data.nfeatures,n_future_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,data,8,(1e-4,0),(1e-3,1e-4),lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v_truth(model, u_test, p_test, x_test, A_true.data, B_true.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future_steps = 1\n",
    "batch_size = 1\n",
    "\n",
    "scale = 1\n",
    "time_train, u_train, p_train, x_train = time_train, u_train.half()*scale, p_train.half()*scale, x_train.half()*scale\n",
    "time_test, u_test, p_test, x_test = time_test, u_test.half()*scale, p_test.half()*scale, x_test.half()*scale\n",
    "data = FishSeqData(u_train,p_train,x_train,n_future_steps)\n",
    "model = DynamicsSeq(data.nfeatures,n_future_steps,T.float16,scale)\n",
    "train_fp16(model,data,15,(1e-4,1e-5),(1e-3,0),lr=1e-3,verbose=True, loss_scale=512)\n",
    "\n",
    "model_v_truth(model, u_test, p_test, x_test, A_true.data, B_true.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
