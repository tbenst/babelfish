{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cluster.bicluster import SpectralBiclustering\n",
    "from sklearn.cluster.bicluster import SpectralCoclustering\n",
    "from sklearn.metrics import consensus_score\n",
    "\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import os\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from pandas import DataFrame\n",
    "\n",
    "import os, sys, datetime\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "import visualization_utils as vizutil\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "fishIdx = [(\"e\", 2),  (\"e\", 5), (\"c\", 1),  (\"c\", 6),  (\"enp\", 1), (\"enp\", 5)]\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy import signal\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "# df, sig = f.get_cnmf_roi_table_and_signals()\n",
    "\n",
    "\n",
    "# data = np.load(\"../cnmf_f01555.npz\")\n",
    "# cnmf = data['cnmf'].astype(np.float32)\n",
    "# raw = data['raw'].astype(np.float32)\n",
    "# del data\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    # a is a signal\n",
    "    ret = np.cumsum(a,0) # sum over time\n",
    "    ret[n:] = ret[n:] - ret[:-n] # diff of n samples back\n",
    "    rm = ret[n - 1:] / n\n",
    "    pad_start = np.full((n-1,rm.shape[1]), rm[0])\n",
    "    return np.vstack([pad_start, rm])\n",
    "\n",
    "def ewma(data,span):\n",
    "    \"exponential weighted moving average.\"\n",
    "    df = DataFrame(data)\n",
    "    return df.ewm(span).mean().values\n",
    "\n",
    "def df_f(x,ma_window=6,span=6):\n",
    "    u = moving_average(x,ma_window)\n",
    "    return ewma((x - u)/u, span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(neurons, df):\n",
    "    region_pca = {}\n",
    "    for r in regions:\n",
    "        X = neurons[:,df[r]]\n",
    "        pca = PCA()\n",
    "        pca.fit(X)\n",
    "        transform = pca.fit_transform(X)\n",
    "        region_pca[r] = {\"components\": pca.components_, \"explained_var\": pca.explained_variance_ratio_, \"transform\": transform}\n",
    "    neurons_pca_transform = np.concatenate([region_pca[r]['transform'] for r in regions],1)\n",
    "    return region_pca, neurons_pca_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_letter(x):\n",
    "    return x[0][5]\n",
    "def plot_pca(region_pca, f):\n",
    "    N = len(region_pca)\n",
    "    iterator = enumerate(sorted(region_pca.items(), key=region_letter))\n",
    "    plt.figure()\n",
    "    for i, (region, data) in iterator:\n",
    "        nNeurons = sum(df[region])\n",
    "        var = np.cumsum(data['explained_var'])\n",
    "        sns.lineplot(nNeurons/np.arange(1,len(var)+1),var, label=region,\n",
    "                     color=sns.color_palette('tab20')[i])\n",
    "    plt.xlabel(\"Compression ( # neurons / # PCs)\")\n",
    "    plt.ylabel(\"Explained variance\")\n",
    "    plt.xlim(0,100)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(f.fishid)\n",
    "\n",
    "def plot_pca_over_neurons(region_pca, f):\n",
    "    N = len(region_pca)\n",
    "    iterator = enumerate(sorted(region_pca.items(), key=region_letter))\n",
    "    plt.figure()\n",
    "    for i, (region, data) in iterator:\n",
    "        nNeurons = sum(df[region])\n",
    "        var = np.cumsum(data['explained_var'])\n",
    "        sns.lineplot(np.arange(1,len(var)+1)/nNeurons,var, label=region,\n",
    "                     color=sns.color_palette('tab20')[i])\n",
    "    plt.xlabel(\"Compression ( # PCs / # neurons)\")\n",
    "    plt.ylabel(\"Explained variance\")\n",
    "#     plt.xlim(0,100)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(f.fishid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fish_data(indicator):\n",
    "    f = all_data[fishIdx[indicator][0]][fishIdx[indicator][1]]\n",
    "    M = f.get_signals_raw(z=None)\n",
    "    neurons = M.T\n",
    "\n",
    "    # neuron_ids = np.sort(np.argsort(neurons.std(0))[-5000:])\n",
    "    df = f.get_roi_table()\n",
    "    # df = df.iloc[neuron_ids]\n",
    "    # df.reset_index(drop=True, inplace=True)\n",
    "    # neurons = neurons[:,neuron_ids]\n",
    "\n",
    "\n",
    "    neurons = signal.decimate(neurons,4, axis=0)\n",
    "\n",
    "    neurons = df_f(neurons).astype(np.float32)\n",
    "    neurons = (neurons - neurons.mean(0))/(neurons.std(0)+1e-8)\n",
    "    return f, neurons, df\n",
    "\n",
    "def get_pca_indicator(indicator):\n",
    "    f, neurons, df = read_fish_data(indicator)\n",
    "    return pca(neurons, df)\n",
    "def plot_pca_indicator(indicator):\n",
    "    region_pca, pca_transform = get_pca_indicator(indicator)\n",
    "    plot_pca(region_pca, f)\n",
    "\n",
    "# [plot_pca_indicator(i) for i in range(6)]\n",
    "# pcas = [get_pca_indicator(i) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pca_df(pcas, condition, fish_id, time_window):\n",
    "    pca_df = DataFrame(columns=[\"condition\", \"fish_id\", \"time_window\", \"region\", \"pca_num\", \"explained_var\"])\n",
    "    region_pca, pca_transform = pcas\n",
    "    iterator = enumerate(sorted(region_pca.items(), key=region_letter))\n",
    "    for i, (region, data) in iterator:\n",
    "        var = np.cumsum(data['explained_var'])\n",
    "        df = pd.DataFrame({\"condition\": condition, \"fish_id\": fish_id, \"time_window\": time_window,\n",
    "                           \"region\": region, \"pca_num\": np.arange(len(var)), \"explained_var\":var})\n",
    "        pca_df = pca_df.append(df)\n",
    "    return pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho_regions = [u'in_l_cerebellum', u'in_r_cerebellum', \n",
    "    u'in_l_vthal', u'in_r_vthal', u'in_l_tectum', u'in_r_tectum', \n",
    "    u'in_l_raphe', u'in_r_raphe', u'in_l_hind', u'in_r_hind', \n",
    "    u'in_l_dthal', u'in_r_dthal', u'in_l_LHb', u'in_r_LHb', \n",
    "    u'in_l_tel', u'in_r_tel', u'in_l_MHb',  u'in_r_MHb']\n",
    "\n",
    "_, _, df = read_fish_data(0)\n",
    "regions = []\n",
    "for r in ortho_regions:\n",
    "    if r in df.columns:\n",
    "        regions.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " all_pca_df_filled = DataFrame.from_csv(\"all_pca_df_filled_no_decimate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params:\n",
    "lag = 1\n",
    "bExcludeMotion = False\n",
    "bCNMF = False\n",
    "dff_win = 500\n",
    "decimate = None\n",
    "bWhite = False\n",
    "bWhiteByWindow = True\n",
    "bTop = False\n",
    "bOneWindow = True\n",
    "\n",
    "fishids = [['f01606','f01604','f01547','f01550','f01553'],#,'f01597','f02326','f01520','f01527',],\n",
    "           ['f01555','f01575','f01576','f01594','f01598'],\n",
    "           ['f01736','f01732','f01733','f01735','f01729']]#,'f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pca_df = DataFrame(columns=[\"condition\", \"fish_id\", \"time_window\", \"region\", \"pca_num\", \"explained_var\"])\n",
    "for ncond, cond in enumerate(['shock','reexposed','control',]):\n",
    "    for nf, fid in enumerate(fishids[ncond]):\n",
    "        f = p2putils.get_fish(all_data,fid)[0]\n",
    "        print('Starting', f.fishid)\n",
    "        \n",
    "        if bExcludeMotion:\n",
    "            exclude_before = 1\n",
    "            exclude_after = 4\n",
    "            motion_frames = numpy.searchsorted(f.frame_et[:,-1], f.tail_movement_start_times,side=\"left\")\n",
    "            exclude_idx = np.unique((motion_frames[:,None] + np.arange(-exclude_before,exclude_after+1)[None]).flatten())\n",
    "        else:\n",
    "            exclude_idx = None\n",
    "            \n",
    "        \n",
    "        #Load the signals\n",
    "        if bCNMF:\n",
    "            df, M = f.get_cnmf_roi_table_and_signals()\n",
    "        else:\n",
    "            M = f.get_signals_raw(z=None)\n",
    "            df = f.get_roi_table()\n",
    "        neurons = M.T  \n",
    "#         print(\"INITIAL SHAPE\", neurons.shape)\n",
    "        #build time windows of frames to examine\n",
    "        if bOneWindow:\n",
    "            windows = [(0,np.argmax(f.frame_st[:,0]>(f.get_shock_start_time() + 60*24 + 360)))]\n",
    "        else:\n",
    "            window_len = 360\n",
    "            windows = [(np.argmax(f.frame_st[:,0]>f.get_shock_start_time()-window_len), np.argmax(f.frame_st[:,0]>f.get_shock_start_time())),\n",
    "                       (np.argmax(f.frame_st[:,0]>f.get_shock_start_time()),np.argmax(f.frame_st[:,0]>f.get_shock_start_time()+window_len)),\n",
    "    #                    (neurons.shape[0]-360,neurons.shape[0])\n",
    "                       (np.argmax(f.frame_st[:,0]>(f.get_shock_start_time() + 60*24)),np.argmax(f.frame_st[:,0]>(f.get_shock_start_time() + 60*24 + window_len))),\n",
    "                       #(np.argmax(f.frame_st[:,0]>f.get_shock_start_time()-window_len), np.argmax(f.frame_st[:,0]>(f.get_shock_start_time() + 60*24 + window_len)))\n",
    "                      ]\n",
    "        \n",
    "        #Extract top 5000 plus all in regions\n",
    "        if bTop:\n",
    "            bndx = np.zeros(df.shape[0],dtype=np.bool)\n",
    "            for nReg, reg in enumerate(regions):\n",
    "                if reg in df.columns:\n",
    "                    bndx = bndx | df[reg]\n",
    "            bndx[np.argsort(neurons.std(0))[-5000:]] = True\n",
    "            neuron_ids = np.where(bndx)[0]\n",
    "            df = df.iloc[neuron_ids]\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            neurons = neurons[:,neuron_ids]\n",
    "        print('num neurons %d'%(neurons.shape[1]))\n",
    "        #Preprocess\n",
    "        if not bCNMF: #if not CNMF loaded above\n",
    "            neurons = df_f(neurons,dff_win,6) #6,6 or 500,6\n",
    "        else: #else if CNMF data\n",
    "            neurons = (neurons - neurons.mean(0))/neurons.mean(0) \n",
    "        if decimate is not None:\n",
    "            neurons = signal.decimate(neurons,decimate,axis=0)\n",
    "            windows = [(int(np.floor(w0/decimate)), int(np.floor(w1/decimate))) for w0,w1 in windows]\n",
    "        if bWhite:\n",
    "            neurons = (neurons - neurons.mean(0))/(neurons.std(0)+1e-8)\n",
    "            ndx = np.where(neurons.std(0)==0)\n",
    "            neurons[:,ndx] = 0\n",
    "#         print(\"AFTER\", neurons.shape)\n",
    "        \n",
    "        for it,window in enumerate(windows):\n",
    "            wneurons = neurons[window[0]:window[1]]\n",
    "            if bWhiteByWindow:\n",
    "                wneurons = (wneurons - wneurons.mean(0))/(wneurons.std(0)+1e-8) #numericall reversible?\n",
    "                ndx = np.where(wneurons.std(0)==0)\n",
    "                wneurons[:,ndx] = 0\n",
    "            # RUN ANALYSIS HERE\n",
    "#             print(wneurons.shape)\n",
    "            pcas = pca(wneurons, df)\n",
    "            pca_df = make_pca_df(pcas, cond, fid, it)\n",
    "            all_pca_df = all_pca_df.append(pca_df)\n",
    "           \n",
    "        # SAVE DATA\n",
    "#         fn = f.data_prefix+'_pca.npz'\n",
    "#         np.savez(fn, all_pcas[cond][fid][window])\n",
    "        print('Done', f.fishid)#, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for viz purposes, if max(num_pca) < desired_pcas, then pad variance explained with 1. until desired_pca\n",
    "desired_pcas = 100\n",
    "all_pca_df_filled = all_pca_df.query(\"pca_num<100\").copy()\n",
    "for ncond, cond in enumerate(['shock','reexposed','control',]):\n",
    "    for nf, fid in enumerate(fishids[ncond]):\n",
    "        for it in range(len(windows)):\n",
    "            for r in regions:\n",
    "                q = 'fish_id==\"{}\" and region==\"{}\" and time_window=={} and pca_num<100'.format(fid, r, it)\n",
    "                rows = all_pca_df.query(q)\n",
    "                if len(rows)==100 or len(rows)==0:\n",
    "                    continue\n",
    "                else:\n",
    "                    npcas = len(rows)\n",
    "#                     print(fid, cond, it, r, npcas)\n",
    "    #                 print(row)\n",
    "                    filled_df = pd.DataFrame({\"condition\": cond, \"fish_id\": fid, \"time_window\": it,\n",
    "                           \"region\": r, \"pca_num\": np.arange(npcas,desired_pcas+1, dtype=int), \"explained_var\":1.})\n",
    "                    all_pca_df_filled = all_pca_df_filled.append(filled_df)\n",
    "                \n",
    "# all_pca_df_filled.query('fish_id==\"f01553\" and region==\"in_r_raphe\" and condition==\"shock\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pca_df_filled.to_csv(\"all_neurons_pca_df_filled_no_decimate_whiten_one_window.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = all_pca_df_filled.query('condition == \"control\" and time_window==0')\n",
    "nregions = len(dat[\"region\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = all_pca_df_filled.query('pca_num<=30')\n",
    "g = sns.FacetGrid(dat, col=\"condition\", margin_titles=True)\n",
    "g.map(sns.lineplot, \"pca_num\", \"explained_var\", \"region\",\n",
    "     palette=sns.color_palette('tab20')[:nregions])\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find n_pca needed to explain >= desired_var\n",
    "desired_var = 0.5\n",
    "if windows:\n",
    "    nwindows = len(windows)\n",
    "else:\n",
    "    nwindows = 3    \n",
    "all_n_pca_df = DataFrame(columns=[u'condition', u'fish_id', u'pca_num', u'region',\n",
    "       u'time_window'])\n",
    "for ncond, cond in enumerate(['shock','reexposed','control',]):\n",
    "    for nf, fid in enumerate(fishids[ncond]):\n",
    "        for it in range(nwindows):\n",
    "            for r in regions:\n",
    "                q = 'fish_id==\"{}\" and region==\"{}\" and time_window=={} and explained_var>={}'.format(fid, r, it, desired_var)\n",
    "                rows = all_pca_df.query(q)\n",
    "                if len(rows)==0:\n",
    "                    continue\n",
    "                else:\n",
    "                    pca_n = float(rows.iloc[0].pca_num)\n",
    "                    n_pca_df = pd.DataFrame({\"condition\": cond, \"fish_id\": fid, \"time_window\": it,\n",
    "                           \"region\": r, \"pca_num\": [pca_n]})\n",
    "                    all_n_pca_df = all_n_pca_df.append(n_pca_df)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = all_n_pca_df\n",
    "sns.lineplot(\"condition\", \"pca_num\", \"region\", sort = False,\n",
    "     data=dat, palette=sns.color_palette('tab20')[:nregions])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = all_n_pca_df\n",
    "g = sns.FacetGrid(dat, col=\"condition\", margin_titles=True)\n",
    "g.map(sns.lineplot, \"time_window\", \"pca_num\", \"region\",\n",
    "     palette=sns.color_palette('tab20')[:nregions])\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.query('time_window==0 and region==\"in_l_vthal\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = all_pca_df.query('time_window == 1 and fish_id == \"f01606\" and condition == \"shock\"')\n",
    "dat = all_n_pca_df.query('condition == \"control\"')\n",
    "nregions = len(dat[\"region\"].unique())\n",
    "ax = sns.lineplot(x=\"time_window\", y=\"pca_num\", hue=\"region\", data=dat,\n",
    "                  palette=sns.color_palette('tab20')[:nregions])\n",
    "# ax.set_xlim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat = all_pca_df.query('time_window == 1 and fish_id == \"f01606\" and condition == \"shock\"')\n",
    "dat = all_pca_df.query('condition == \"control\" and time_window==1 and pca_num <=100')\n",
    "nregions = len(dat[\"region\"].unique())\n",
    "ax = sns.lineplot(x=\"pca_num\", y=\"explained_var\", hue=\"region\", data=dat,\n",
    "                  palette=sns.color_palette('tab20')[:nregions])\n",
    "# ax.set_xlim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pca_df.query('condition == \"control\" and time_window==1 and pca_num <=100').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pca_df.query('condition == \"control\" and time_window==0 and pca_num <=100').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
