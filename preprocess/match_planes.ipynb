{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tifffile import imread\n",
    "from glob import glob\n",
    "import re\n",
    "import nrrd\n",
    "import tifffile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from deepfish.helpers import get_frames_from_z, get_imaging_from_fish, gen_imaging, resize_volume, resize_batch, read_cnmf, no_overlap_idx, train_valid_test_split, train_test_split, pad_imaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/data2/Data/f10542/\"\n",
    "# fname = \"f10542_postfix_gad-405_vglut-647.ome.btf\"\n",
    "# file_path = \"/home/tyler/Dropbox/data/20181127/f10542/f10542_postfix_gcamp.ome.btf\"\n",
    "# file_path = \"/home/tyler/Dropbox/data/20181127/f10542/f10542_alive_isosbestic_gcamp_0004.ome.btf\"\n",
    "# file_path = directory + fname\n",
    "\n",
    "get_num = re.compile(\".*_zplane=(\\d*).*\\.mmap\")\n",
    "get_z = lambda x: int(get_num.search(x).group(1))\n",
    "planes = glob(directory + \"cnmf/f10542_zplane=*_els_*.mmap\")\n",
    "planes = sorted(planes, key=lambda a: get_z(a))\n",
    "nZ = len(planes)\n",
    "print(f\"Number of planes: {nZ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_shape(mytuple):\n",
    "    \"\"\" This promotes the elements inside a shape into np.uint64. It is intended to prevent overflows\n",
    "        with some numpy operations that are sensitive to it, e.g. np.memmap \"\"\"\n",
    "    if not isinstance(mytuple, tuple):\n",
    "        raise Exception(\"Internal error: prepare_shape() passed a non-tuple\")\n",
    "    return tuple(map(lambda x: np.uint64(x), mytuple))\n",
    "\n",
    "# from Caiman\n",
    "def load_memmap(filename, mode='r'):\n",
    "    \"\"\" Load a memory mapped file created by the function save_memmap\n",
    "    Args:\n",
    "        filename: str\n",
    "            path of the file to be loaded\n",
    "        mode: str\n",
    "            One of 'r', 'r+', 'w+'. How to interact with files\n",
    "    Returns:\n",
    "        Yr:\n",
    "            memory mapped variable\n",
    "        dims: tuple\n",
    "            frame dimensions\n",
    "        T: int\n",
    "            number of frames\n",
    "    Raises:\n",
    "        Exception \"Unknown file extension\"\n",
    "    \"\"\"\n",
    "    if ('.mmap' in filename):\n",
    "        # Strip path components and use CAIMAN_DATA/example_movies\n",
    "        # TODO: Eventually get the code to save these in a different dir\n",
    "        file_to_load = filename\n",
    "        filename = os.path.split(filename)[-1]\n",
    "        fpart = filename.split('_')[1:-1] # The filename encodes the structure of the map\n",
    "        d1, d2, d3, T, order = int(fpart[-9]), int(fpart[-7]\n",
    "                                                   ), int(fpart[-5]), int(fpart[-1]), fpart[-3]\n",
    "        Yr = np.memmap(file_to_load, mode=mode, shape=prepare_shape((\n",
    "            d1 * d2 * d3, T)), dtype=np.float32, order=order)\n",
    "        return (Yr, (d1, d2), T) if d3 == 1 else (Yr, (d1, d2, d3), T)\n",
    "    else:\n",
    "        logging.error(\"Unknown extension for file \" + str(filename))\n",
    "        raise Exception('Unknown file extension (should be .mmap)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# verify good alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postfix_gcamp, header = nrrd.read(directory+\"warped/postfix_gcamp.nrrd\")\n",
    "sumZ_postfix = postfix_gcamp.sum(0)\n",
    "\n",
    "isosbestic_gcamp, header = nrrd.read(directory+\"f10542_alive_isosbestic_gcamp_0004.nrrd\")\n",
    "sumZ_isosbestic = isosbestic_gcamp.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postfix_gad, header = nrrd.read(directory+\"warped/postfix_gad.nrrd\")\n",
    "sumZ_gad = postfix_gad.sum(0)\n",
    "postfix_vglut, header = nrrd.read(directory+\"warped/postfix_vglut.nrrd\")\n",
    "sumZ_vglut = postfix_vglut.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(sumZ_postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(sumZ_isosbestic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(sumZ_vglut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(sumZ_gad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxT_sumZ_plane = None\n",
    "for z,pfile in enumerate(planes):\n",
    "    Yr, dims, T = load_memmap(pfile)\n",
    "    plane = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "    if maxT_sumZ_plane is None:\n",
    "        maxT_sumZ_plane = plane.sum(axis=0)\n",
    "    else:\n",
    "        maxT_sumZ_plane += plane.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(maxT_sumZ_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop so no nan\n",
    "midH = maxT_sumZ_plane.shape[0]/2\n",
    "midW = maxT_sumZ_plane.shape[1]/2\n",
    "corners = np.zeros([4,2],dtype=int) # counter-clockwise\n",
    "corners[1] = [maxT_sumZ_plane.shape[0]-1,0]\n",
    "corners[2] = [maxT_sumZ_plane.shape[0]-1,maxT_sumZ_plane.shape[1]-1]\n",
    "corners[3] = [0,maxT_sumZ_plane.shape[1]-1]\n",
    "\n",
    "# find reasonable bounding box\n",
    "i = 0\n",
    "while np.isnan(maxT_sumZ_plane[corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]].sum()):\n",
    "    corners[0] += 1\n",
    "    corners[1,0] -= 1\n",
    "    corners[1,1] += 1\n",
    "    corners[2] -= 1\n",
    "    corners[3,0] += 1\n",
    "    corners[3,1] -= 1\n",
    "    i+= 1\n",
    "    if i> 500:\n",
    "        print(\"oops\")\n",
    "        break\n",
    "print(\"sum\", maxT_sumZ_plane[corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]].sum())\n",
    "\n",
    "# TODO improve by adjusting x,y on corner-by-corner basis\n",
    "\n",
    "# Create figure and axes\n",
    "fig,ax = plt.subplots(1)\n",
    "\n",
    "# Display the image\n",
    "ax.matshow(maxT_sumZ_plane)\n",
    "\n",
    "# Create largest Rectangle patch within corners\n",
    "rect_y = max(corners[0,0],corners[3,0])\n",
    "rect_x = max(corners[0,1],corners[1,1])\n",
    "rect_H = min(corners[1,0]-corners[0,0], corners[2,0]-corners[3,0])\n",
    "rect_W = min(corners[3,1]-corners[0,1], corners[2,1]-corners[1,1])\n",
    "# make even for resizing\n",
    "if rect_H % 2 == 1:\n",
    "    rect_H -= 1\n",
    "if rect_W % 2 == 1:\n",
    "    rect_W -= 1\n",
    "# make all four corners on rectangle\n",
    "corners = np.array([ [rect_y,rect_x], [rect_y+rect_H, rect_x], [rect_y+rect_H, rect_x+rect_W], [rect_y, rect_x+rect_W] ])\n",
    "print(\"rect\",[rect_x,rect_y,rect_H, rect_W])\n",
    "# flip for viz\n",
    "rect = patches.Rectangle([rect_x, rect_y],rect_W,rect_H,linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "# Add the patch to the Axes\n",
    "ax.add_patch(rect)\n",
    "    \n",
    "# plt.figure()\n",
    "# plt.scatter(*np.where(np.isnan(maxT_plane)))\n",
    "ax.scatter(corners[:,1], corners[:,0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(maxT_sumZ_plane[corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxT_sumZ_crop = maxT_sumZ_plane[corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save corners\n",
    "np.save(directory+\"/cnmf/corners.npy\", corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find xy shift\n",
    "TODO: right now does no shift..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image(image, H, W):\n",
    "    try:\n",
    "        assert image.shape[0] <= H and image.shape[1] <= W\n",
    "    except Exception as e:\n",
    "        print(\"H ({}) and W ({}) must be less than {} and {}\".format(H, W, image.shape[0], image.shape[1]))\n",
    "        raise e\n",
    "    new_image = np.zeros([H,W])\n",
    "    if image.shape[0]==H:\n",
    "        pad_top = False\n",
    "    else:\n",
    "        pad_top = int(np.ceil((H-image.shape[0])/2))\n",
    "        pad_bottom = int(np.floor((H-image.shape[0])/2))\n",
    "    if image.shape[0]==W:\n",
    "        pad_left = False\n",
    "    else:\n",
    "        pad_left = int(np.ceil((W-image.shape[1])/2))\n",
    "        pad_right = int(np.floor((W-image.shape[1])/2))\n",
    "    if not pad_left and not pad_top:\n",
    "        return image\n",
    "    elif pad_left and not pad_top:\n",
    "        new_image[:,pad_left:(-pad_right)] = image\n",
    "    elif pad_top and not pad_left:\n",
    "        new_image[pad_top:(-pad_bottom),:] = image\n",
    "    else:\n",
    "        new_image[pad_top:(-pad_bottom),pad_left:(-pad_right)] = image\n",
    "    return new_image.astype(np.float32)\n",
    "\n",
    "def crop_image(image, H, W):\n",
    "    try:\n",
    "        assert image.shape[0] >= H and image.shape[1] >= W\n",
    "    except Exception as e:\n",
    "        print(\"H ({}) and W ({}) must be less than {} and {}\".format(H, W, image.shape[0], image.shape[1]))\n",
    "        raise e\n",
    "    new_image = np.zeros([H,W])\n",
    "    if image.shape[0]==H:\n",
    "        crop_top = False\n",
    "    else:\n",
    "        crop_top = int(np.ceil((image.shape[0]-H)/2))\n",
    "        crop_bottom = int(np.floor((image.shape[0]-H)/2))\n",
    "    if image.shape[0]==W:\n",
    "        crop_left = False\n",
    "    else:\n",
    "        crop_left = int(np.ceil((image.shape[1]-W)/2))\n",
    "        crop_right = int(np.floor((image.shape[1]-W)/2))\n",
    "    if not crop_left and not crop_top:\n",
    "        return image\n",
    "    elif crop_left and not crop_top:\n",
    "        new_image = image[:,crop_left:(-crop_right)]\n",
    "    elif crop_top and not crop_left:\n",
    "        new_image = image[crop_top:(-crop_bottom),:]\n",
    "    else:\n",
    "        new_image = image[crop_top:(-crop_bottom),crop_left:(-crop_right)]\n",
    "    return new_image.astype(np.float32)\n",
    "\n",
    "\n",
    "def pad_volume(image, H, W):\n",
    "    # this should be ND...\n",
    "    try:\n",
    "        assert image.shape[1] <= H and image.shape[2] <= W\n",
    "    except Exception as e:\n",
    "        print(\"H ({}) and W ({}) must be less than {} and {}\".format(H, W, image.shape[1], image.shape[2]))\n",
    "        raise e\n",
    "    new_image = np.zeros([image.shape[0], H,W])\n",
    "    if image.shape[1]==H:\n",
    "        pad_top = False\n",
    "    else:\n",
    "        pad_top = int(np.ceil((H-image.shape[1])/2))\n",
    "        pad_bottom = int(np.floor((H-image.shape[1])/2))\n",
    "    if image.shape[1]==W:\n",
    "        pad_left = False\n",
    "    else:\n",
    "        pad_left = int(np.ceil((W-image.shape[2])/2))\n",
    "        pad_right = int(np.floor((W-image.shape[2])/2))\n",
    "    if not pad_left and not pad_top:\n",
    "        return image\n",
    "    elif pad_left and not pad_top:\n",
    "        new_image[:, :,pad_left:(-pad_right)] = image\n",
    "    elif pad_top and not pad_left:\n",
    "        new_image[:, pad_top:(-pad_bottom),:] = image\n",
    "    else:\n",
    "        new_image[:, pad_top:(-pad_bottom),pad_left:(-pad_right)] = image\n",
    "    return new_image.astype(np.float32)\n",
    "\n",
    "def norm01(a):\n",
    "    return (a-a.min())/a.max()\n",
    "\n",
    "# def shift_image(a,dW,dH):\n",
    "#     new_a = np.zeros(*a.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_functional = pad_image(norm01(maxT_sumZ_crop),352,512)\n",
    "percent = 80\n",
    "pad_functional[pad_functional>np.percentile(pad_functional,percent)] = np.percentile(pad_functional,percent)\n",
    "norm_postfix = norm01(sumZ_postfix)\n",
    "norm_postfix[norm_postfix>np.percentile(norm_postfix,percent)] = np.percentile(norm_postfix,percent)\n",
    "equalized_postfix = norm_postfix/norm_postfix.sum()*1.25*pad_functional.sum()\n",
    "plt.matshow(np.hstack([pad_functional,equalized_postfix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "H, W = sumZ_postfix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad_image(norm01(maxT_sumZ_crop),352,512)\n",
    "MI = {k: mutual_information(pad_functional,np.roll(equalized_postfix,k)) for k in product(range(-10,10),range(-10,10))}\n",
    "print(sorted(list(MI.values()),reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "func2D = pad_image(maxT_sumZ_crop,H, W)\n",
    "fix2D = sumZ_postfix\n",
    "MI = {k: mutual_information(func2D,np.roll(fix2D,k)) for k in product(range(-10,10),range(-10,10))}\n",
    "print(sorted(list(MI.values()),reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = np.zeros([*pad_functional.shape, 3])\n",
    "mix[:,:,0] = pad_functional*5\n",
    "norm_postfix = norm01(sumZ_postfix)\n",
    "equalized_postfix = norm_postfix/norm_postfix.sum()*pad_functional.sum()\n",
    "mix[:,:,1] = equalized_postfix*5\n",
    "plt.imshow(mix)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find z matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://matthew-brett.github.io/teaching/mutual_information.html\n",
    "def mutual_information(A, B):\n",
    "    \"\"\" Mutual information for joint histogram\n",
    "    \"\"\"\n",
    "    hgram, x_edges, y_edges = np.histogram2d(A.ravel(), B.ravel(), bins=20) \n",
    "    # Convert bins counts to probability values\n",
    "\n",
    "    pxy = hgram / float(np.sum(hgram))\n",
    "    px = np.sum(pxy, axis=1) # marginal for x over y\n",
    "    py = np.sum(pxy, axis=0) # marginal for y over x\n",
    "    px_py = px[:, None] * py[None, :] # Broadcast to multiply marginals\n",
    "    # Now we can do the calculation using the pxy, px_py 2D arrays\n",
    "    nzs = pxy > 0 # Only non-zero pxy values contribute to the sum\n",
    "    return np.sum(pxy[nzs] * np.log(pxy[nzs] / px_py[nzs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = np.load(directory+\"/cnmf/corners.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0\n",
    "pfile = planes[z]\n",
    "Yr, dims, T = load_memmap(pfile)\n",
    "plane = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "# sumT_pad_crop_plane = pad_volume(plane[:,corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]], H, W).sum(0)\n",
    "sumT_pad_crop_plane = pad_image(plane[:,corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]].sum(0), H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_plane = plane[:,corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]].sum(0)\n",
    "cropH, cropW = crop_plane.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfixedZ = isosbestic_gcamp.shape[0]\n",
    "mi_alive = np.zeros([nZ,nfixedZ])\n",
    "mi_postfix = np.zeros([nZ,nfixedZ])\n",
    "for z in range(nZ):\n",
    "    pfile = planes[z]\n",
    "    Yr, dims, T = load_memmap(pfile)\n",
    "    plane = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "    sumT_crop_plane = plane[:,corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]].sum(0)\n",
    "    for fixedZ in range(nfixedZ):\n",
    "        mi_alive[z,fixedZ] = mutual_information(sumT_crop_plane,crop_image(isosbestic_gcamp[fixedZ],cropH, cropW))\n",
    "        mi_postfix[z,fixedZ] = mutual_information(sumT_crop_plane,crop_image(postfix_gcamp[fixedZ],cropH, cropW))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be ascending with no duplicates\n",
    "matching_alive = np.argmax(mi_alive,axis=1)\n",
    "matching_alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be ascending with no duplicates (messier matching)\n",
    "matching_fixed = np.argmax(mi_postfix,axis=1)\n",
    "matching_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_fixed = np.array([ 18,  22,  28,  33,  38,  43,  48,  54,  60,  65,  70,  75,  80,\n",
    "        85,  91,  96, 101, 106, 112, 117, 122, 126, 130, 136, 140, 144,\n",
    "       150, 156, 160])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save small volume using matching!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane[:,corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_volume\n",
    "# fig,ax = plt.subplots(5,5, figsize=(30,40))\n",
    "i = 0\n",
    "crop_isosbestic_gcamp = []\n",
    "crop_postfix_gcamp = []\n",
    "crop_postfix_gad = []\n",
    "crop_postfix_vglut = []\n",
    "small_imaging = None\n",
    "for z, fixedZ in enumerate(matching_alive):\n",
    "    print(z)\n",
    "    pfile = planes[z]\n",
    "    Yr, dims, T = load_memmap(pfile)\n",
    "    plane = np.reshape(Yr.T, [T] + list(dims), order='F')[:,corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]]\n",
    "    small_plane = resize_volume(plane, 0.5, 0.5)\n",
    "    if small_imaging is None:\n",
    "        small_imaging = np.zeros([small_plane.shape[0], nZ, *small_plane.shape[1:]])\n",
    "    small_imaging[:,z] = small_plane\n",
    "    \n",
    "for z, fixedZ in enumerate(matching_fixed):\n",
    "    crop_isosbestic_gcamp.append(crop_image(isosbestic_gcamp[fixedZ],cropH, cropW))\n",
    "    crop_postfix_gcamp.append(crop_image(postfix_gcamp[fixedZ],cropH, cropW))\n",
    "    crop_postfix_gad.append(crop_image(postfix_gad[fixedZ],cropH, cropW))\n",
    "    crop_postfix_vglut.append(crop_image(postfix_vglut[fixedZ],cropH, cropW))\n",
    "\n",
    "crop_isosbestic_gcamp = resize_volume(np.array(crop_isosbestic_gcamp),0.5,0.5)\n",
    "crop_postfix_gcamp = resize_volume(np.array(crop_postfix_gcamp),0.5,0.5)\n",
    "crop_postfix_gad = resize_volume(np.array(crop_postfix_gad),0.5,0.5)\n",
    "crop_postfix_vglut = resize_volume(np.array(crop_postfix_vglut),0.5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_postfix_gcamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_imaging(imaging, H, W):\n",
    "    try:\n",
    "        assert imaging.shape[2] <= H and imaging.shape[3] <= W\n",
    "    except Exception as e:\n",
    "        print(\"H ({}) and W ({}) must be greater than {} and {}\".format(H, W, imaging.shape[2], imaging.shape[3]))\n",
    "        raise e\n",
    "    new_imaging = np.zeros([imaging.shape[0],imaging.shape[1],H,W])\n",
    "    if imaging.shape[2]==H:\n",
    "        pad_top = False\n",
    "    else:\n",
    "        pad_top = int(np.floor((H-imaging.shape[2])/2))\n",
    "        pad_bottom = int(np.ceil((H-imaging.shape[2])/2))\n",
    "    if imaging.shape[3]==W:\n",
    "        pad_left = False\n",
    "    else:\n",
    "        pad_left = int(np.floor((W-imaging.shape[3])/2))\n",
    "        pad_right = int(np.ceil((W-imaging.shape[3])/2))\n",
    "        \n",
    "    if not pad_right and not pad_bottom:\n",
    "        return imaging\n",
    "    elif pad_right and not pad_bottom:\n",
    "        new_imaging[:,:,:,pad_left:(-pad_right)] = imaging\n",
    "    elif pad_bottom and not pad_right:\n",
    "        new_imaging[:,:,pad_top:(-pad_bottom),:] = imaging\n",
    "    else:\n",
    "        new_imaging[:,:,pad_top:(-pad_bottom),pad_left:(-pad_right)] = imaging\n",
    "    return new_imaging.astype(np.float32)\n",
    "\n",
    "def pad_volume(image, H, W):\n",
    "    # this should be ND...\n",
    "    try:\n",
    "        assert image.shape[1] <= H and image.shape[2] <= W\n",
    "    except Exception as e:\n",
    "        print(\"H ({}) and W ({}) must be less than {} and {}\".format(H, W, image.shape[1], image.shape[2]))\n",
    "        raise e\n",
    "    new_image = np.zeros([image.shape[0], H,W])\n",
    "    if image.shape[1]==H:\n",
    "        pad_top = False\n",
    "    else:\n",
    "        pad_top = int(np.floor((H-image.shape[1])/2))\n",
    "        pad_bottom = int(np.ceil((H-image.shape[1])/2))\n",
    "    if image.shape[1]==W:\n",
    "        pad_left = False\n",
    "    else:\n",
    "        pad_left = int(np.floor((W-image.shape[2])/2))\n",
    "        pad_right = int(np.ceil((W-image.shape[2])/2))\n",
    "        \n",
    "#     print(pad_top,pad_bottom, pad_left, pad_right)\n",
    "    if not pad_right and not pad_bottom:\n",
    "        return image\n",
    "    elif pad_right and not pad_bottom:\n",
    "        new_image[:, :,pad_left:(-pad_right)] = image\n",
    "    elif pad_bottom and not pad_right:\n",
    "        new_image[:, pad_top:(-pad_bottom),:] = image\n",
    "    else:\n",
    "        new_image[:, pad_top:(-pad_bottom),pad_left:(-pad_right)] = image\n",
    "    return new_image.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_small_imaging = pad_imaging(small_imaging,256,256)\n",
    "pad_small_imaging.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_isosbestic_gcamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_isosbestic_gcamp = pad_volume(crop_isosbestic_gcamp,256,256)\n",
    "pad_postfix_gcamp = pad_volume(crop_postfix_gcamp,256,256)\n",
    "pad_postfix_gad = pad_volume(crop_postfix_gad,256,256)\n",
    "pad_postfix_vglut = pad_volume(crop_postfix_vglut,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_postfix_gcamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{directory}/cnmf/functional.npy\", pad_small_imaging)\n",
    "np.save(f\"{directory}/cnmf/isosbestic_gcamp.npy\",\n",
    "    pad_isosbestic_gcamp)\n",
    "np.save(f\"{directory}/cnmf/postfix_gcamp.npy\",\n",
    "    pad_postfix_gcamp)\n",
    "np.save(f\"{directory}/cnmf/postfix_gad.npy\",\n",
    "    pad_postfix_gad)\n",
    "np.save(f\"{directory}/cnmf/postfix_vglut.npy\",\n",
    "    pad_postfix_vglut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_isosbestic_gcamp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_small_imaging.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pad_isosbestic_gcamp[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pad_small_imaging[0,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(small_imaging[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_isosbestic_gcamp[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=27\n",
    "pfile = planes[z]\n",
    "Yr, dims, T = load_memmap(pfile)\n",
    "plane = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "# sumT_pad_crop_plane = pad_volume(plane[:,corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]], H, W).sum(0)\n",
    "sumT_pad_crop_plane = pad_image(plane[:,corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]].sum(0), H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3, figsize=(20,10))\n",
    "ax[0].matshow(sumT_pad_crop_plane)\n",
    "ax[1].matshow(postfix_gcamp[150])\n",
    "ax[2].matshow(postfix_gcamp[155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfixedZ = isosbestic_gcamp.shape[0]\n",
    "mi_alive = np.zeros([nZ,nfixedZ])\n",
    "mi_postfix = np.zeros([nZ,nfixedZ])\n",
    "for z in range(nZ):\n",
    "    pfile = planes[z]\n",
    "    Yr, dims, T = load_memmap(pfile)\n",
    "    plane = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "    # sumT_pad_crop_plane = pad_volume(plane[:,corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]], H, W).sum(0)\n",
    "    sumT_pad_crop_plane = pad_image(plane[:,corners[0,0]:corners[1,0],corners[0,1]:corners[3,1]].sum(0), H, W)\n",
    "    for fixedZ in range(nfixedZ):\n",
    "        mi_alive[z,fixedZ] = mutual_information(sumT_pad_crop_plane,isosbestic_gcamp[fixedZ])\n",
    "        mi_postfix[z,fixedZ] = mutual_information(sumT_pad_crop_plane,postfix_gcamp[fixedZ])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffH = postfix_gcamp.shape[1]-maxT_plane.shape[0]\n",
    "diffW = postfix_gcamp.shape[2]-maxT_plane.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halfH = int(diffH/2)\n",
    "post_crop = postfix_gcamp[:,halfH:-halfH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_crop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = np.zeros([*alive[100].shape, 3])\n",
    "mix[:,:,0] = (alive[100]-alive[100].min())/alive[100].max()\n",
    "mix[:,:,1] = (post_gcamp[100]-post_gcamp[100].min())/post_gcamp[100].max()\n",
    "plt.imshow(mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(maxT_plane)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(post_crop[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_information(maxT_plane, post_crop[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfixedZ = postfix_gcamp.shape[0]\n",
    "mi = np.zeros(nfixedZ)\n",
    "for fixedZ in range(nfixedZ):\n",
    "    mi[fixedZ] = mutual_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_images = None\n",
    "for z,pfile in enumerate(planes):\n",
    "    pfile = planes[z]\n",
    "    Yr, dims, T = load_memmap(pfile)\n",
    "    plane = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "    small_plane = resize_volume(plane, 0.5, 0.5)\n",
    "    if small_images is None:\n",
    "        # T x H x W\n",
    "        shape = small_plane.shape\n",
    "        small_images = np.zeros([shape[0],nZ,*shape[1:]])\n",
    "\n",
    "    small_images[:,z] = small_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(small_images[110,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(small_images[110,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[109])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory, fname = os.path.split(file_path)\n",
    "name, ext = os.path.splitext(file_path)\n",
    "name, ext2 = os.path.splitext(name)\n",
    "ext = ext + ext2\n",
    "tiff = tifffile.imread(file_path,)\n",
    "\n",
    "# Z x T? x C? x X x Y\n",
    "# where ? is optional and T is retakes (\"time\") and C is channel eg gad or vglut\n",
    "tiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alive, header = nrrd.read(directory+\"f10542_alive_isosbestic_gcamp_0004.nrrd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
