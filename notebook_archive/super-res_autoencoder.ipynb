{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from torchvision.transforms import Resize\n",
    "import dill\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "\n",
    "import os, sys, datetime\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "f = all_data['e'][2]\n",
    "\n",
    "time_fish = T.from_numpy(f.frame_st.mean(1).astype(np.float32)).cuda()\n",
    "u_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "p_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "u_fish[numpy.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_from_z(z, fish):\n",
    "    tiff = fish.get_tif_rasl(z)\n",
    "    ntime = fish.frame_et.shape[0]\n",
    "    frames = np.zeros((ntime, tiff.frame_shape[0],tiff.frame_shape[1])).astype(np.float32)\n",
    "    for t in range(ntime):\n",
    "        frame = np.array(tiff.get_frame(t)).astype(np.float32)\n",
    "        frames[t] = frame\n",
    "    return frames\n",
    "\n",
    "def get_imaging_from_fish(f,n_jobs=8):\n",
    "    nZ = f.num_zplanes\n",
    "    # frames_by_z = pool.map(partial(get_frames_from_z, fish=f), range(nZ))\n",
    "    frames_by_z = Parallel(n_jobs=n_jobs)(delayed(get_frames_from_z)(z,fish=f) for z in range(nZ))\n",
    "    imaging = np.stack(frames_by_z).swapaxes(0,1).astype(np.float32)\n",
    "    return imaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_volume(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    new[0] = im\n",
    "    for i, img in enumerate(images[1:]):\n",
    "        new[i] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new\n",
    "\n",
    "def resize_batch(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0,0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],images.shape[1], im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    for b, vol in enumerate(images):\n",
    "        for z, img in enumerate(vol):\n",
    "            new[b,z] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging = get_imaging_from_fish(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishImageData(Dataset):    \n",
    "    def __init__(self, imaging):\n",
    "        self.data = T.from_numpy(imaging)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data[idx+1]\n",
    "\n",
    "data = FishImageData(imaging)\n",
    "batch_size = 64\n",
    "nZ, H, W = data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nZ, H,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import factorint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorint(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorint(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "512/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data[0]\n",
    "F.mse_loss(x.cuda(),y.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data[0]\n",
    "F.mse_loss(x.cuda(),T.zeros_like(x.cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_vs_real(model,data):\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    with T.no_grad():\n",
    "        for i in range(4):\n",
    "            time = np.random.randint(len(data))\n",
    "            z = np.random.randint(nZ)\n",
    "            X, Y = data[time]\n",
    "            x = X.cuda()\n",
    "            y = Y.cuda()\n",
    "            X_pred = model(x[None,:,None])\n",
    "            loss = float(F.mse_loss(X_pred[0],y).cpu())\n",
    "            prev_loss = float(F.mse_loss(x,y).cpu())\n",
    "            zero_loss = float(F.mse_loss(X_pred[0],T.zeros_like(X_pred[0])).cpu())\n",
    "            mymax = max(Y[0,z].max()[0],X[0,z].max()[0],[0,z]\n",
    "            plt.subplot(4,3,i*3+1)\n",
    "            plt.imshow(X[0].cpu().numpy())\n",
    "            plt.title(\"Time=\"+str(time) + \", z=\"+str(z))\n",
    "            plt.subplot(4,3,i*3+2)\n",
    "            plt.imshow(Y[0].cpu().numpy())\n",
    "            plt.title(\"Time=\"+str(time+1) + \", z=\"+str(z))\n",
    "            plt.subplot(4,3,i*3+3)\n",
    "            plt.imshow(X_pred[0,0].cpu().numpy())\n",
    "            plt.title(\"Pred={:.0f}, Prev={:.0f}, Zero={:.0f}\".format(loss,prev_loss,zero_loss))\n",
    "            print(X_pred[0,0].max(),Y[0].max(),X[0].max())\n",
    "plot_model_vs_real(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(padding_type, kernel_size):\n",
    "    assert padding_type in ['SAME', 'VALID']\n",
    "    if padding_type == 'SAME':\n",
    "        return tuple((k - 1) // 2 for k in kernel_size)\n",
    "    return tuple(0 for _ in kernel_size)\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, nZ=11, H=232, W=512, nEmbedding=20):\n",
    "        super(Conv, self).__init__()\n",
    "        self.nZ = nZ\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        # batch x channel x Z x H x W\n",
    "        # Encoding\n",
    "        self.conv1 = nn.Parameter(T.cuda.FloatTensor(8,1,9,9))\n",
    "#         self.conv1 = nn.Conv2d(1,1,1,9,9)\n",
    "        self.pad1 = get_padding('SAME',(9,9))\n",
    "        self.activation = nn.ReLU()\n",
    "        self.conv2 = nn.Parameter(T.cuda.FloatTensor(16,8,9,9))\n",
    "        self.pad2 = get_padding('SAME',(9,9))\n",
    "        # b x 11 x 32 x 11 x 25\n",
    "        self.encoding = nn.Linear(nZ*12*26, nEmbedding, bias=False)\n",
    "        \n",
    "        # Decoding (super resolution)\n",
    "        # https://arxiv.org/pdf/1609.05158.pdf\n",
    "        upscale_factor = 22\n",
    "        self.dconv1 = nn.Parameter(T.cuda.FloatTensor(64,16,5,5))\n",
    "        self.dpad1 = (2,2)\n",
    "        self.dconv2 = nn.Parameter(T.cuda.FloatTensor(64,64,3,3))\n",
    "        self.dpad2 = (1,1)\n",
    "        self.dconv3 = nn.Parameter(T.cuda.FloatTensor(32,64,3,3))\n",
    "        self.dpad3 = (1,1)\n",
    "        self.dconv4 = nn.Parameter(T.cuda.FloatTensor(upscale_factor**2,32,3,3))\n",
    "        self.dpad4 = (1,1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "                \n",
    "    def vol_conv(self, x, weight, pad):\n",
    "        # batch x Z x C x H x W\n",
    "        activations = T.cuda.FloatTensor(x.shape[0],x.shape[1],weight.shape[0],x.shape[3],x.shape[4])\n",
    "        for z in range(x.shape[1]):\n",
    "            activations[:,z] = F.conv2d(x[:,z], weight, padding=pad)\n",
    "        return activations\n",
    "    \n",
    "    def vol_MaxPool2d(self, x, kernel_size):\n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def vol_PixelShuffle(self, x):\n",
    "        first = self.pixel_shuffle(x[:,0])\n",
    "        # b x z x H x W\n",
    "        ret = T.cuda.FloatTensor(x.shape[0],x.shape[1],first.shape[2], first.shape[3])\n",
    "        for z in range(x.shape[1]):\n",
    "            ret[:,z] = self.pixel_shuffle(x[:,z])[:,0]\n",
    "        return ret\n",
    "        \n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # b x 11 x 1 x 232 x 512\n",
    "        x = self.activation(self.vol_MaxPool2d(self.vol_conv(x, self.conv1, self.pad1),4))\n",
    "        # b x 11 x 8 x 58 x 128\n",
    "        x = self.activation(self.vol_MaxPool2d(self.vol_conv(x, self.conv2, self.pad2),5))\n",
    "        # b x 11 x 32 x 11 x 25\n",
    "        return x\n",
    "    \n",
    "    def crop(self, x):\n",
    "        cropH = (x.shape[2] - self.H)/2\n",
    "        cropW = (x.shape[3] - self.W)/2\n",
    "        x = x[:,:,int(np.floor(cropH)):-int(np.ceil(cropH))]\n",
    "        x = x[:,:,:,int(np.floor(cropW)):-int(np.ceil(cropW))]\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = self.activation(self.vol_conv(x, self.dconv1, self.dpad1))\n",
    "        x = self.activation(self.vol_conv(x, self.dconv2, self.dpad2))\n",
    "        x = self.activation(self.vol_conv(x, self.dconv3, self.dpad3))\n",
    "        x = self.vol_PixelShuffle(self.vol_conv(x, self.dconv4, self.dpad4))\n",
    "        return self.crop(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return decoded\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        nn.init.orthogonal_(self.conv1, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.conv2, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv1, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv2, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv3, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv4, nn.init.calculate_gain('relu'))\n",
    "\n",
    "\n",
    "# def train(model,data,nepochs=10, lambdaA=(1e-8, 1e-6), lambdaB=(1e-6, 1e-6),\n",
    "#           lambdaC=(1e-5, 1e-5), lambdaD=(1e-5, 1e-5), lr=0.1, verbose=True):\n",
    "def train(model,data,nepochs=10, lr=0.1):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "    \n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        for batch_data in dataloader:\n",
    "            X, Y = batch_data\n",
    "            # add 1 channel\n",
    "            Y_pred = model(X[:,:,None].cuda())\n",
    "            loss = F.mse_loss(Y_pred,Y.cuda())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "\n",
    "        print(\"avg_loss: {:3E}\".format(cum_loss/len(data)))\n",
    "\n",
    "nEmbedding = 20\n",
    "batch_size = 64\n",
    "nZ, H, W = data[0][0].shape\n",
    "\n",
    "conv_model = Conv(nZ,H,W,nEmbedding)\n",
    "conv_model.cuda()\n",
    "# conv_model(data[0][0][None,:,None].cuda()).shape\n",
    "train(conv_model,data,25,lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.00E+1\n",
    "plot_model_vs_real(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "21**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total num params:\", np.sum([np.prod(x.shape) for x in conv_model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D\n",
    "class SuperRes(nn.Module):\n",
    "    def __init__(self, upscale_factor):\n",
    "        super(SuperRes, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        nn.init.orthogonal_(self.conv1.weight, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.conv2.weight, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.conv3.weight, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.conv4.weight)\n",
    "        \n",
    "def train(model,data,nepochs=10, lr=0.1, batch_size=32):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "    \n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        for batch_data in dataloader:\n",
    "            X, _ = batch_data\n",
    "            X = X.reshape(-1,X.shape[2],X.shape[3])\n",
    "            x = T.from_numpy(resize_volume(X.numpy(),0.25,0.25)).cuda()[:,None]\n",
    "            X_pred = model(x)\n",
    "            loss = F.mse_loss(X_pred[:,0],X.cuda())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "\n",
    "        print(\"avg_loss: {:3E}\".format(cum_loss/len(data)))\n",
    "    with T.no_grad():\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.imshow(X_pred[0,0].cpu().numpy())\n",
    "        plt.subplot(2,1,2)\n",
    "        plt.imshow(X[0].cpu().numpy())\n",
    "\n",
    "super_res = SuperRes(4)\n",
    "super_res.cuda()\n",
    "batch_size = 64\n",
    "train(super_res,data,10,lr=1e-3, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, nZ, H, W, nHidden=100, nEmbedding=20):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(nZ*H*W, 100)\n",
    "        self.fc21 = nn.Linear(100, nEmbedding)\n",
    "        self.fc22 = nn.Linear(100, nEmbedding)\n",
    "        self.fc3 = nn.Linear(nEmbedding, 100)\n",
    "        self.fc4 = nn.Linear(100, nZ*H*W)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.reshape(x.shape[0],-1))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z).reshape(x.shape), mu, logvar\n",
    "\n",
    "    \n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.cross_entropy(recon_x, x, size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD\n",
    "\n",
    "def train(model,data,nepochs=10, lr=0.1):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "    \n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        for batch_data in dataloader:\n",
    "            X, Y = batch_data\n",
    "            x = X.cuda()\n",
    "            recon_batch, mu, logvar = model(x)\n",
    "            print(recon_batch.dtype,x.dtype)\n",
    "            loss = loss_function(recon_batch, x, mu, logvar)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            cum_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "\n",
    "        print(\"avg_loss: {:3E}\".format(cum_loss/len(data)))\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(64, 20).to(device)\n",
    "            sample = model.decode(sample).cpu()\n",
    "            save_image(sample.view(64, 1, 28, 28),\n",
    "                       'results/sample_' + str(epoch) + '.png')\n",
    "\n",
    "# def train(epoch):\n",
    "#     model.train()\n",
    "#     train_loss = 0\n",
    "#     for batch_idx, (data, _) in enumerate(train_loader):\n",
    "#         data = data.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         recon_batch, mu, logvar = model(data)\n",
    "#         loss = loss_function(recon_batch, data, mu, logvar)\n",
    "#         loss.backward()\n",
    "#         train_loss += loss.item()\n",
    "#         optimizer.step()\n",
    "#         if batch_idx % log_interval == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader),\n",
    "#                 loss.item() / len(data)))\n",
    "\n",
    "#     print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "#           epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "# def test(epoch):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for i, (data, _) in enumerate(test_loader):\n",
    "#             data = data.to(device)\n",
    "#             recon_batch, mu, logvar = model(data)\n",
    "#             test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "#             if i == 0:\n",
    "#                 n = min(data.size(0), 8)\n",
    "#                 comparison = torch.cat([data[:n],\n",
    "#                                       recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
    "#                 save_image(comparison.cpu(),\n",
    "#                          'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "#     print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "model = VAE(nZ,H,W,64,16)\n",
    "model.cuda()\n",
    "\n",
    "train(model,data, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with T.no_grad():\n",
    "    X, Y = data[0]\n",
    "    Y_pred = model(X.cuda()[None])\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(Y_pred[0,6].cpu().numpy())\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(Y[6].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(nn.Module):\n",
    "    def __init__(self, nZ, H, W, nEmbedding):\n",
    "        super(Dense, self).__init__()\n",
    "        self.Dense1 = nn.Linear(nZ*H*W,nEmbedding, bias=False)\n",
    "        self.Dense2 = nn.Linear(nEmbedding,nZ*H*W, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = F.relu(self.Dense1(x.reshape(x.shape[0],-1)))\n",
    "        decoded = self.Dense2(encoded)\n",
    "        return decoded.reshape(x.shape)\n",
    "\n",
    "    \n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, nZ, H, W, nEmbedding):\n",
    "        super(Dense, self).__init__()\n",
    "        self.Dense1 = nn.Conv2d()\n",
    "        self.Dense2 = nn.Linear(nEmbedding,nZ*H*W, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.Dense1(x.reshape(x.shape[0],-1))\n",
    "        decoded = self.Dense2(encoded)\n",
    "        return decoded.reshape(x.shape)\n",
    "\n",
    "    \n",
    "# def train(model,data,nepochs=10, lambdaA=(1e-8, 1e-6), lambdaB=(1e-6, 1e-6),\n",
    "#           lambdaC=(1e-5, 1e-5), lambdaD=(1e-5, 1e-5), lr=0.1, verbose=True):\n",
    "def train(model,data,nepochs=10, lr=0.1):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "    \n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        for batch_data in dataloader:\n",
    "            X, Y = batch_data\n",
    "            Y_pred = model(X.cuda())\n",
    "            loss = F.mse_loss(Y_pred,X.cuda())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "\n",
    "        print(\"avg_loss: {:3E}\".format(cum_loss/len(data)))\n",
    "\n",
    "nEmbedding = 20\n",
    "batch_size = 64\n",
    "nZ, H, W = data[0][0].shape\n",
    "\n",
    "dense_model = Dense(nZ,H,W,nEmbedding)\n",
    "dense_model.cuda()\n",
    "\n",
    "train(dense_model,data,10,lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fish = data.data.mean(0)\n",
    "min_fish = data.data.min(0)[0]\n",
    "\n",
    "max_fish = data.data.max(0)[0]\n",
    "\n",
    "var_fish = data.data.var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imaging[0,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imaging[0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(max_fish[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mean_fish[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(min_fish[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imaging[0,6,180:220,180:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(var_fish[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data.data[0:400].mean(0)[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data.data[2000:2400].mean(0)[6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
