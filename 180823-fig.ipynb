{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(i) for i in [0, 1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from torchvision.transforms import Resize\n",
    "import dill\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "import resource\n",
    "import apex # https://github.com/NVIDIA/apex.git\n",
    "from apex.amp import amp\n",
    "\n",
    "import os, sys, datetime\n",
    "import itertools\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = False\n",
    "# gen = True\n",
    "cuda=True\n",
    "# cnmf=True\n",
    "cnmf=False\n",
    "half=True\n",
    "half=False\n",
    "multi_gpu = True\n",
    "num_workers = 16\n",
    "prev_frames = 5\n",
    "next_frames = 5\n",
    "\n",
    "f = all_data['e'][2]\n",
    "\n",
    "frame_times = T.from_numpy(f.frame_st.mean(1).astype(np.float32))\n",
    "shocks = T.FloatTensor(frame_times.shape).zero_()\n",
    "shocks[numpy.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1\n",
    "\n",
    "tail_movements = T.FloatTensor(frame_times.shape).zero_()\n",
    "tail_movements[numpy.searchsorted(f.frame_et[:,-1],\n",
    "    f.tail_movement_start_times,side=\"left\")] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(shocks.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tail_movements.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_from_z(z, fish,half=False):\n",
    "    tiff = fish.get_tif_rasl(z)\n",
    "    ntime = fish.frame_et.shape[0]\n",
    "    if half:\n",
    "        dtype = np.float16\n",
    "    else:\n",
    "        dtype = np.float32\n",
    "    frames = np.zeros((ntime, tiff.frame_shape[0],tiff.frame_shape[1])).astype(dtype)\n",
    "    for t in range(ntime):\n",
    "        frame = np.array(tiff.get_frame(t)).astype(dtype)\n",
    "        frames[t] = frame\n",
    "    return frames\n",
    "\n",
    "def get_imaging_from_fish(f,n_jobs=8, half=False):\n",
    "    nZ = f.num_zplanes\n",
    "    if half:\n",
    "        dtype = np.float16\n",
    "    else:\n",
    "        dtype = np.float32\n",
    "    # frames_by_z = pool.map(partial(get_frames_from_z, fish=f), range(nZ))\n",
    "    frames_by_z = Parallel(n_jobs=n_jobs)(delayed(get_frames_from_z)(z,fish=f) for z in range(nZ))\n",
    "    imaging = np.stack(frames_by_z).swapaxes(0,1).astype(dtype)\n",
    "    return imaging\n",
    "\n",
    "def gen_imaging(nT, nZ, H, W, half=False):\n",
    "    if half:\n",
    "        dtype = np.float16\n",
    "    else:\n",
    "        dtype = np.float32\n",
    "    return np.random.randint(0,3000,[nT,nZ,H,W]).astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_volume(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    new[0] = im\n",
    "    for i, img in enumerate(images[1:]):\n",
    "        new[i] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new\n",
    "\n",
    "def resize_batch(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0,0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],images.shape[1], im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    for b, vol in enumerate(images):\n",
    "        for z, img in enumerate(vol):\n",
    "            new[b,z] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new\n",
    "\n",
    "def read_cnmf(base_filename, nZ=11):\n",
    "    planes = []\n",
    "    for i in range(1,nZ+1):\n",
    "        plane = np.load(base_filename + \"_plane{}_denoised.mp4.npy\".format(i))\n",
    "        planes.append(plane)\n",
    "    return np.stack(planes,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gen:\n",
    "    imaging = gen_imaging(32,11,232,512)\n",
    "elif cnmf:\n",
    "#     imaging = read_cnmf('/home/ubuntu/f01555')\n",
    "    imaging = np.load('/home/ubuntu/f01555_cnmf_small.npz')['fish']\n",
    "else:\n",
    "#     imaging = get_imaging_from_fish(f)\n",
    "# imaging = resize_batch(imaging,0.5,0.5)\n",
    "# np.savez('/home/ubuntu/f01555.npz',fish=imaging)\n",
    "# np.savez('/home/ubuntu/f01555_small.npz',fish=imaging)\n",
    "#     imaging = np.load('/home/ubuntu/f01555.npz')['fish']\n",
    "    imaging = np.load('/home/ubuntu/f01555_small.npz')['fish']\n",
    "#     imaging = np.load('/home/ubuntu/f01555_medfilt_small.npy')\n",
    "#     fishpath = '/data2/Data/MPzfish/drn_hb/{}/{}_small.npz'.format(f.fishid, f.fishid)\n",
    "#     imaging = np.load(fishpath)['fish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_overlap_idx(startIdx, stopIdx, prev_frames=5, next_frames=5):\n",
    "    start = startIdx + prev_frames -1\n",
    "    stop = stopIdx - next_frames\n",
    "    return list(np.arange(start,stop))\n",
    "    \n",
    "def train_valid_test_split(nIdx, prev_frames=5, next_frames=5, n_per_sample=10, nchunks=3):\n",
    "    \"\"\"Eg 5 prev frames and 5 next frames is n_per_sample=10. No overlap of index.\n",
    "    uses nchunks for validation + nchunks for test\"\"\"\n",
    "    idx_per_chunk = prev_frames+next_frames+n_per_sample - 1\n",
    "    idx_per_train_chunk =int(( nIdx - (idx_per_chunk*2*nchunks) )/(2*nchunks+1))\n",
    "    try:\n",
    "        assert idx_per_chunk*nchunks*2 + idx_per_train_chunk*(2*nchunks+1) <= nIdx\n",
    "    except:\n",
    "        print(\"Need {} indices\".format(idx_per_chunk*nchunks*2 + idx_per_train_chunk*(2*nchunks+1)))\n",
    "        raise\n",
    "    tvt = {\"train\": [], \"validation\": [], \"test\": []}\n",
    "    chunk_start = []\n",
    "    idx = 0\n",
    "    for i in range(nchunks*2):\n",
    "        idx += idx_per_train_chunk\n",
    "        chunk_start.append(idx)\n",
    "        idx += idx_per_chunk\n",
    "    chunk_stop = list(map(lambda start: start+idx_per_chunk, chunk_start))\n",
    "    prev_stop = 0\n",
    "    for i, (start, stop) in enumerate(zip(chunk_start, chunk_stop)):\n",
    "        tvt[\"train\"] += no_overlap_idx(prev_stop, start, prev_frames, next_frames)\n",
    "        if i%2==0:\n",
    "            tvt[\"test\"] += no_overlap_idx(start, stop, prev_frames, next_frames)            \n",
    "        else:\n",
    "            tvt[\"validation\"] += no_overlap_idx(start, stop, prev_frames, next_frames)\n",
    "        prev_stop = stop\n",
    "    tvt[\"train\"] += no_overlap_idx(prev_stop, nIdx, prev_frames, next_frames)\n",
    "    return tvt\n",
    "\n",
    "def train_test_split(nIdx, prev_frames=5, next_frames=5, n_per_sample=10, nchunks=3):\n",
    "    \"\"\"Eg 5 prev frames and 5 next frames is n_per_sample=10. No overlap of index.\n",
    "    uses nchunks for validation + nchunks for test\"\"\"\n",
    "    idx_per_chunk = prev_frames+next_frames+n_per_sample - 1\n",
    "    idx_per_train_chunk =int(( nIdx - (idx_per_chunk*nchunks) )/(2*nchunks+1))\n",
    "    try:\n",
    "        assert idx_per_chunk*nchunks + idx_per_train_chunk*(nchunks+1) <= nIdx\n",
    "    except:\n",
    "        print(\"Need {} indices\".format(idx_per_chunk*nchunks + idx_per_train_chunk*(nchunks+1)))\n",
    "        raise\n",
    "    tvt = {\"train\": [], \"validation\": [], \"test\": []}\n",
    "    chunk_start = []\n",
    "    idx = 0\n",
    "    for i in range(nchunks):\n",
    "        idx += idx_per_train_chunk\n",
    "        chunk_start.append(idx)\n",
    "        idx += idx_per_chunk\n",
    "    chunk_stop = list(map(lambda start: start+idx_per_chunk, chunk_start))\n",
    "    prev_stop = 0\n",
    "    for i, (start, stop) in enumerate(zip(chunk_start, chunk_stop)):\n",
    "        tvt[\"train\"] += no_overlap_idx(prev_stop, start, prev_frames, next_frames)\n",
    "        tvt[\"test\"] += no_overlap_idx(start, stop, prev_frames, next_frames)            \n",
    "        prev_stop = stop\n",
    "    tvt[\"train\"] += no_overlap_idx(prev_stop, nIdx, prev_frames, next_frames)\n",
    "    return tvt\n",
    "\n",
    "# tvt_split = train_valid_test_split(2826, nchunks=20)\n",
    "tvt_split = train_test_split(2826, nchunks=20)\n",
    "total_examples = sum([len(x) for x in tvt_split.values()])\n",
    "print([\"{}: {} ({:.2f}%)\".format(k, len(v), 100*len(v)/total_examples) for k,v in tvt_split.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: memory inefficient for train + validation (duplicates)\n",
    "class ZebraFishData(Dataset):\n",
    "    \"B x nFrames x Z x H x W\"\n",
    "    def __init__(self, imaging_vol, shocks, tail_movements,\n",
    "                 index_map=None, prev_frames=2, next_frames=1):\n",
    "        imaging = np.pad(imaging_vol,((0,0),(0,0),(6,6),(0,0)), 'constant', constant_values=(0,0))\n",
    "        data = imaging - imaging.mean(0)\n",
    "        # use channel for future / prev frames\n",
    "        self.data = T.from_numpy(data)\n",
    "        self.prev_frames = prev_frames\n",
    "        self.next_frames = next_frames\n",
    "        self.shocks = shocks\n",
    "        self.tail_movements = tail_movements\n",
    "        self.index_map = index_map\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.index_map:\n",
    "            return len(self.index_map)\n",
    "        else:\n",
    "            return self.data.shape[0]-self.prev_frames - self.next_frames + 1\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.index_map:\n",
    "            idx = self.index_map[i]\n",
    "        else:\n",
    "            idx = i + self.prev_frames - 1 # avoid wraparound\n",
    "        X = {\"brain\": [], \"shock\": [], \"tail_movement\": []}\n",
    "        Y = {\"brain\": [], \"shock\": [], \"tail_movement\": []}\n",
    "        for i in reversed(range(self.prev_frames)):\n",
    "            ix = idx-i\n",
    "            X[\"brain\"].append(self.data[ix])\n",
    "            X[\"shock\"].append(self.shocks[ix])\n",
    "            X[\"tail_movement\"].append(self.tail_movements[ix])\n",
    "        for i in range(1,self.next_frames+1):\n",
    "            ix = idx+i\n",
    "            Y[\"brain\"].append(self.data[ix])\n",
    "            Y[\"shock\"].append(self.shocks[ix])\n",
    "            Y[\"tail_movement\"].append(self.tail_movements[ix])\n",
    "        X = {k: T.stack(v,0) for k,v in X.items()}\n",
    "        Y = {k: T.stack(v,0) for k,v in Y.items()}\n",
    "        return X, Y\n",
    "\n",
    "train_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        tvt_split['train'], prev_frames,next_frames)\n",
    "\n",
    "# valid_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "#                         tvt_split['validation'], prev_frames,next_frames)\n",
    "\n",
    "test_data = ZebraFishData(imaging,shocks,tail_movements,\n",
    "                        tvt_split['test'], prev_frames,next_frames)\n",
    "\n",
    "_, nZ, H, W = train_data[0][0][\"brain\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_schedule(t,k=5):\n",
    "    t0 = t/2\n",
    "    k = k/t0\n",
    "    t = np.arange(t)\n",
    "    return (1/(1+np.exp(-k*(t-t0)))).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, prev_frames=1):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(prev_frames, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "#         self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1) # for full-size images\n",
    "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, layers[3], stride=2)\n",
    "#         self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "#         self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 232 x 512\n",
    "        x = self.conv1(x)\n",
    "#         print(\"conv1\", x.shape)\n",
    "        x = self.bn1(x)\n",
    "        conv1_out = self.relu(x)\n",
    "        x = self.maxpool(conv1_out)\n",
    "#         print(\"pool1\", x.shape)\n",
    "#         print(x.shape)\n",
    "        # 58 x 128\n",
    "\n",
    "        layer1_out = self.layer1(x)\n",
    "#         print(\"layer1\", x.shape)\n",
    "        # 29 x 64\n",
    "        layer2_out = self.layer2(layer1_out)\n",
    "#         print(\"layer2\", x.shape)\n",
    "        # 15 x 32\n",
    "        layer3_out = self.layer3(layer2_out)\n",
    "#         print(\"layer3\", x.shape)\n",
    "        # 8 x 16\n",
    "        layer4_out = self.layer4(layer3_out)\n",
    "#         print(\"layer4\", x.shape)\n",
    "        # 4 x 8\n",
    "        x = x.view(x.shape[0],-1).mean(1)\n",
    "        # 1 x 1\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "        layer_outputs = {\"conv1_out\": conv1_out, \"layer1_out\": layer1_out,\n",
    "                         \"layer2_out\": layer2_out, \"layer3_out\": layer3_out,\n",
    "                         \"layer4_out\": layer4_out}\n",
    "        return x[:,None], layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(padding_type, kernel_size):\n",
    "    assert padding_type in ['SAME', 'VALID']\n",
    "    if padding_type == 'SAME':\n",
    "        return tuple((k - 1) // 2 for k in kernel_size)\n",
    "    return tuple(0 for _ in kernel_size)\n",
    "\n",
    "\n",
    "class Vol2D(nn.Module):\n",
    "    \"Use same 2D operations mapped over each z slice\"\n",
    "    def __init__(self, tensor=T.cuda.FloatTensor):\n",
    "        super(Vol2D, self).__init__()\n",
    "        self.tensor = tensor\n",
    "        \n",
    "    def vol_PixelShuffle(self, x):\n",
    "        # Helper for subpixel convolution\n",
    "        first = self.pixel_shuffle(x[:,0])\n",
    "        # b x z x H x W\n",
    "        ret = self.tensor(x.shape[0],x.shape[1],first.shape[2], first.shape[3])\n",
    "        for z in range(x.shape[1]):\n",
    "            ret[:,z] = self.pixel_shuffle(x[:,z])[:,0]\n",
    "        return ret\n",
    "        \n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def vol_MaxPool2d(self, x, kernel_size):\n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def vol_BatchNorm2d(self, x, bn):\n",
    "        activations = self.tensor(x.shape)\n",
    "        for z in range(x.shape[1]):\n",
    "            activations[:,z] = bn(x[:,z].contiguous())\n",
    "        return activations\n",
    "                \n",
    "    def vol_conv2d(self, x, weight, pad):\n",
    "        # batch x Z x C x H x W\n",
    "        activations = self.tensor(x.shape[0],x.shape[1],weight.shape[0],x.shape[3],x.shape[4])\n",
    "        for z in range(x.shape[1]):\n",
    "            activations[:,z] = F.conv2d(x[:,z], weight, padding=pad)\n",
    "        return activations\n",
    "    \n",
    "    def crop(self, x):\n",
    "        cropH = (x.shape[2] - self.H)/2\n",
    "        cropW = (x.shape[3] - self.W)/2\n",
    "        if cropH>0:\n",
    "            x = x[:,:,int(np.floor(cropH)):-int(np.ceil(cropH))]\n",
    "        if cropW>0:\n",
    "            x = x[:,:,:,int(np.floor(cropW)):-int(np.ceil(cropW))]\n",
    "        return x\n",
    "\n",
    "class SuperResBlock(Vol2D):\n",
    "    \"\"\"Upsample Volume using subpixel convolution.\n",
    "    \n",
    "    Reference: https://arxiv.org/pdf/1609.05158.pdf\"\"\"\n",
    "    def __init__(self, upscale_factor, in_channels=1, tensor=T.cuda.FloatTensor):\n",
    "        super(SuperResBlock, self).__init__(tensor)\n",
    "        self.tensor = tensor\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dconv1 = nn.Parameter(self.tensor(64,in_channels,5,5))\n",
    "        self.dpad1 = (2,2)\n",
    "        self.dbn1 = nn.BatchNorm2d(64)\n",
    "        self.dconv2 = nn.Parameter(self.tensor(64,64,3,3))\n",
    "        self.dpad2 = (1,1)\n",
    "        self.dbn2 = nn.BatchNorm2d(64)\n",
    "        self.dconv3 = nn.Parameter(self.tensor(32,64,3,3))\n",
    "        self.dpad3 = (1,1)\n",
    "        self.dbn3 = nn.BatchNorm2d(32)\n",
    "        self.dconv4 = nn.Parameter(self.tensor(upscale_factor**2,32,3,3))\n",
    "        self.dpad4 = (1,1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x, layer_output):        \n",
    "        x_chan = x.shape[2]\n",
    "        new_x = tensor(x.shape[0], x.shape[1], x_chan+layer_output.shape[2],\n",
    "                       x.shape[3], x.shape[4])\n",
    "        new_x[:,:,:x_chan] = x\n",
    "#         print(new_x.shape, layer_output.shape)\n",
    "        new_x[:,:,x_chan:] = layer_output\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(new_x, self.dconv1, self.dpad1), self.dbn1))\n",
    "        del new_x\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv2, self.dpad2), self.dbn2))\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv3, self.dpad3), self.dbn3))\n",
    "        x = self.vol_conv2d(x, self.dconv4, self.dpad4)\n",
    "        x = self.vol_PixelShuffle(x)\n",
    "        # add back single channel\n",
    "        x = x[:,:,None]\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        if self.tensor==T.cuda.FloatTensor:\n",
    "            nn.init.orthogonal_(self.dconv1, nn.init.calculate_gain('relu'))\n",
    "            nn.init.orthogonal_(self.dconv2, nn.init.calculate_gain('relu'))\n",
    "            nn.init.orthogonal_(self.dconv3, nn.init.calculate_gain('relu'))\n",
    "            nn.init.orthogonal_(self.dconv4)\n",
    "        else:\n",
    "            for m in [self.dconv1, self.dconv2, self.dconv3, self.dconv4]:\n",
    "                nn.init.kaiming_normal_(m, mode='fan_out', nonlinearity='relu')\n",
    "        for bn in [self.dbn1,self.dbn2,self.dbn3]:\n",
    "            nn.init.constant_(bn.weight, 1)\n",
    "            nn.init.constant_(bn.bias, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tofp16(nn.Module):\n",
    "    \"\"\"\n",
    "    Model wrapper that implements::\n",
    "        def forward(self, input):\n",
    "            return input.half()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(tofp16, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input.cuda().half()\n",
    "\n",
    "\n",
    "def BN_convert_float(module):\n",
    "    '''\n",
    "    Designed to work with network_to_half.\n",
    "    BatchNorm layers need parameters in single precision.\n",
    "    Find all layers and convert them back to float. This can't\n",
    "    be done with built in .apply as that function will apply\n",
    "    fn to all modules, parameters, and buffers. Thus we wouldn't\n",
    "    be able to guard the float conversion based on the module type.\n",
    "    '''\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.float()\n",
    "    for child in module.children():\n",
    "        BN_convert_float(child)\n",
    "    return module\n",
    "\n",
    "\n",
    "def network_to_half(network):\n",
    "    \"\"\"\n",
    "    Convert model to half precision in a batchnorm-safe way.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(tofp16(), BN_convert_float(network.half()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(Vol2D):\n",
    "    def __init__(self, nZ=11, H=232, W=512, nEmbedding=20, prev_frames=1,\n",
    "                 pred_hidden=20, tensor=T.cuda.FloatTensor):\n",
    "        super(Conv, self).__init__(tensor)\n",
    "        self.tensor = tensor\n",
    "        self.nZ = nZ\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        self.lowH = 8\n",
    "        self.lowW = 16\n",
    "        self.lowFeatures = 1\n",
    "        self.prev_frames = prev_frames\n",
    "        # batch x channel x Z x H x W\n",
    "        # Encoding\n",
    "        self.resnet = ResNet(BasicBlock, [2, 2, 2, 2], prev_frames)\n",
    "        self.resOut = 1\n",
    "        self.nEmbedding = nEmbedding\n",
    "        \n",
    "        # b x 11 x 32 x 11 x 25\n",
    "        self.encoding_mean = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        self.encoding_logvar = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        \n",
    "        # Prediction\n",
    "        self.pred1 = nn.Linear(nEmbedding+prev_frames, pred_hidden) # add dim for shock_{t+1}\n",
    "        self.pred_bn1 = nn.BatchNorm1d(pred_hidden)\n",
    "        self.pred2 = nn.Linear(pred_hidden, nEmbedding) # last 10 (context) are unused\n",
    "        \n",
    "        # Decoding\n",
    "        self.activation = nn.Tanh()\n",
    "        # only use 10 embeddings for frame decoding, the other 10 are context\n",
    "        self.decoding = nn.Linear(nEmbedding/2,self.lowFeatures*nZ*self.lowH*self.lowW)\n",
    "        self.upconv1 = SuperResBlock(2,65,tensor)\n",
    "        # 11 x 16 x 32\n",
    "        self.upconv2 = SuperResBlock(2,65,tensor)\n",
    "        # 11 x 32 x 64\n",
    "        self.upconv3 = SuperResBlock(2,65,tensor)\n",
    "        # 11 x 64 x 128\n",
    "        self.upconv4 = SuperResBlock(2,65,tensor)\n",
    "        # 11 x 128 x 256\n",
    "#         self.upconv5 = SuperResBlock(2,tensor)\n",
    "        # 11 x 256 x 512\n",
    "    \n",
    "        self.tail_decoding = nn.Linear(1,1)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        nn.init.xavier_normal_(self.encoding_mean.weight)\n",
    "        # TODO - make larger?\n",
    "        nn.init.xavier_normal_(self.encoding_logvar.weight,1e-3)\n",
    "    \n",
    "    def sample_embedding(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = x.transpose(1,2)\n",
    "        out = self.tensor(x.shape[0],x.shape[1],self.resOut)\n",
    "        layers = [\"conv1_out\", \"layer1_out\", \"layer2_out\", \"layer3_out\", \"layer4_out\"]\n",
    "        layer_outputs = {k: [] for k in layers}\n",
    "        for z in range(x.shape[1]):\n",
    "            out[:,z], layer_out = self.resnet(x[:,z])\n",
    "            for k in layers:\n",
    "                layer_outputs[k].append(layer_out[k])\n",
    "        layer_outputs = {k: T.stack(v,1) for k,v in layer_outputs.items()}\n",
    "        mean = self.encoding_mean(out.reshape(x.shape[0],-1))\n",
    "        logvar = self.encoding_logvar(out.reshape(x.shape[0],-1))\n",
    "        return mean, logvar, layer_outputs\n",
    "     \n",
    "    def predict(self, x, shock):\n",
    "        x = T.cat([x, shock],1)\n",
    "        x = self.activation(self.pred1(x))\n",
    "        x = self.pred2(x)\n",
    "        return x\n",
    "        \n",
    "    def decode(self, x, layer_output):\n",
    "        tail = F.sigmoid(self.tail_decoding(x[:,[0]])) # use first embedding only\n",
    "        # b x 10\n",
    "        # only use first half for brain data\n",
    "        x = self.activation(self.decoding(x[:,:int(self.nEmbedding/2)]))\n",
    "        x = x.reshape(x.shape[0],self.nZ,self.lowFeatures,self.lowH,self.lowW)\n",
    "#         print(\"upconv1\", x.shape)\n",
    "        x = self.upconv1(x, layer_output[\"layer3_out\"])\n",
    "#         print(\"upconv2\", x.shape)\n",
    "        x = self.upconv2(x, layer_output[\"layer2_out\"])\n",
    "#         print(\"upconv3\", x.shape)\n",
    "        x = self.upconv3(x, layer_output[\"layer1_out\"])\n",
    "#         print(\"upconv4\", x.shape)\n",
    "        x = self.upconv4(x, layer_output[\"conv1_out\"])\n",
    "#         x = self.upconv5(x)\n",
    "        x = self.crop(x[:,:,0])\n",
    "        # squeeze channel\n",
    "        return x, tail\n",
    "        \n",
    "    def forward(self, x, shock):\n",
    "        \"Return Previous volume (denoised), next volume (prediction), latent mean and logvar.\"\n",
    "        mean, logvar, layer_outputs = self.encode(x)\n",
    "        encoded = self.sample_embedding(mean, logvar)\n",
    "        encoded_pred = self.predict(encoded, shock)\n",
    "        zero_embed = T.zeros_like(encoded)\n",
    "        prev = self.decode(zero_embed, layer_outputs) # force to use only skip connections for decode\n",
    "        pred = self.decode(encoded_pred, layer_outputs)\n",
    "        return prev, pred, mean, logvar # should we move variational layer? or return encoded_pred?\n",
    "    \n",
    "def unit_norm_KL_divergence(mu, logvar):\n",
    "    \"Reconstruction + KL divergence losses summed over all elements and batch.\"\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "\n",
    "def train(model,train_data,valid_data, nepochs=10, lr=1e-3, kl_lambda=1, kl_tail=1e2, half=False, cuda=True):\n",
    "    dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    valid_dataloader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    kl_schedule = T.from_numpy(sigmoid_schedule(nepochs))\n",
    "    if half:\n",
    "        optimizer = apex.fp16_utils.FP16_Optimizer(T.optim.Adam(model.parameters(),lr=lr))\n",
    "    else:\n",
    "        optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "        \n",
    "    if cuda:\n",
    "        kl_schedule = kl_schedule.cuda()\n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        cum_X_loss = 0\n",
    "        cum_Y_loss = 0\n",
    "        cum_kld_loss = 0\n",
    "        cum_tail_loss = 0\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            X, Y = batch_data\n",
    "            X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "            Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                X_shock = X_shock.cuda()\n",
    "                Y_shock = Y_shock.cuda()\n",
    "                X_tail = X_tail.cuda()\n",
    "                Y_tail = Y_tail.cuda()\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "            if half:\n",
    "                X_pred = X_pred.float()\n",
    "                Y_pred = Y_pred.float()\n",
    "                mean = mean.float()\n",
    "                logvar = logvar.float()\n",
    "            kld = unit_norm_KL_divergence(mean, logvar)\n",
    "            mse_X = F.mse_loss(X_pred, Y[:,0])\n",
    "            mse_Y = F.mse_loss(Y_pred, Y[:,-1])\n",
    "            mse_tail = F.mse_loss(X_pred_tail, X_tail[:,[-1]])\n",
    "            loss = mse_X + mse_Y + kl_lambda*kl_schedule[e] * kld + kl_tail*mse_tail\n",
    "            if e==0:\n",
    "                print(\"MSE_X: {:.3E}, MSE_Y: {:.3E}, KLD: {:.3E}, Tail: {:.3E}\".format(float(mse_X),float(mse_Y),float(kld),float(mse_tail)))\n",
    "            optimizer.zero_grad()\n",
    "            if half:\n",
    "                optimizer.backward(loss)\n",
    "            else:\n",
    "                loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "            cum_X_loss += float(mse_X)\n",
    "            cum_Y_loss += float(mse_Y)\n",
    "            cum_kld_loss += float(kld)\n",
    "            cum_tail_loss += float(mse_tail)\n",
    "        \n",
    "        print(\"avg_loss: {:3E}, X_loss: {:3E}, Y_loss: {:3E}, KLD: {:3E}, tail_loss: {:3E}\".format(\n",
    "            cum_loss/len(train_data), cum_X_loss/len(train_data), cum_Y_loss/len(train_data), cum_kld_loss/len(train_data), cum_tail_loss/len(train_data)))        \n",
    "        cum_loss = 0\n",
    "        cum_X_loss = 0\n",
    "        cum_Y_loss = 0\n",
    "        cum_kld_loss = 0\n",
    "        cum_tail_loss = 0\n",
    "        model.eval()\n",
    "        for batch_data in valid_dataloader:\n",
    "            X, Y = batch_data\n",
    "            X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "            Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                X_shock = X_shock.cuda()\n",
    "                Y_shock = Y_shock.cuda()\n",
    "                X_tail = X_tail.cuda()\n",
    "                Y_tail = Y_tail.cuda()\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "            if half:\n",
    "                X_pred = X_pred.float()\n",
    "                Y_pred = Y_pred.float()\n",
    "                mean = mean.float()\n",
    "                logvar = logvar.float()\n",
    "            kld = unit_norm_KL_divergence(mean, logvar)\n",
    "            mse_X = F.mse_loss(X_pred, Y[:,0])\n",
    "            mse_Y = F.mse_loss(Y_pred, Y[:,-1])\n",
    "            mse_tail = F.mse_loss(X_pred_tail, X_tail[:,[-1]])\n",
    "            loss = mse_X + mse_Y + kl_lambda*kl_schedule[e] * kld + kl_tail*mse_tail\n",
    "            cum_loss += float(loss)\n",
    "            cum_X_loss += float(mse_X)\n",
    "            cum_Y_loss += float(mse_Y)\n",
    "            cum_kld_loss += float(kld)\n",
    "            cum_tail_loss += float(mse_tail)\n",
    "        model.train()\n",
    "        print(\"VALIDATION: avg_loss: {:3E}, X_loss: {:3E}, Y_loss: {:3E}, KLD: {:3E}, tail_loss: {:3E}\".format(\n",
    "            cum_loss/len(valid_data), cum_X_loss/len(valid_data), cum_Y_loss/len(valid_data), cum_kld_loss/len(valid_data), cum_tail_loss/len(valid_data)))        \n",
    "\n",
    "nEmbedding = 20\n",
    "batch_size = 10\n",
    "batch_size = 32\n",
    "tensorlib = T\n",
    "if cuda:\n",
    "    tensorlib = T.cuda\n",
    "\n",
    "if half:\n",
    "    tensor = tensorlib.HalfTensor\n",
    "else:\n",
    "    tensor = tensorlib.FloatTensor\n",
    "\n",
    "conv_model = Conv(nZ,H,W,nEmbedding,prev_frames,tensor=tensor)\n",
    "if cuda:\n",
    "    conv_model.cuda()\n",
    "if half:\n",
    "    conv_model = apex.fp16_utils.network_to_half(conv_model)\n",
    "if multi_gpu:\n",
    "    conv_model = nn.DataParallel(conv_model)\n",
    "print(\"total num params:\", np.sum([np.prod(x.shape) for x in conv_model.parameters()]))\n",
    "# conv_model(data[0][0][None,:,None].cuda()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train(conv_model,train_data,test_data,100,lr=1e-3, kl_lambda=1e-3, half=half, cuda=cuda)\n",
    "# 1.91E+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"/data2/trained_models/180822_skip_force_zero_small_X=t-4:t_Y=t+1,t+5_epochs=25_KL=1e-3_X_val_MSE(X)=2.66E+01_Y_val_MSE(Y)=3.09E+01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T.save(conv_model.state_dict(),model_name+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.load_state_dict(T.load(model_name+\".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "T.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_mse(X, Y):\n",
    "    with T.no_grad():\n",
    "        loss = F.mse_loss(X,Y,reduce=False).reshape(X.shape[0],-1).sum(1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleMSE(model,data, batch_size=96):\n",
    "    prev_frames = data.prev_frames\n",
    "    next_frames = data.next_frames\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    xlabels = ['X_t'] + ['X_t-{}'.format(i) for i in range(1,prev_frames)] + ['X_pred']\n",
    "    ylabels = ['Y_t+{}'.format(i) for i in range(1,next_frames+1)] + ['Y_pred']\n",
    "    labels = xlabels+ylabels\n",
    "    mses = {\"MSE({},{})\".format(x,y): [] for x,y in itertools.product(labels, labels)}\n",
    "    size = len(data)\n",
    "    with T.no_grad():\n",
    "        # stabilize running_mean and running_std of batchnorm\n",
    "        niters = 0\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            if niters >= 10:\n",
    "                break\n",
    "            niters += 1\n",
    "            X, Y = batch_data\n",
    "            X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "            Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "            X = X.cuda()\n",
    "            Y_shock = Y_shock.cuda()\n",
    "            Y = Y.cuda()\n",
    "            _ = model(X, Y_shock)\n",
    "    model.eval()\n",
    "    for batch_data in tqdm(dataloader):\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        X = X.cuda()\n",
    "        Y_shock = Y_shock.cuda()\n",
    "        Y = Y.cuda()\n",
    "        (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(X, Y_shock)\n",
    "        xs = [X[:,i] for i in reversed(range(prev_frames))] + [X_pred]\n",
    "        ys = [Y[:,i] for i in range(next_frames)] + [Y_pred]\n",
    "        dat = xs+ys\n",
    "        iter = itertools.product(zip(labels,dat), zip(labels,dat))\n",
    "        for (xlabel, x), (ylabel, y) in iter:\n",
    "            mse = volume_mse(x,y)\n",
    "            mses[\"MSE({},{})\".format(xlabel,ylabel)].append(mse)\n",
    "    model.train()\n",
    "    mses = {k: T.cat(v).cpu().numpy() for k,v in mses.items()}\n",
    "    return mses\n",
    "\n",
    "mses_train = sampleMSE(conv_model, train_data, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses_test = sampleMSE(conv_model, test_data, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mses_train[\"MSE(X_pred,Y_t+5)\"]\n",
    "b = mses_train[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),a.mean()-b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = mses_test[\"MSE(X_pred,Y_t+5)\"]\n",
    "b = mses_test[\"MSE(Y_pred,Y_t+5)\"]\n",
    "print(stats.wilcoxon(a,b),a.mean()-b.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(2,1,1)\n",
    "mse_diff = mses_train[\"MSE(Y_pred,X_t-1)\"]-mses_train[\"MSE(X_pred,X_t-1)\"]\n",
    "sb.distplot(mse_diff)\n",
    "plt.axvline(0,c='k')\n",
    "plt.title(\"Train\")\n",
    "plt.axvline(mse_diff.mean(),c='r')\n",
    "plt.subplot(2,1,2,sharex=ax)\n",
    "sb.distplot(mses_train[\"MSE(Y_pred,Y_t+5)\"]-mses_train[\"MSE(X_pred,Y_t+5)\"])\n",
    "plt.axvline(0,c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot(2,1,1)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,X_t)\"]-mses_test[\"MSE(X_pred,X_t)\"])\n",
    "plt.axvline(0,c='k')\n",
    "plt.title(\"Test\")\n",
    "plt.subplot(2,1,2,sharex=ax)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,Y_t+5)\"]-mses_test[\"MSE(X_pred,Y_t+5)\"])\n",
    "plt.axvline(0,c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(tvt_split[\"test\"],mses_test[\"MSE(X_pred,Y_t+5)\"],'.',c='indianred',alpha=0.5)\n",
    "plt.plot(tvt_split[\"test\"],mses_test[\"MSE(Y_pred,Y_t+5)\"],'.',c='steelblue',alpha=0.5)\n",
    "plt.subplot(2,1,2)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,Y_t+5)\"]-mses_test[\"MSE(X_pred,Y_t+5)\"])\n",
    "plt.axvline(0,c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvt_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(mses_test[\"MSE(X_pred,Y_t+5)\"],c='indianred')\n",
    "plt.plot(mses_test[\"MSE(Y_pred,Y_t+5)\"],c='steelblue')\n",
    "plt.subplot(2,1,2)\n",
    "sb.distplot(mses_test[\"MSE(Y_pred,Y_t+5)\"]-mses_test[\"MSE(X_pred,Y_t+5)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.distplot(mses_test[\"MSE(X_pred,Y_t+5)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mses_test[\"MSE(X_pred,Y_t+5)\"] - mses_test[\"MSE(Y_pred,Y_t+5)\"],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mses_test[\"MSE(X_pred,Y_t+5)\"] - mses_test[\"MSE(Y_pred,Y_t+5)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.eval()\n",
    "\n",
    "conv_model.module.pred_bn1.track_running_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses = mses_test\n",
    "idx = np.argsort(mses['MSE(X_t,Y_t+1)'])#[-250:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Distribution of MSE for X_pred (t+1)\")\n",
    "labels = ['MSE(X_pred,X_t-4)', 'MSE(X_pred,X_t-1)', 'MSE(X_pred,X_t)',\n",
    "          'MSE(X_pred,Y_t+1)', 'MSE(X_pred,Y_t+4)', 'MSE(X_pred,Y_t+5)']\n",
    "vals = [mses[k][idx] for k in labels]\n",
    "plt.hist(np.stack(vals,1), 20)\n",
    "plt.legend([\"{}={:.4g}\".format(k,m.mean()) for k, m in zip(labels, vals)])\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "labels = ['MSE(Y_pred,X_t-4)', 'MSE(Y_pred,X_t-1)', 'MSE(Y_pred,X_t)',\n",
    "          'MSE(Y_pred,Y_t+1)', 'MSE(Y_pred,Y_t+4)', 'MSE(Y_pred,Y_t+5)']\n",
    "vals = [mses[k][idx] for k in labels]\n",
    "plt.hist(np.stack(vals,1), 20)\n",
    "plt.legend([\"{}={:.4g}\".format(k,m.mean()) for k, m in zip(labels, vals)])\n",
    "plt.title(\"Distribution of MSE for Y_pred (t+5)\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "labels = ['MSE(X_t-1,X_t)', 'MSE(X_t,Y_t+1)',\n",
    "          'MSE(X_t-1,Y_t+1)']\n",
    "vals = [mses[k][idx] for k in labels]\n",
    "plt.hist(np.stack(vals,1), 20)\n",
    "plt.legend([\"{}={:.4g}\".format(k,m.mean()) for k, m in zip(labels, vals)])\n",
    "plt.title(\"Distribution of MSE for different timesteps\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "labels = ['MSE(X_pred,Y_pred)']\n",
    "vals = [mses[k][idx] for k in labels]\n",
    "plt.hist(np.stack(vals,1), 20)\n",
    "plt.legend([\"{}={:.4g}\".format(k,m.mean()) for k, m in zip(labels, vals)])\n",
    "plt.title(\"Distribution of MSE(X_pred,Y_pred)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(mses_test['MSE(X_pred,Y_t+5)'],\n",
    "                         mses_test['MSE(Y_pred,Y_t+5)'])#,\n",
    "#                         alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(mses_test['MSE(X_pred,Y_t+5)'],\n",
    "                         mses_test['MSE(Y_pred,Y_t+5)'])#,\n",
    "#                         alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mses['MSE(X_pred,Y_t+5)'] -\n",
    "                         mses['MSE(Y_pred,Y_t+5)'], 25)#,\n",
    "#                         alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in mses.items():\n",
    "    if k[:11]==\"MSE(Y_pred,\":\n",
    "        print(\"{}: {:.4g}\".format(k,v.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot_model_vs_real(model,data):\n",
    "    plt.figure(figsize=(30,15))\n",
    "\n",
    "    with T.no_grad():\n",
    "        for i in range(4):\n",
    "            time = np.random.randint(len(data))\n",
    "            z = np.random.randint(nZ)\n",
    "            X, Y = data[time]\n",
    "            X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "            Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "            x = X[None].cuda()\n",
    "            Y_shock = Y_shock[None].cuda()\n",
    "            y = Y[None].cuda()\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), mean, logvar = model(x, Y_shock)\n",
    "            mse_X = float(F.mse_loss(X_pred,x[:,0]).cpu())\n",
    "            mse_X_pred_to_Y = float(F.mse_loss(X_pred,y[:,0]).cpu())\n",
    "            mse_Y_pred_to_X = float(F.mse_loss(Y_pred,x[:,-1]).cpu())\n",
    "            mse_Y = float(F.mse_loss(Y_pred,y[:,-1]).cpu())\n",
    "            prev_loss = float(F.mse_loss(x[:,0],y[:,-1]).cpu())\n",
    "#             x_zero_loss = float(F.mse_loss(x,T.zeros_like(x)).cpu())\n",
    "#             y_zero_loss = float(F.mse_loss(y,T.zeros_like(y)).cpu())\n",
    "            mymin = min(float(y[0,:,z].min()[0]),float(x[0,:,z].min()[0]),float(X_pred[0,z].min()[0]))\n",
    "            mymax = max(float(y[0,:,z].max()[0]),float(x[0,:,z].max()[0]),float(X_pred[0,z].max()[0]))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+1)\n",
    "            plt.imshow(X[-1,z].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"Time=\"+str(time) + \", z=\"+str(z))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+2)\n",
    "            plt.imshow(Y[0,z].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"Time=\"+str(time+1) + \", z=\"+str(z))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+3)\n",
    "            plt.imshow(X_pred[0,z].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"MSE: (X_pred,X)={:.0f}, (X_pred,Y)={:.0f}\".format(mse_X,mse_X_pred_to_Y))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+4)\n",
    "            plt.imshow(Y_pred[0,z].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"MSE: (Y_pred,Y)={:.0f}, (Y_pred,X)={:.0f}\".format(mse_Y,mse_Y_pred_to_X))\n",
    "\n",
    "plot_model_vs_real(conv_model.module,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def get_gradient_from_embedding(model,frame,embedding,niters=20, lr=1e-3):\n",
    "#     model.eval()\n",
    "#     frame = frame.cuda()\n",
    "#     frame.requires_grad = True\n",
    "#     embedding_pred, _ = model.encode(frame)\n",
    "#     print(embedding_pred.shape)\n",
    "#     embedding_pred.backward(gradient=embedding)\n",
    "#     model.train()\n",
    "#     return frame.grad[0]\n",
    "\n",
    "# def get_input_from_embedding(model,frame,embedding,niters=75, lr=1e-1, rand=False):\n",
    "#     \"Take an embedding vector, and use backprop to find the volume\"\n",
    "#     if rand:\n",
    "#         prev_img = T.rand_like(frame[None], requires_grad=True).cuda()\n",
    "#     else:\n",
    "#         prev_img = frame[None].cuda()\n",
    "#         prev_img.requires_grad = True\n",
    "#     optimizer = T.optim.Adam([prev_img],lr=lr)\n",
    "#     model.eval()\n",
    "#     for i in range(niters):\n",
    "#         embedding_pred, _ = model.encode(prev_img)\n",
    "#         loss = F.mse_loss(embedding_pred,embedding[None]) #+ 1e-7*T.norm(prev_img,1)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "# #         print(\"iter {} loss: \".format(i), float(loss))\n",
    "#     model.train()\n",
    "#     return prev_img[0].detach().cpu().numpy()\n",
    "\n",
    "def interpret(model,prev_vol, next_vol, nEmbedding):\n",
    "    \"Plot prev & next frame for each latent dimension\"\n",
    "    plt.figure(figsize=(10,40))\n",
    "    \n",
    "    embedding = T.from_numpy(np.zeros(nEmbedding).astype(np.float32)).cuda()[None]\n",
    "#     shock = T.FloatTensor([0,1])[:,None,None].cuda()\n",
    "    shock = T.cuda.FloatTensor(2,1,prev_frames).zero_()\n",
    "    shock[0] = T.zeros(1,prev_frames)\n",
    "    shock[1] = T.ones(1,prev_frames)\n",
    "    with T.no_grad():\n",
    "        prev_img = model.decode(embedding)[0][0] # ignore tail\n",
    "        next_img = model.decode(model.predict(embedding,shock[0]))[0][0] # ignore tail\n",
    "        next_img_shock = model.decode(model.predict(embedding,shock[1]))[0][0]\n",
    "        \n",
    "    plt.subplot(1+nEmbedding,4,1)\n",
    "    plt.imshow(prev_img[6])\n",
    "    plt.title(\"Prev (Zero Vector)\")\n",
    "    \n",
    "    plt.subplot(1+nEmbedding,4,2)\n",
    "    plt.imshow(next_img[6])\n",
    "    plt.title(\"Next (Zero Vector)\")\n",
    "    \n",
    "    plt.subplot(1+nEmbedding,4,3)\n",
    "    plt.imshow(next_img[6] - prev_img[6])\n",
    "    plt.title(\"Diff (Zero Vector)\")\n",
    "    \n",
    "    plt.subplot(1+nEmbedding,4,4)\n",
    "    plt.imshow(next_img_shock[6])\n",
    "    plt.title(\"Next (Shock)\")\n",
    "    for i in range(nEmbedding):\n",
    "        embedding = T.from_numpy(np.eye(nEmbedding)[i].astype(np.float32)).cuda()[None]\n",
    "        with T.no_grad():\n",
    "            prev_img = model.decode(embedding)[0][0]\n",
    "            next_img = model.decode(model.predict(embedding,shock[0]))[0][0]\n",
    "            next_img_shock = model.decode(model.predict(embedding,shock[0]))[0][0]\n",
    "        plt.subplot(1+nEmbedding,4,i*4+5)\n",
    "        plt.imshow(prev_img[6])\n",
    "        plt.title(\"Prev (Dim {})\".format(i))\n",
    "        \n",
    "        plt.subplot(1+nEmbedding,4,i*4+6)\n",
    "        plt.imshow(next_img[6])\n",
    "        plt.title(\"Next (Dim {})\".format(i))\n",
    "        \n",
    "        plt.subplot(1+nEmbedding,4,i*4+7)\n",
    "        plt.imshow(next_img[6]-prev_img[6])\n",
    "        plt.title(\"Diff (Dim {})\".format(i))\n",
    "        \n",
    "        plt.subplot(1+nEmbedding,4,i*4+8)\n",
    "        plt.imshow(next_img_shock[6])\n",
    "        plt.title(\"Next w/ shock (Dim {})\".format(i))\n",
    "    plt.tight_layout()\n",
    "\n",
    "x, y = data[1000]\n",
    "interpret(conv_model.module,x,y,nEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_over_time(model,data, batch_size=64):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    embeddings = []\n",
    "    logvars = []\n",
    "    model.eval()\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        with T.no_grad():\n",
    "            embedding, logvar, _ = model.encode(X.cuda())\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "        logvars.append(logvar.cpu().numpy())\n",
    "    model.train()\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    logvars = np.vstack(logvars)\n",
    "    nEmbeddings = embeddings.shape[1]\n",
    "    half = int(np.ceil(nEmbeddings / 2))\n",
    "    \n",
    "    plt.figure(figsize=(15,20))\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(embeddings[:,0:half])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(embeddings[:,half:])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    \n",
    "    plt.subplot(4,1,3)\n",
    "    plt.plot(logvars[:,0:half])\n",
    "    plt.title(\"Logvars over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(logvars[:,half:])\n",
    "    plt.title(\"Logvars over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return embeddings\n",
    "embeddings = plot_embedding_over_time(conv_model.module,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP mean added back\n",
    "def scale_for_vid(arr, mymin, mymax):\n",
    "    return ((arr - mymin) * (1/(mymax - mymin)) * 255).astype('uint8')\n",
    "\n",
    "import skvideo.io\n",
    "def makePredVideo(model, data, mean_fish, batch_size=32):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    writer = skvideo.io.FFmpegWriter(model_name + \"_test_prediction.mp4\",outputdict={\n",
    "        '-b': '30000000', '-vcodec': 'libx264'})\n",
    "    mymax = float(T.cat([test_data[i][0]['brain']+mean_fish for i in np.arange(len(test_data))]).max())\n",
    "    mymin = float(T.cat([test_data[i][0]['brain']+mean_fish for i in np.arange(len(test_data))]).min())\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        with T.no_grad():\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), _, _= model(X.cuda(),Y_shock.cuda())\n",
    "        for x, x_pred, y, y_pred in zip(X,X_pred,Y,Y_pred):\n",
    "            # 7th z layer\n",
    "            zslice = x_pred[6]\n",
    "            H = zslice.shape[0]\n",
    "            W = zslice.shape[1]\n",
    "            frame = np.zeros([H*2,W*3])\n",
    "            \n",
    "            frame[:H, :W] = y[0,6]+mean_fish\n",
    "            frame[:H, W:(2*W)] = y[-1,6] - y[0,6]\n",
    "            frame[:H, (2*W):] = y[-1,6]+mean_fish\n",
    "            frame[H:, :W] = x_pred[6]+mean_fish\n",
    "            frame[H:, W:(2*W)] = y_pred[6] - y[0,6] #x_pred[6]\n",
    "            frame[H:, (2*W):] = y_pred[6]+mean_fish\n",
    "            writer.writeFrame(scale_for_vid(frame,mymin,mymax))\n",
    "    writer.close()\n",
    "    return frame\n",
    "\n",
    "mean_fish = T.from_numpy(imaging.mean(0)).cuda()\n",
    "frame = makePredVideo(conv_model,test_data, mean_fish)\n",
    "\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_for_vid(arr, mymin, mymax):\n",
    "    return ((arr - mymin) * (1/(mymax - mymin)) * 255).astype('uint8')\n",
    "\n",
    "import skvideo.io\n",
    "def makePredVideo(model, data, batch_size=32):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    writer = skvideo.io.FFmpegWriter(model_name + \"_test_prediction.mp4\",outputdict={\n",
    "        '-b': '30000000', '-vcodec': 'libx264'})\n",
    "    mymax = float(T.cat([test_data[i][0]['brain'] for i in np.arange(len(test_data))]).max())\n",
    "    mymin = float(T.cat([test_data[i][0]['brain'] for i in np.arange(len(test_data))]).min())\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        X, X_shock, X_tail = (X[\"brain\"], X[\"shock\"], X[\"tail_movement\"])\n",
    "        Y, Y_shock, Y_tail = (Y[\"brain\"], Y[\"shock\"], Y[\"tail_movement\"])\n",
    "        with T.no_grad():\n",
    "            (X_pred, X_pred_tail), (Y_pred, Y_pred_tail), _, _= model(X.cuda(),Y_shock.cuda())\n",
    "        for x, x_pred, y, y_pred in zip(X,X_pred,Y,Y_pred):\n",
    "            # 7th z layer\n",
    "            zslice = x_pred[6]\n",
    "            H = zslice.shape[0]\n",
    "            W = zslice.shape[1]\n",
    "            frame = np.zeros([H*2,W*3])\n",
    "            \n",
    "            frame[:H, :W] = y[0,6]\n",
    "            frame[:H, W:(2*W)] = y[-1,6] - y[0,6]\n",
    "            frame[:H, (2*W):] = y[-1,6]\n",
    "            frame[H:, :W] = x_pred[6]\n",
    "            frame[H:, W:(2*W)] = y_pred[6] - y[0,6].cuda() #x_pred[6]\n",
    "            frame[H:, (2*W):] = y_pred[6]\n",
    "            writer.writeFrame(scale_for_vid(frame,mymin,mymax))\n",
    "    writer.close()\n",
    "    return frame\n",
    "frame = makePredVideo(conv_model,test_data)\n",
    "\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.cat([test_data[i][0]['brain'] for i in np.arange(len(test_data))]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.cat([test_data[i][0]['brain'] for i in np.arange(len(test_data))]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[np.arange(len(test_data))][0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishDistanceData(Dataset):\n",
    "    def __init__(self, imaging, distance):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        self.data = T.from_numpy(data)\n",
    "        self.distance=distance\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]-self.distance\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data[idx+self.distance]\n",
    "\n",
    "def MSEbyDist(imaging, maxdist=10, batch_size=256):\n",
    "    mse = []\n",
    "    \n",
    "    with T.no_grad():\n",
    "        for d in range(1,maxdist+1):\n",
    "            data = FishDistanceData(imaging,d)\n",
    "            dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "            mse.append([])\n",
    "            for batch_data in tqdm(dataloader):\n",
    "                X, Y = batch_data\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                mse[d-1].append(volume_mse(X, Y).cpu())\n",
    "\n",
    "    mse = [T.cat(m).numpy() for m in mse]\n",
    "    return mse\n",
    "\n",
    "mse = MSEbyDist(imaging,10)\n",
    "\n",
    "plt.hist(mse)\n",
    "plt.legend([\"MSE distance {}={:.4g}\".format(d+1,m.mean()) for d, m in enumerate(mse)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishMAData(Dataset):\n",
    "    def __init__(self, imaging, ma=5, nfuture=1, index_map=None):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        self.data = T.from_numpy(data)\n",
    "        self.ma=ma\n",
    "        self.nfuture=nfuture\n",
    "        self.index_map=index_map\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.index_map:\n",
    "            return len(self.index_map)\n",
    "        else:\n",
    "            return self.data.shape[0]-self.ma-self.nfuture\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if self.index_map:\n",
    "            idx = self.index_map[i]\n",
    "        else:\n",
    "            idx = i\n",
    "        return self.data[(idx-self.ma+1):(idx+1)].mean(0), self.data[idx+self.nfuture]\n",
    "\n",
    "def MSE_MA(imaging, ma=5, nfuture=1, batch_size=256, index_map=None):\n",
    "    mse = []\n",
    "    with T.no_grad():\n",
    "        data = FishMAData(imaging, ma, nfuture,index_map)\n",
    "        dataloader = DataLoader(data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            X, Y = batch_data\n",
    "            X = X.cuda()\n",
    "            Y = Y.cuda()\n",
    "            mse.append(volume_mse(X, Y).cpu())\n",
    "\n",
    "    return T.cat(mse).numpy()\n",
    "\n",
    "mse = MSE_MA(imaging, 5, 5, 256, tvt_split['train'])\n",
    "\n",
    "plt.hist(mse,30)\n",
    "plt.legend([\"MSE={:.4g}\".format(mse.mean())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MSE_MA(imaging, 5, 5, 256, tvt_split['test'])\n",
    "\n",
    "plt.hist(mse,30)\n",
    "plt.legend([\"MSE={:.4g}\".format(mse.mean())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
