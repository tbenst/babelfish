{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from torchvision.transforms import Resize\n",
    "import dill\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "\n",
    "import os, sys, datetime\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "f = all_data['e'][2]\n",
    "\n",
    "time_fish = T.from_numpy(f.frame_st.mean(1).astype(np.float32)).cuda()\n",
    "u_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "p_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "u_fish[numpy.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_from_z(z, fish):\n",
    "    tiff = fish.get_tif_rasl(z)\n",
    "    ntime = fish.frame_et.shape[0]\n",
    "    frames = np.zeros((ntime, tiff.frame_shape[0],tiff.frame_shape[1])).astype(np.float32)\n",
    "    for t in range(ntime):\n",
    "        frame = np.array(tiff.get_frame(t)).astype(np.float32)\n",
    "        frames[t] = frame\n",
    "    return frames\n",
    "\n",
    "def get_imaging_from_fish(f,n_jobs=8):\n",
    "    nZ = f.num_zplanes\n",
    "    # frames_by_z = pool.map(partial(get_frames_from_z, fish=f), range(nZ))\n",
    "    frames_by_z = Parallel(n_jobs=n_jobs)(delayed(get_frames_from_z)(z,fish=f) for z in range(nZ))\n",
    "    imaging = np.stack(frames_by_z).swapaxes(0,1).astype(np.float32)\n",
    "    return imaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_volume(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    new[0] = im\n",
    "    for i, img in enumerate(images[1:]):\n",
    "        new[i] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new\n",
    "\n",
    "def resize_batch(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0,0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],images.shape[1], im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    for b, vol in enumerate(images):\n",
    "        for z, img in enumerate(vol):\n",
    "            new[b,z] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging = get_imaging_from_fish(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishImageData(Dataset):    \n",
    "    def __init__(self, imaging):\n",
    "        data = imaging - imaging.mean()\n",
    "        self.data = T.from_numpy(data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data[idx+1]\n",
    "\n",
    "data = FishImageData(imaging)\n",
    "batch_size = 64\n",
    "nZ, H, W = data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(padding_type, kernel_size):\n",
    "    assert padding_type in ['SAME', 'VALID']\n",
    "    if padding_type == 'SAME':\n",
    "        return tuple((k - 1) // 2 for k in kernel_size)\n",
    "    return tuple(0 for _ in kernel_size)\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, nZ=11, H=232, W=512, nEmbedding=20):\n",
    "        super(Conv, self).__init__()\n",
    "        self.nZ = nZ\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        self.lowH = 11\n",
    "        self.lowW = 25\n",
    "        self.lowFeatures = 16\n",
    "        # batch x channel x Z x H x W\n",
    "        # Encoding\n",
    "        self.conv1 = nn.Parameter(T.cuda.FloatTensor(8,1,9,9))\n",
    "#         self.conv1 = nn.Conv2d(1,1,1,9,9)\n",
    "        self.pad1 = get_padding('SAME',(9,9))\n",
    "        self.activation = nn.ReLU()\n",
    "        self.conv2 = nn.Parameter(T.cuda.FloatTensor(self.lowFeatures,8,9,9))\n",
    "        self.pad2 = get_padding('SAME',(9,9))\n",
    "        # b x 11 x 32 x 11 x 25\n",
    "        self.encoding_mean = nn.Linear(self.lowFeatures*self.nZ*self.lowH*self.lowW, nEmbedding)\n",
    "        self.encoding_logvar = nn.Linear(self.lowFeatures*self.nZ*self.lowH*self.lowW, nEmbedding)\n",
    "        \n",
    "        # Decoding (super resolution)\n",
    "        # https://arxiv.org/pdf/1609.05158.pdf\n",
    "        upscale_factor = 22\n",
    "        self.decoding = nn.Linear(nEmbedding,self.lowFeatures*nZ*self.lowH*self.lowW)\n",
    "        self.dconv1 = nn.Parameter(T.cuda.FloatTensor(64,16,5,5))\n",
    "        self.dpad1 = (2,2)\n",
    "        self.dconv2 = nn.Parameter(T.cuda.FloatTensor(64,64,3,3))\n",
    "        self.dpad2 = (1,1)\n",
    "        self.dconv3 = nn.Parameter(T.cuda.FloatTensor(32,64,3,3))\n",
    "        self.dpad3 = (1,1)\n",
    "        self.dconv4 = nn.Parameter(T.cuda.FloatTensor(upscale_factor**2,32,3,3))\n",
    "        self.dpad4 = (1,1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "                \n",
    "    def vol_conv(self, x, weight, pad):\n",
    "        # batch x Z x C x H x W\n",
    "        activations = T.cuda.FloatTensor(x.shape[0],x.shape[1],weight.shape[0],x.shape[3],x.shape[4])\n",
    "        for z in range(x.shape[1]):\n",
    "            activations[:,z] = F.conv2d(x[:,z], weight, padding=pad)\n",
    "        return activations\n",
    "    \n",
    "    def vol_MaxPool2d(self, x, kernel_size):\n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def vol_PixelShuffle(self, x):\n",
    "        # Helper for subpixel convolution\n",
    "        first = self.pixel_shuffle(x[:,0])\n",
    "        # b x z x H x W\n",
    "        ret = T.cuda.FloatTensor(x.shape[0],x.shape[1],first.shape[2], first.shape[3])\n",
    "        for z in range(x.shape[1]):\n",
    "            ret[:,z] = self.pixel_shuffle(x[:,z])[:,0]\n",
    "        return ret\n",
    "        \n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def sample_embedding(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.1*logvar)\n",
    "            dist = T.distributions.normal.Normal(T.zeros_like(std),T.ones_like(std))\n",
    "            std_z = dist.sample()\n",
    "            return mu + std*std_z\n",
    "#             eps = torch.randn_like(std)\n",
    "#             return eps.mul(std).add_(mu)\n",
    "            dist = T.distributions.normal.Normal(mu, std)\n",
    "            return dist.sample()\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = x[:,:,None]\n",
    "        # b x 11 x 1 x 232 x 512\n",
    "        x = self.activation(self.vol_MaxPool2d(self.vol_conv(x, self.conv1, self.pad1),4))\n",
    "        # b x 11 x 8 x 58 x 128\n",
    "        x = self.activation(self.vol_MaxPool2d(self.vol_conv(x, self.conv2, self.pad2),5))\n",
    "        # b x 11 x 32 x 11 x 25\n",
    "        mean = self.encoding_mean(x.reshape(x.shape[0],-1))\n",
    "        logvar = self.encoding_logvar(x.reshape(x.shape[0],-1))\n",
    "        return mean, logvar\n",
    "    \n",
    "    def crop(self, x):\n",
    "        cropH = (x.shape[2] - self.H)/2\n",
    "        cropW = (x.shape[3] - self.W)/2\n",
    "        x = x[:,:,int(np.floor(cropH)):-int(np.ceil(cropH))]\n",
    "        x = x[:,:,:,int(np.floor(cropW)):-int(np.ceil(cropW))]\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        # b x 20\n",
    "        x = self.activation(self.decoding(x))\n",
    "        x = x.reshape(x.shape[0],self.nZ,self.lowFeatures,self.lowH,self.lowW)\n",
    "        # b x 11 x 32 x 11 x 25\n",
    "        x = self.activation(self.vol_conv(x, self.dconv1, self.dpad1))\n",
    "        x = self.activation(self.vol_conv(x, self.dconv2, self.dpad2))\n",
    "        x = self.activation(self.vol_conv(x, self.dconv3, self.dpad3))\n",
    "        x = self.vol_PixelShuffle(self.vol_conv(x, self.dconv4, self.dpad4))\n",
    "        return self.crop(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        encoded = self.sample_embedding(mean, logvar)\n",
    "        decoded = self.decode(encoded)\n",
    "        return decoded, mean, logvar\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        nn.init.orthogonal_(self.conv1, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.conv2, nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_normal_(self.encoding_mean.weight)\n",
    "#         nn.init.xavier_normal_(self.encoding_mean.bias)\n",
    "        nn.init.xavier_normal_(self.encoding_logvar.weight,1e-3)\n",
    "#         nn.init.xavier_normal_(self.encoding_logvar.bias)\n",
    "        nn.init.orthogonal_(self.dconv1, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv2, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv3, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv4, nn.init.calculate_gain('relu'))\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(pred, target, mu, logvar):\n",
    "    MSE = F.mse_loss(pred, target, size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    var = logvar.exp()\n",
    "#     print(float(var.min()), float(var.max()))\n",
    "    KLD = -0.1 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return MSE, KLD, float(var.min()), float(var.max())\n",
    "    \n",
    "        \n",
    "# def train(model,data,nepochs=10, lambdaA=(1e-8, 1e-6), lambdaB=(1e-6, 1e-6),\n",
    "#           lambdaC=(1e-5, 1e-5), lambdaD=(1e-5, 1e-5), lr=0.1, verbose=True):\n",
    "def train(model,data,nepochs=10, lr=1e-3):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "    \n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        cum_mse_loss = 0\n",
    "        for batch_data in dataloader:\n",
    "            X, Y = batch_data\n",
    "            # add 1 channel\n",
    "            Y_pred, mean, logvar = model(X.cuda())\n",
    "            mse, kld, varmin, varmax = loss_function(Y_pred,Y.cuda(),mean, logvar)\n",
    "            loss = mse+kld\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "            cum_mse_loss += float(mse)\n",
    "\n",
    "        print(\"avg_loss: {:3E}, mse_loss: {:3E}\".format(\n",
    "            cum_loss/len(data), cum_mse_loss/len(data)))\n",
    "        print(\"varmin: {:3E}, varmax: {:3E}\".format(varmin,varmax))\n",
    "\n",
    "nEmbedding = 10\n",
    "batch_size = 64\n",
    "nZ, H, W = data[0][0].shape\n",
    "\n",
    "conv_model = Conv(nZ,H,W,nEmbedding)\n",
    "conv_model.cuda()\n",
    "# conv_model(data[0][0][None,:,None].cuda()).shape\n",
    "train(conv_model,data,10000,lr=1e-8)\n",
    "# 1.91E+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_vs_real(model,data):\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    with T.no_grad():\n",
    "        for i in range(4):\n",
    "            time = np.random.randint(len(data))\n",
    "            z = np.random.randint(nZ)\n",
    "            X, Y = data[time]\n",
    "            x = X[None].cuda()\n",
    "            y = Y[None].cuda()\n",
    "            X_pred, _, _ = model(x)\n",
    "            loss = float(F.mse_loss(X_pred,y).cpu())\n",
    "            prev_loss = float(F.mse_loss(x,y).cpu())\n",
    "            zero_loss = float(F.mse_loss(y,T.zeros_like(y)).cpu())\n",
    "            mymax = max(float(y[0,z].max()[0]),float(x[0,z].max()[0]),float(X_pred[0,z].max()[0]))\n",
    "            plt.subplot(4,3,i*3+1)\n",
    "            plt.imshow(X[z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "            plt.title(\"Time=\"+str(time) + \", z=\"+str(z))\n",
    "            plt.subplot(4,3,i*3+2)\n",
    "            plt.imshow(Y[z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "            plt.title(\"Time=\"+str(time+1) + \", z=\"+str(z))\n",
    "            plt.subplot(4,3,i*3+3)\n",
    "            plt.imshow(X_pred[0,z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "            plt.title(\"MSE: Pred={:.0f}, Prev={:.0f}, Zero={:.0f}\".format(loss,prev_loss,zero_loss))\n",
    "\n",
    "plot_model_vs_real(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_from_embedding(model,frame,embedding,niters=20, lr=1e-3):\n",
    "    model.eval()\n",
    "    frame = frame.cuda()\n",
    "    frame.requires_grad = True\n",
    "    embedding_pred, _ = model.encode(frame)\n",
    "    print(embedding_pred.shape)\n",
    "    embedding_pred.backward(gradient=embedding)\n",
    "    return frame.grad[0]\n",
    "\n",
    "frame = data[0][0]\n",
    "embedding = T.from_numpy(np.eye(10)[0].astype(np.float32)).cuda()\n",
    "prev_img = get_gradient_from_embedding(conv_model, frame[None], embedding[None])\n",
    "with T.no_grad():\n",
    "    next_img = conv_model.decode(embedding[None])[0]\n",
    "plt.imshow(prev_img[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_from_embedding(model,frame,embedding,niters=75, lr=1e-1, rand=False):\n",
    "    \"Take an embedding vector, and use backprop to find the volume\"\n",
    "    if rand:\n",
    "        prev_img = T.rand_like(frame[None], requires_grad=True).cuda()\n",
    "    else:\n",
    "        prev_img = frame[None].cuda()\n",
    "        prev_img.requires_grad = True\n",
    "    optimizer = T.optim.Adam([prev_img],lr=lr)\n",
    "    model.eval()\n",
    "    for i in range(niters):\n",
    "        embedding_pred, _ = model.encode(prev_img)\n",
    "        loss = F.mse_loss(embedding_pred,embedding[None]) #+ 1e-7*T.norm(prev_img,1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(\"iter {} loss: \".format(i), float(loss))\n",
    "    model.train()\n",
    "    return prev_img[0].detach().cpu().numpy()\n",
    "\n",
    "frame = data[0][0].cuda()\n",
    "embedding = T.from_numpy(1000*np.eye(10)[1].astype(np.float32)).cuda()\n",
    "prev_img = get_input_from_embedding(conv_model, frame, embedding,niters=81, rand=True)\n",
    "plt.imshow(prev_img[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for _ in range(10):\n",
    "    imgs.append(get_input_from_embedding(conv_model, frame, embedding,niters=81, rand=True)[[6]])\n",
    "plt.imshow(np.vstack(imgs).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(prev_img[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = data[500][0]\n",
    "# frame = 'rand'\n",
    "embedding = T.from_numpy(1000*np.eye(10)[1].astype(np.float32)).cuda()\n",
    "prev_img = get_input_from_embedding(conv_model, frame, embedding,niters=100)\n",
    "plt.imshow(prev_img[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret(model,prev_vol, next_vol, nEmbedding, prev_func):\n",
    "    \"Plot prev & next frame for each latent dimension\"\n",
    "    plt.figure(figsize=(10,50))\n",
    "    plt.subplot(2+nEmbedding,2,1)\n",
    "    plt.imshow(prev_vol[6])\n",
    "    plt.title(\"Prev Frame\")\n",
    "    plt.subplot(2+nEmbedding,2,2)\n",
    "    plt.imshow(next_vol[6])\n",
    "    plt.title(\"Next Frame\")\n",
    "    \n",
    "    embedding = T.from_numpy(np.zeros(nEmbedding).astype(np.float32)).cuda()[None]\n",
    "    with T.no_grad():\n",
    "        next_img = model.decode(embedding)[0]\n",
    "    prev_img = prev_func(model, prev_vol[None], embedding)\n",
    "    plt.subplot(2+nEmbedding,2,3)\n",
    "    plt.imshow(prev_img[6])\n",
    "    plt.title(\"Prev (Zero Vector)\")\n",
    "    plt.subplot(2+nEmbedding,2,4)\n",
    "    plt.imshow(next_img[6])\n",
    "    plt.title(\"Next (Zero Vector)\")\n",
    "    for i in range(nEmbedding):\n",
    "        embedding = T.from_numpy(np.eye(nEmbedding)[i].astype(np.float32)).cuda()[None]\n",
    "        with T.no_grad():\n",
    "            next_img = model.decode(embedding)[0]\n",
    "        prev_img = prev_func(model, prev_vol[None], embedding)\n",
    "        plt.subplot(2+nEmbedding,2,i*2+5)\n",
    "        plt.imshow(prev_img[6])\n",
    "        plt.title(\"Prev (Dim {})\".format(i))\n",
    "        plt.subplot(2+nEmbedding,2,i*2+6)\n",
    "        plt.imshow(next_img[6])\n",
    "        plt.title(\"Next (Dim {})\".format(i))\n",
    "    plt.tight_layout()\n",
    "\n",
    "x, y = data[1000]\n",
    "interpret(conv_model,x,y,10,get_gradient_from_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_over_time(model,data, batch_size=64):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    embeddings = []\n",
    "    for batch_data in dataloader:\n",
    "        X, _ = batch_data\n",
    "        # add 1 channel\n",
    "        with T.no_grad():\n",
    "            embedding, _ = model.encode(X.cuda())\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    nEmbeddings = embeddings.shape[1]\n",
    "    half = int(np.ceil(nEmbeddings / 2))\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(embeddings[:,0:half])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(embeddings[:,half:])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    plt.tight_layout()\n",
    "    return embeddings\n",
    "embeddings = plot_embedding_over_time(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo.io\n",
    "def makePredVideo(model, data, batch_size=64):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    writer = skvideo.io.FFmpegWriter(\"180705_conv_model_VAE.mp4\",outputdict={\n",
    "        '-b': '30000000'})\n",
    "    for batch_data in dataloader:\n",
    "        X, _ = batch_data\n",
    "        with T.no_grad():\n",
    "            vol_preds, _, _ = model(X.cuda())\n",
    "        for actual,pred in zip(X,vol_preds):\n",
    "            # 7th z layer\n",
    "            f = pred[6]\n",
    "            H = f.shape[0]\n",
    "            frame = np.zeros([H*2,f.shape[1]])\n",
    "            frame[:H] = actual[6]\n",
    "            frame[H:] = pred[6]\n",
    "            writer.writeFrame(frame)\n",
    "            \n",
    "    writer.close()\n",
    "makePredVideo(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = T.device('cuda')\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, nZ, H, W, nHidden=100, nEmbedding=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.nZ = nZ\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        self.nEmbedding = nEmbedding\n",
    "        self.fc1 = nn.Linear(nZ*H*W, 100)\n",
    "        self.fc21 = nn.Linear(100, nEmbedding)\n",
    "        self.fc22 = nn.Linear(100, nEmbedding)\n",
    "        self.fc3 = nn.Linear(nEmbedding, 100)\n",
    "        self.fc4 = nn.Linear(100, nZ*H*W)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.reshape(x.shape[0],-1))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z).reshape(x.shape), mu, logvar\n",
    "\n",
    "    \n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    MSE = F.mse_loss(recon_x, x, size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "#     KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    KLD = 0.5 * torch.mean(mu**2 + stddev_sq - torch.log(stddev_sq) - 1)\n",
    "    return MSE + KLD\n",
    "\n",
    "def train(model,data,nepochs=10, lr=0.1):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "    \n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        for batch_data in dataloader:\n",
    "            X, Y = batch_data\n",
    "            x = X.cuda()\n",
    "            recon_batch, mu, logvar = model(x)\n",
    "            loss = loss_function(recon_batch, x, mu, logvar)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            cum_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "\n",
    "        print(\"avg_loss: {:3E}\".format(cum_loss/len(data)))\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(64, model.nEmbedding).to(device)\n",
    "            sample = model.decode(sample).cpu()\n",
    "            save_image(sample.view(64, 11, model.H, model.W)[:,[0]],\n",
    "                       'results/sample_' + str(e) + '.png')\n",
    "\n",
    "model = VAE(nZ,H,W,64,16)\n",
    "model.cuda()\n",
    "\n",
    "train(model,data, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11*225*512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.encode(X[None,:,None].cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total num params:\", np.sum([np.prod(x.shape) for x in conv_model.parameters()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
