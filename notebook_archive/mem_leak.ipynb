{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_{t+1} = (A + pB)x_t + Cu_{t+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):    \n",
    "    def __init__(self, u, p, x,n_future_steps=1):\n",
    "        self.x = nn.Parameter(x,requires_grad=False)\n",
    "        self.p = nn.Parameter(p,requires_grad=False)\n",
    "        self.u = nn.Parameter(u,requires_grad=False)\n",
    "        self.nfeatures = x.shape[1]\n",
    "        self.n_future_steps = n_future_steps\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)-self.n_future_steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indices = slice(idx,idx+self.n_future_steps)\n",
    "        x_true_indices = slice(idx+1,idx+self.n_future_steps+1)\n",
    "        return (self.u[indices], self.p[indices],\n",
    "                self.x[indices], self.x[x_true_indices])\n",
    "\n",
    "class Dynamics(nn.Module):\n",
    "    def __init__(self, nfeatures):\n",
    "        super(Dynamics, self).__init__()\n",
    "        self.A = nn.Parameter(T.normal(T.zeros(nfeatures,nfeatures),0.5),requires_grad=True)\n",
    "        self.B = nn.Parameter(T.normal(T.zeros(nfeatures,nfeatures),0.5),requires_grad=True)\n",
    "        self.C = nn.Parameter(T.normal(T.zeros(nfeatures),0.5),requires_grad=True)\n",
    "\n",
    "    def forward(self, u, p, x):\n",
    "        return (x[:,0] + (T.matmul((self.A + p[:,0,None,None]*self.B), x[:,0,:,None]).squeeze()) + u[:,0,None] * self.C)[:,None]\n",
    "\n",
    "\n",
    "def train(model,data,nepochs=10, lambdaA=1e-8, lambdaB=1e-6, lr=0.001):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "#     optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "#     optimizer = T.optim.SGD(model.parameters(),lr=lr)\n",
    "    optimizer = T.optim.Adagrad(model.parameters(),lr=lr)\n",
    "#     optimizer = T.optim.Adadelta(model.parameters(),lr=lr)\n",
    "#     optimizer = T.optim.Adamax(model.parameters(),lr=lr)\n",
    "#     optimizer = T.optim.RMSprop(model.parameters(),lr=lr)\n",
    "    og_mem = T.cuda.memory_allocated() / 1024**2\n",
    "    print(\"Allocated Memory: {} MB\".format(og_mem))\n",
    "    for e in range(nepochs):\n",
    "        for batch_data in dataloader:\n",
    "            U,P,X, X_true = batch_data\n",
    "            X_pred = model(U,P,X)\n",
    "            mse_loss = F.mse_loss(X_pred,X_true)\n",
    "            l1_B = model.B.norm(1)\n",
    "            l1_A = model.A.norm(1)\n",
    "            \n",
    "            loss = mse_loss + lambdaA*l1_A + lambdaB*l1_B\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            del X_pred, U,P,X, X_true, mse_loss, l1_A, l1_B, loss\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            mem = T.cuda.memory_allocated() / 1024**2\n",
    "            print(\"New allocations: {} MB\".format(mem-og_mem))\n",
    "            og_mem = mem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntime = 2826\n",
    "nstim = 30\n",
    "nfeatures = 15888\n",
    "\n",
    "u_train = T.rand(ntime).cuda()\n",
    "p_train = T.rand(ntime).cuda()\n",
    "time_train = T.from_numpy(np.arange(ntime)).cuda()\n",
    "x_train = T.rand(ntime,nfeatures).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future_steps = 1\n",
    "batch_size = 1\n",
    "\n",
    "data = MyData(u_train,p_train,x_train,n_future_steps)\n",
    "model = Dynamics(data.nfeatures)\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,data,1,1e-4,1e-6,lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
