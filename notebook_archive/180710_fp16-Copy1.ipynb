{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import os\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from torchvision.transforms import Resize\n",
    "import dill\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "import resource\n",
    "import apex # https://github.com/NVIDIA/apex.git\n",
    "from apex.amp import amp\n",
    "\n",
    "import os, sys, datetime\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = False\n",
    "# gen = True\n",
    "cuda=True\n",
    "# half=True\n",
    "half=False\n",
    "\n",
    "if not gen:\n",
    "    f = all_data['e'][2]\n",
    "\n",
    "# time_fish = T.from_numpy(f.frame_st.mean(1).astype(np.float32)).cuda()\n",
    "# u_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "# p_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "# u_fish[numpy.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_gpu_memory_map():\n",
    "    \"\"\"Get the current gpu usage.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    usage: dict\n",
    "        Keys are device ids as integers.\n",
    "        Values are memory usage as integers in MB.\n",
    "    \"\"\"\n",
    "    result = subprocess.check_output(\n",
    "        [\n",
    "            'nvidia-smi', '--query-gpu=memory.used',\n",
    "            '--format=csv,nounits,noheader'\n",
    "        ])\n",
    "    # Convert lines into a dictionary\n",
    "    gpu_memory = [int(x) for x in result.strip().split('\\n')]\n",
    "    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n",
    "    return gpu_memory_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_from_z(z, fish,half=False):\n",
    "    tiff = fish.get_tif_rasl(z)\n",
    "    ntime = fish.frame_et.shape[0]\n",
    "    if half:\n",
    "        dtype = np.float16\n",
    "    else:\n",
    "        dtype = np.float32\n",
    "    frames = np.zeros((ntime, tiff.frame_shape[0],tiff.frame_shape[1])).astype(dtype)\n",
    "    for t in range(ntime):\n",
    "        frame = np.array(tiff.get_frame(t)).astype(dtype)\n",
    "        frames[t] = frame\n",
    "    return frames\n",
    "\n",
    "def get_imaging_from_fish(f,n_jobs=8, half=False):\n",
    "    nZ = f.num_zplanes\n",
    "    if half:\n",
    "        dtype = np.float16\n",
    "    else:\n",
    "        dtype = np.float32\n",
    "    # frames_by_z = pool.map(partial(get_frames_from_z, fish=f), range(nZ))\n",
    "    frames_by_z = Parallel(n_jobs=n_jobs)(delayed(get_frames_from_z)(z,fish=f) for z in range(nZ))\n",
    "    imaging = np.stack(frames_by_z).swapaxes(0,1).astype(dtype)\n",
    "    return imaging\n",
    "\n",
    "def gen_imaging(nT, nZ, H, W, half=False):\n",
    "    if half:\n",
    "        dtype = np.float16\n",
    "    else:\n",
    "        dtype = np.float32\n",
    "    return np.random.randint(0,3000,[nT,nZ,H,W]).astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_volume(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    new[0] = im\n",
    "    for i, img in enumerate(images[1:]):\n",
    "        new[i] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new\n",
    "\n",
    "def resize_batch(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0,0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],images.shape[1], im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    for b, vol in enumerate(images):\n",
    "        for z, img in enumerate(vol):\n",
    "            new[b,z] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gen:\n",
    "    imaging = gen_imaging(32,11,232,512)\n",
    "else:\n",
    "    imaging = get_imaging_from_fish(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('/home/ubuntu/f01555.npz',fish=imaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishImageData(Dataset):    \n",
    "    def __init__(self, imaging):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        self.data = T.from_numpy(data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data[idx+1]\n",
    "    \n",
    "class FishDiffData(Dataset):    \n",
    "    def __init__(self, imaging):\n",
    "        X = imaging - imaging.mean(0)\n",
    "        self.X = T.from_numpy(X)\n",
    "        self.Y = T.from_numpy(np.diff(X, axis=0))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "# data = FishImageData(imaging)\n",
    "data = FishDiffData(imaging)\n",
    "batch_size = 64\n",
    "nZ, H, W = data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_schedule(t,k=5):\n",
    "    t0 = t/2\n",
    "    k = k/t0\n",
    "    t = np.arange(t)\n",
    "    return (1/(1+np.exp(-k*(t-t0)))).astype(np.float32)\n",
    "\n",
    "plt.plot(sigmoid_schedule(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, layers[3], stride=2)\n",
    "#         self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "#         self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 232 x 512\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "#         print(x.shape)\n",
    "        # 58 x 128\n",
    "\n",
    "        x = self.layer1(x)\n",
    "#         print(x.shape)\n",
    "        # 29 x 64\n",
    "        x = self.layer2(x)\n",
    "#         print(x.shape)\n",
    "        # 15 x 32\n",
    "        x = self.layer3(x)\n",
    "#         print(x.shape)\n",
    "        # 8 x 16\n",
    "        x = self.layer4(x)\n",
    "        # 4 x 8\n",
    "        x = x.view(x.shape[0],-1).mean(1)\n",
    "        # 1 x 1\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "        return x[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(padding_type, kernel_size):\n",
    "    assert padding_type in ['SAME', 'VALID']\n",
    "    if padding_type == 'SAME':\n",
    "        return tuple((k - 1) // 2 for k in kernel_size)\n",
    "    return tuple(0 for _ in kernel_size)\n",
    "\n",
    "\n",
    "class Vol2D(nn.Module):\n",
    "    \"Use same 2D operations mapped over each z slice\"\n",
    "    def __init__(self, tensor=T.cuda.FloatTensor):\n",
    "        super(Vol2D, self).__init__()\n",
    "        self.tensor = tensor\n",
    "        \n",
    "    def vol_PixelShuffle(self, x):\n",
    "        # Helper for subpixel convolution\n",
    "        first = self.pixel_shuffle(x[:,0])\n",
    "        # b x z x H x W\n",
    "        ret = self.tensor(x.shape[0],x.shape[1],first.shape[2], first.shape[3])\n",
    "        for z in range(x.shape[1]):\n",
    "            ret[:,z] = self.pixel_shuffle(x[:,z])[:,0]\n",
    "        return ret\n",
    "        \n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def vol_MaxPool2d(self, x, kernel_size):\n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def vol_BatchNorm2d(self, x, bn):\n",
    "        activations = self.tensor(x.shape)\n",
    "        for z in range(x.shape[1]):\n",
    "            activations[:,z] = bn(x[:,z].contiguous())\n",
    "        return activations\n",
    "                \n",
    "    def vol_conv2d(self, x, weight, pad):\n",
    "        # batch x Z x C x H x W\n",
    "        activations = self.tensor(x.shape[0],x.shape[1],weight.shape[0],x.shape[3],x.shape[4])\n",
    "        for z in range(x.shape[1]):\n",
    "            activations[:,z] = F.conv2d(x[:,z], weight, padding=pad)\n",
    "        return activations\n",
    "    \n",
    "    def crop(self, x):\n",
    "        cropH = (x.shape[2] - self.H)/2\n",
    "        cropW = (x.shape[3] - self.W)/2\n",
    "        if cropH>0:\n",
    "            x = x[:,:,int(np.floor(cropH)):-int(np.ceil(cropH))]\n",
    "        if cropW>0:\n",
    "            x = x[:,:,:,int(np.floor(cropW)):-int(np.ceil(cropW))]\n",
    "        return x\n",
    "\n",
    "class SuperResBlock(Vol2D):\n",
    "    \"\"\"Upsample Volume using subpixel convolution.\n",
    "    \n",
    "    Reference: https://arxiv.org/pdf/1609.05158.pdf\"\"\"\n",
    "    def __init__(self, upscale_factor, tensor):\n",
    "        super(SuperResBlock, self).__init__(tensor=T.cuda.FloatTensor)\n",
    "        self.tensor = tensor\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dconv1 = nn.Parameter(self.tensor(64,1,5,5))\n",
    "        self.dpad1 = (2,2)\n",
    "        self.dbn1 = nn.BatchNorm2d(64)\n",
    "        self.dconv2 = nn.Parameter(self.tensor(64,64,3,3))\n",
    "        self.dpad2 = (1,1)\n",
    "        self.dbn2 = nn.BatchNorm2d(64)\n",
    "        self.dconv3 = nn.Parameter(self.tensor(32,64,3,3))\n",
    "        self.dpad3 = (1,1)\n",
    "        self.dbn3 = nn.BatchNorm2d(32)\n",
    "        self.dconv4 = nn.Parameter(self.tensor(upscale_factor**2,32,3,3))\n",
    "        self.dpad4 = (1,1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv1, self.dpad1), self.dbn1))\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv2, self.dpad2), self.dbn2))\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv3, self.dpad3), self.dbn3))\n",
    "        x = self.vol_conv2d(x, self.dconv4, self.dpad4)\n",
    "        x = self.vol_PixelShuffle(x)\n",
    "        # add back single channel\n",
    "        x = x[:,:,None]\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        if self.tensor==T.cuda.FloatTensor:\n",
    "            nn.init.orthogonal_(self.dconv1, nn.init.calculate_gain('relu'))\n",
    "            nn.init.orthogonal_(self.dconv2, nn.init.calculate_gain('relu'))\n",
    "            nn.init.orthogonal_(self.dconv3, nn.init.calculate_gain('relu'))\n",
    "            nn.init.orthogonal_(self.dconv4)\n",
    "        else:\n",
    "            for m in [self.dconv1, self.dconv2, self.dconv3, self.dconv4]:\n",
    "                nn.init.kaiming_normal_(m, mode='fan_out', nonlinearity='relu')\n",
    "        for bn in [self.dbn1,self.dbn2,self.dbn3]:\n",
    "            nn.init.constant_(bn.weight, 1)\n",
    "            nn.init.constant_(bn.bias, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_grad(params, params_with_grad):\n",
    "\n",
    "    for param, param_w_grad in zip(params, params_with_grad):\n",
    "        if param.grad is None:\n",
    "            param.grad = torch.nn.Parameter(param.data.new().resize_(*param.data.size()))\n",
    "        param.grad.copy_(param_w_grad.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tofp16(nn.Module):\n",
    "    \"\"\"\n",
    "    Model wrapper that implements::\n",
    "        def forward(self, input):\n",
    "            return input.half()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(tofp16, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input.cuda().half()\n",
    "\n",
    "\n",
    "def BN_convert_float(module):\n",
    "    '''\n",
    "    Designed to work with network_to_half.\n",
    "    BatchNorm layers need parameters in single precision.\n",
    "    Find all layers and convert them back to float. This can't\n",
    "    be done with built in .apply as that function will apply\n",
    "    fn to all modules, parameters, and buffers. Thus we wouldn't\n",
    "    be able to guard the float conversion based on the module type.\n",
    "    '''\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        module.float()\n",
    "    for child in module.children():\n",
    "        BN_convert_float(child)\n",
    "    return module\n",
    "\n",
    "\n",
    "def network_to_half(network):\n",
    "    \"\"\"\n",
    "    Convert model to half precision in a batchnorm-safe way.\n",
    "    \"\"\"\n",
    "    return nn.Sequential(tofp16(), BN_convert_float(network.half()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(Vol2D):\n",
    "    def __init__(self, nZ=11, H=232, W=512, nEmbedding=20, tensor=T.cuda.FloatTensor):\n",
    "        super(Conv, self).__init__(tensor)\n",
    "        self.tensor = tensor\n",
    "        self.nZ = nZ\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        self.lowH = 8\n",
    "        self.lowW = 16\n",
    "        self.lowFeatures = 1\n",
    "        # batch x channel x Z x H x W\n",
    "        # Encoding\n",
    "        self.resnet = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "        self.resOut = 1\n",
    "        \n",
    "        # b x 11 x 32 x 11 x 25\n",
    "        self.encoding_mean = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        self.encoding_logvar = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        \n",
    "        # Prediction\n",
    "        self.pred1 = nn.Linear(nEmbedding, nEmbedding)\n",
    "        self.pred2 = nn.Linear(nEmbedding, nEmbedding)\n",
    "        self.pred_bn1 = nn.BatchNorm1d(nEmbedding)\n",
    "        \n",
    "        # Decoding\n",
    "        self.activation = nn.Tanh() # change on Jul 9\n",
    "#         self.activation = nn.ReLU()\n",
    "        self.decoding = nn.Linear(nEmbedding,self.lowFeatures*nZ*self.lowH*self.lowW)\n",
    "        self.upconv1 = SuperResBlock(2,tensor)\n",
    "        # 11 x 16 x 32\n",
    "        self.upconv2 = SuperResBlock(2,tensor)\n",
    "        # 11 x 32 x 64\n",
    "        self.upconv3 = SuperResBlock(2,tensor)\n",
    "        # 11 x 64 x 128\n",
    "        self.upconv4 = SuperResBlock(2,tensor)\n",
    "        # 11 x 128 x 256\n",
    "        self.upconv5 = SuperResBlock(2,tensor)\n",
    "        # 11 x 256 x 512\n",
    "        \n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        nn.init.xavier_normal_(self.encoding_mean.weight)\n",
    "        # TODO - make larger?\n",
    "        nn.init.xavier_normal_(self.encoding_logvar.weight,1e-3)\n",
    "    \n",
    "    def sample_embedding(self, mu, logvar):\n",
    "        if self.training:\n",
    "            # during training so far, had this implementation which lowers logvar (until Jul 7, 2018)\n",
    "#             std = torch.exp(0.1*logvar)\n",
    "#             dist = T.distributions.normal.Normal(T.zeros_like(std),T.ones_like(std))\n",
    "#             std_z = dist.sample()\n",
    "#             return mu + std*std_z\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = x[:,:,None]\n",
    "        out = self.tensor(x.shape[0],x.shape[1],self.resOut)\n",
    "        for z in range(x.shape[1]):\n",
    "            out[:,z] = self.resnet(x[:,z])\n",
    "        mean = self.encoding_mean(out.reshape(x.shape[0],-1))\n",
    "        logvar = self.encoding_logvar(out.reshape(x.shape[0],-1))\n",
    "        return mean, logvar\n",
    "     \n",
    "    def predict(self, x):\n",
    "        x = self.activation(self.pred1(x))\n",
    "        x = self.pred2(x)\n",
    "        return x\n",
    "        \n",
    "    def decode(self, x):\n",
    "        # b x 20\n",
    "        x = self.activation(self.decoding(x))\n",
    "        x = x.reshape(x.shape[0],self.nZ,self.lowFeatures,self.lowH,self.lowW)\n",
    "        x = self.upconv1(x)\n",
    "        x = self.upconv2(x)\n",
    "        x = self.upconv3(x)\n",
    "        x = self.upconv4(x)\n",
    "        x = self.upconv5(x)\n",
    "        x = self.crop(x[:,:,0])\n",
    "        # squeeze channel\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"Return Previous volume (denoised), next volume (prediction), latent mean and logvar.\"\n",
    "        mean, logvar = self.encode(x)\n",
    "        encoded = self.sample_embedding(mean, logvar)\n",
    "        encoded_pred = self.predict(encoded)\n",
    "        prev = self.decode(encoded)\n",
    "        pred = self.decode(encoded_pred)\n",
    "        return prev, pred, mean, logvar\n",
    "\n",
    "    \n",
    "def unit_norm_KL_divergence(mu, logvar):\n",
    "    \"Reconstruction + KL divergence losses summed over all elements and batch.\"\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "\n",
    "def train(model,data,nepochs=10, lr=1e-3, half=False, cuda=True):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    kl_schedule = T.from_numpy(sigmoid_schedule(nepochs))\n",
    "    if half:\n",
    "        optimizer = apex.fp16_utils.FP16_Optimizer(T.optim.Adam(model.parameters(),lr=lr))\n",
    "    else:\n",
    "        optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "        \n",
    "    if cuda:\n",
    "        kl_schedule = kl_schedule.cuda()\n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        cum_X_loss = 0\n",
    "        cum_Y_loss = 0\n",
    "        for batch_data in tqdm(dataloader):\n",
    "            X, Y = batch_data\n",
    "            # add 1 channel\n",
    "            if cuda:\n",
    "                # half will alrea\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "            X_pred, Y_pred, mean, logvar = model(X)\n",
    "            if half:\n",
    "                X_pred = X_pred.float()\n",
    "                Y_pred = Y_pred.float()\n",
    "                mean = mean.float()\n",
    "                logvar = logvar.float()\n",
    "            kld = unit_norm_KL_divergence(mean, logvar)\n",
    "            mse_X = F.mse_loss(X_pred, X, size_average=False) # was size_average=False until July 9\n",
    "            mse_Y = F.mse_loss(Y_pred, Y,size_average=False)\n",
    "            loss = mse_X + mse_Y + kl_schedule[e] * kld\n",
    "            if e==0:\n",
    "                print(\"MSE_X: {:.3E}, MSE_Y: {:.3E}, KLD: {:.3E}\".format(float(mse_X),float(mse_Y),float(kld)))\n",
    "            optimizer.zero_grad()\n",
    "            if half:\n",
    "                optimizer.backward(loss)\n",
    "            else:\n",
    "                loss.backward()\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "            cum_X_loss += float(mse_X)\n",
    "            cum_Y_loss += float(mse_Y)\n",
    "\n",
    "        print(\"avg_loss: {:3E}, X_loss: {:3E}, Y_loss: {:3E}\".format(\n",
    "            cum_loss/len(data), cum_X_loss/len(data), cum_Y_loss/len(data)))        \n",
    "\n",
    "nEmbedding = 10\n",
    "batch_size = 6\n",
    "nZ, H, W = data[0][0].shape\n",
    "\n",
    "tensorlib = T\n",
    "if cuda:\n",
    "    tensorlib = T.cuda\n",
    "\n",
    "if half:\n",
    "    tensor = tensorlib.HalfTensor\n",
    "else:\n",
    "    tensor = tensorlib.FloatTensor\n",
    "\n",
    "conv_model = Conv(nZ,H,W,nEmbedding,tensor=tensor)\n",
    "if cuda:\n",
    "    conv_model.cuda()\n",
    "if half:\n",
    "    conv_model = apex.fp16_utils.network_to_half(conv_model)\n",
    "print(\"total num params:\", np.sum([np.prod(x.shape) for x in conv_model.parameters()]))\n",
    "# conv_model(data[0][0][None,:,None].cuda()).shape\n",
    "train(conv_model,data,100,lr=1e-3, half=half, cuda=cuda)\n",
    "# 1.91E+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sz_avg=False:\n",
    "epoch 1: avg_loss: 9.025106E+09, X_loss: 4.514291E+09, Y_loss: 4.510816E+09\n",
    "epoch 2: avg_loss: 8.635393E+09, X_loss: 4.316321E+09, Y_loss: 4.319072E+09\n",
    "epoch 3: avg_loss: 8.425725E+09, X_loss: 4.211480E+09, Y_loss: 4.214245E+09\n",
    "epoch 4: avg_loss: 8.304267E+09, X_loss: 4.150881E+09, Y_loss: 4.153385E+09\n",
    "epoch 5: avg_loss: 8.211217E+09, X_loss: 4.104135E+09, Y_loss: 4.107081E+09\n",
    "epoch 6: avg_loss: 8.154908E+09, X_loss: 4.075904E+09, Y_loss: 4.079004E+09\n",
    "epoch 7: avg_loss: 8.105444E+09, X_loss: 4.051218E+09, Y_loss: 4.054226E+09\n",
    "epoch 8: avg_loss: 8.059247E+09, X_loss: 4.028319E+09, Y_loss: 4.030929E+09\n",
    "epoch 9: avg_loss: 8.023846E+09, X_loss: 4.010521E+09, Y_loss: 4.013325E+09\n",
    "epoch 10: avg_loss: 7.959344E+09, X_loss: 3.978424E+09, Y_loss: 3.980920E+09\n",
    "epoch 12: avg_loss: 7.937324E+09, X_loss: 3.966849E+09, Y_loss: 3.970475E+09\n",
    "epoch 13: avg_loss: 7.913101E+09, X_loss: 3.954937E+09, Y_loss: 3.958164E+09\n",
    "epoch 14: avg_loss: 7.887365E+09, X_loss: 3.942145E+09, Y_loss: 3.945220E+09\n",
    "epoch 15: avg_loss: 7.866695E+09, X_loss: 3.931801E+09, Y_loss: 3.934894E+09\n",
    "epoch 16: avg_loss: 7.850621E+09, X_loss: 3.923779E+09, Y_loss: 3.926842E+09\n",
    "epoch 17: avg_loss: 7.832272E+09, X_loss: 3.914669E+09, Y_loss: 3.917603E+09\n",
    "epoch 18: avg_loss: 7.811225E+09, X_loss: 3.904124E+09, Y_loss: 3.907101E+09\n",
    "epoch 19: avg_loss: 7.797960E+09, X_loss: 3.897282E+09, Y_loss: 3.900678E+09\n",
    "epoch 20: avg_loss: 7.784135E+09, X_loss: 3.890460E+09, Y_loss: 3.893674E+09\n",
    "epoch 21: avg_loss: 7.769884E+09, X_loss: 3.883294E+09, Y_loss: 3.886589E+09\n",
    "epoch 22: avg_loss: 7.757159E+09, X_loss: 3.876780E+09, Y_loss: 3.880379E+09\n",
    "epoch 23: avg_loss: 7.741684E+09, X_loss: 3.869390E+09, Y_loss: 3.872294E+09\n",
    "epoch 24: avg_loss: 7.733636E+09, X_loss: 3.865235E+09, Y_loss: 3.868401E+09\n",
    "epoch 25: avg_loss: 7.721238E+09, X_loss: 3.859067E+09, Y_loss: 3.862171E+09\n",
    "epoch 26: avg_loss: 7.714142E+09, X_loss: 3.855281E+09, Y_loss: 3.858861E+09\n",
    "epoch 27: avg_loss: 7.696866E+09, X_loss: 3.846964E+09, Y_loss: 3.849902E+09\n",
    "epoch 28: avg_loss: 7.694627E+09, X_loss: 3.845731E+09, Y_loss: 3.848896E+09\n",
    "epoch 29: avg_loss: 7.693011E+09, X_loss: 3.844707E+09, Y_loss: 3.848303E+09\n",
    "Autoencoder\n",
    "Name\n",
    "Last Modified\n",
    "\n",
    "import torch as T\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import scipy.linalg\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "%pylab\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sb\n",
    "\n",
    "import os\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "from torchvision.transforms import Resize\n",
    "\n",
    "import dill\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import cv2\n",
    "\n",
    "import resource\n",
    "\n",
    "import apex # https://github.com/NVIDIA/apex.git\n",
    "\n",
    "from apex.amp import amp\n",
    "\n",
    "​\n",
    "\n",
    "import os, sys, datetime\n",
    "\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "​\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "\n",
    "reload(p2putils)\n",
    "\n",
    "tmp_dir = '/tmp/'\n",
    "\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
    "  (fname, cnt))\n",
    "/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
    "  (fname, cnt))\n",
    "\n",
    "Using matplotlib backend: agg\n",
    "Populating the interactive namespace from numpy and matplotlib\n",
    "\n",
    "/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
    "  from ._conv import register_converters as _register_converters\n",
    "\n",
    "gen = False\n",
    "\n",
    "# gen = True\n",
    "\n",
    "cuda=True\n",
    "\n",
    "# half=True\n",
    "\n",
    "half=False\n",
    "\n",
    "​\n",
    "\n",
    "if not gen:\n",
    "\n",
    "    f = all_data['e'][2]\n",
    "\n",
    "​\n",
    "\n",
    "# time_fish = T.from_numpy(f.frame_st.mean(1).astype(np.float32)).cuda()\n",
    "\n",
    "# u_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "\n",
    "# p_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "\n",
    "# u_fish[numpy.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1\n",
    "\n",
    "import subprocess\n",
    "\n",
    "​\n",
    "\n",
    "def get_gpu_memory_map():\n",
    "\n",
    "    \"\"\"Get the current gpu usage.\n",
    "\n",
    "​\n",
    "\n",
    "    Returns\n",
    "\n",
    "    -------\n",
    "\n",
    "    usage: dict\n",
    "\n",
    "        Keys are device ids as integers.\n",
    "\n",
    "        Values are memory usage as integers in MB.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    result = subprocess.check_output(\n",
    "\n",
    "        [\n",
    "\n",
    "            'nvidia-smi', '--query-gpu=memory.used',\n",
    "\n",
    "            '--format=csv,nounits,noheader'\n",
    "\n",
    "        ])\n",
    "\n",
    "    # Convert lines into a dictionary\n",
    "\n",
    "    gpu_memory = [int(x) for x in result.strip().split('\\n')]\n",
    "\n",
    "    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n",
    "\n",
    "    return gpu_memory_map\n",
    "\n",
    "def get_frames_from_z(z, fish,half=False):\n",
    "\n",
    "    tiff = fish.get_tif_rasl(z)\n",
    "\n",
    "    ntime = fish.frame_et.shape[0]\n",
    "\n",
    "    if half:\n",
    "\n",
    "        dtype = np.float16\n",
    "\n",
    "    else:\n",
    "\n",
    "        dtype = np.float32\n",
    "\n",
    "    frames = np.zeros((ntime, tiff.frame_shape[0],tiff.frame_shape[1])).astype(dtype)\n",
    "\n",
    "    for t in range(ntime):\n",
    "\n",
    "        frame = np.array(tiff.get_frame(t)).astype(dtype)\n",
    "\n",
    "        frames[t] = frame\n",
    "\n",
    "    return frames\n",
    "\n",
    "​\n",
    "\n",
    "def get_imaging_from_fish(f,n_jobs=8, half=False):\n",
    "\n",
    "    nZ = f.num_zplanes\n",
    "\n",
    "    if half:\n",
    "\n",
    "        dtype = np.float16\n",
    "\n",
    "    else:\n",
    "\n",
    "        dtype = np.float32\n",
    "\n",
    "    # frames_by_z = pool.map(partial(get_frames_from_z, fish=f), range(nZ))\n",
    "\n",
    "    frames_by_z = Parallel(n_jobs=n_jobs)(delayed(get_frames_from_z)(z,fish=f) for z in range(nZ))\n",
    "\n",
    "    imaging = np.stack(frames_by_z).swapaxes(0,1).astype(dtype)\n",
    "\n",
    "    return imaging\n",
    "\n",
    "​\n",
    "\n",
    "def gen_imaging(nT, nZ, H, W, half=False):\n",
    "\n",
    "    if half:\n",
    "\n",
    "        dtype = np.float16\n",
    "\n",
    "    else:\n",
    "\n",
    "        dtype = np.float32\n",
    "\n",
    "    return np.random.randint(0,3000,[nT,nZ,H,W]).astype(dtype)\n",
    "\n",
    "def resize_volume(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "\n",
    "    im = cv2.resize(images[0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "\n",
    "    new = np.zeros([images.shape[0],im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "\n",
    "    new[0] = im\n",
    "\n",
    "    for i, img in enumerate(images[1:]):\n",
    "\n",
    "        new[i] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "\n",
    "    return new\n",
    "\n",
    "​\n",
    "\n",
    "def resize_batch(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "\n",
    "    im = cv2.resize(images[0,0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "\n",
    "    new = np.zeros([images.shape[0],images.shape[1], im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "\n",
    "    for b, vol in enumerate(images):\n",
    "\n",
    "        for z, img in enumerate(vol):\n",
    "\n",
    "            new[b,z] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "\n",
    "    return new\n",
    "\n",
    "if gen:\n",
    "\n",
    "    imaging = gen_imaging(32,11,232,512)\n",
    "\n",
    "else:\n",
    "\n",
    "    imaging = get_imaging_from_fish(f)\n",
    "\n",
    "​\n",
    "\n",
    "np.savez('/home/ubuntu/f01555.npz',fish=imaging)\n",
    "\n",
    "class FishImageData(Dataset):    \n",
    "\n",
    "    def __init__(self, imaging):\n",
    "\n",
    "        data = imaging - imaging.mean(0)\n",
    "\n",
    "        self.data = T.from_numpy(data)\n",
    "\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.data.shape[0]-1\n",
    "\n",
    "​\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.data[idx], self.data[idx+1]\n",
    "\n",
    "    \n",
    "\n",
    "class FishDiffData(Dataset):    \n",
    "\n",
    "    def __init__(self, imaging):\n",
    "\n",
    "        X = imaging - imaging.mean(0)\n",
    "\n",
    "        self.X = T.from_numpy(X)\n",
    "\n",
    "        self.Y = T.from_numpy(np.diff(X, axis=0))\n",
    "\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.Y.shape[0]\n",
    "\n",
    "​\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "​\n",
    "\n",
    "# data = FishImageData(imaging)\n",
    "\n",
    "data = FishDiffData(imaging)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "nZ, H, W = data[0][0].shape\n",
    "\n",
    "def sigmoid_schedule(t,k=5):\n",
    "\n",
    "    t0 = t/2\n",
    "\n",
    "    k = k/t0\n",
    "\n",
    "    t = np.arange(t)\n",
    "\n",
    "    return (1/(1+np.exp(-k*(t-t0)))).astype(np.float32)\n",
    "\n",
    "​\n",
    "\n",
    "plt.plot(sigmoid_schedule(20,5))\n",
    "\n",
    "[<matplotlib.lines.Line2D at 0x7ffa4c3f95d0>]\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import math\n",
    "\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    expansion = 1\n",
    "\n",
    "​\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "        self.stride = stride\n",
    "\n",
    "​\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        residual = x\n",
    "\n",
    "​\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        out = self.bn1(out)\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "​\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.bn2(out)\n",
    "\n",
    "​\n",
    "\n",
    "        if self.downsample is not None:\n",
    "\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "​\n",
    "\n",
    "        out += residual\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "​\n",
    "\n",
    "        return out\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "​\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "\n",
    "        self.inplanes = 64\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "\n",
    "                               bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=2)\n",
    "\n",
    "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2)\n",
    "\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "\n",
    "        self.layer4 = self._make_layer(block, 64, layers[3], stride=2)\n",
    "\n",
    "#         self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "\n",
    "#         self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "​\n",
    "\n",
    "        for m in self.modules():\n",
    "\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "​\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "\n",
    "        downsample = None\n",
    "\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "\n",
    "            downsample = nn.Sequential(\n",
    "\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "\n",
    "            )\n",
    "\n",
    "​\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "\n",
    "        self.inplanes = planes * block.expansion\n",
    "\n",
    "        for i in range(1, blocks):\n",
    "\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "​\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "​\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # 232 x 512\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "#         print(x.shape)\n",
    "\n",
    "        # 58 x 128\n",
    "\n",
    "​\n",
    "\n",
    "        x = self.layer1(x)\n",
    "\n",
    "#         print(x.shape)\n",
    "\n",
    "        # 29 x 64\n",
    "\n",
    "        x = self.layer2(x)\n",
    "\n",
    "#         print(x.shape)\n",
    "\n",
    "        # 15 x 32\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "#         print(x.shape)\n",
    "\n",
    "        # 8 x 16\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        # 4 x 8\n",
    "\n",
    "        x = x.view(x.shape[0],-1).mean(1)\n",
    "\n",
    "        # 1 x 1\n",
    "\n",
    "#         x = x.view(x.size(0), -1)\n",
    "\n",
    "#         x = self.fc(x)\n",
    "\n",
    "        return x[:,None]\n",
    "\n",
    "def get_padding(padding_type, kernel_size):\n",
    "\n",
    "    assert padding_type in ['SAME', 'VALID']\n",
    "\n",
    "    if padding_type == 'SAME':\n",
    "\n",
    "        return tuple((k - 1) // 2 for k in kernel_size)\n",
    "\n",
    "    return tuple(0 for _ in kernel_size)\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "class Vol2D(nn.Module):\n",
    "\n",
    "    \"Use same 2D operations mapped over each z slice\"\n",
    "\n",
    "    def __init__(self, tensor=T.cuda.FloatTensor):\n",
    "\n",
    "        super(Vol2D, self).__init__()\n",
    "\n",
    "        self.tensor = tensor\n",
    "\n",
    "        \n",
    "\n",
    "    def vol_PixelShuffle(self, x):\n",
    "\n",
    "        # Helper for subpixel convolution\n",
    "\n",
    "        first = self.pixel_shuffle(x[:,0])\n",
    "\n",
    "        # b x z x H x W\n",
    "\n",
    "        ret = self.tensor(x.shape[0],x.shape[1],first.shape[2], first.shape[3])\n",
    "\n",
    "        for z in range(x.shape[1]):\n",
    "\n",
    "            ret[:,z] = self.pixel_shuffle(x[:,z])[:,0]\n",
    "\n",
    "        return ret\n",
    "\n",
    "        \n",
    "\n",
    "        # batch x Z*C x H x W\n",
    "\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "\n",
    "    \n",
    "\n",
    "    def vol_MaxPool2d(self, x, kernel_size):\n",
    "\n",
    "        # batch x Z*C x H x W\n",
    "\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "\n",
    "    \n",
    "\n",
    "    def vol_BatchNorm2d(self, x, bn):\n",
    "\n",
    "        activations = self.tensor(x.shape)\n",
    "\n",
    "        for z in range(x.shape[1]):\n",
    "\n",
    "            activations[:,z] = bn(x[:,z].contiguous())\n",
    "\n",
    "        return activations\n",
    "\n",
    "                \n",
    "\n",
    "    def vol_conv2d(self, x, weight, pad):\n",
    "\n",
    "        # batch x Z x C x H x W\n",
    "\n",
    "        activations = self.tensor(x.shape[0],x.shape[1],weight.shape[0],x.shape[3],x.shape[4])\n",
    "\n",
    "        for z in range(x.shape[1]):\n",
    "\n",
    "            activations[:,z] = F.conv2d(x[:,z], weight, padding=pad)\n",
    "\n",
    "        return activations\n",
    "\n",
    "    \n",
    "\n",
    "    def crop(self, x):\n",
    "\n",
    "        cropH = (x.shape[2] - self.H)/2\n",
    "\n",
    "        cropW = (x.shape[3] - self.W)/2\n",
    "\n",
    "        if cropH>0:\n",
    "\n",
    "            x = x[:,:,int(np.floor(cropH)):-int(np.ceil(cropH))]\n",
    "\n",
    "        if cropW>0:\n",
    "\n",
    "            x = x[:,:,:,int(np.floor(cropW)):-int(np.ceil(cropW))]\n",
    "\n",
    "        return x\n",
    "\n",
    "​\n",
    "\n",
    "class SuperResBlock(Vol2D):\n",
    "\n",
    "    \"\"\"Upsample Volume using subpixel convolution.\n",
    "\n",
    "    \n",
    "\n",
    "    Reference: https://arxiv.org/pdf/1609.05158.pdf\"\"\"\n",
    "\n",
    "    def __init__(self, upscale_factor, tensor):\n",
    "\n",
    "        super(SuperResBlock, self).__init__(tensor=T.cuda.FloatTensor)\n",
    "\n",
    "        self.tensor = tensor\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        self.dconv1 = nn.Parameter(self.tensor(64,1,5,5))\n",
    "\n",
    "        self.dpad1 = (2,2)\n",
    "\n",
    "        self.dbn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.dconv2 = nn.Parameter(self.tensor(64,64,3,3))\n",
    "\n",
    "        self.dpad2 = (1,1)\n",
    "\n",
    "        self.dbn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.dconv3 = nn.Parameter(self.tensor(32,64,3,3))\n",
    "\n",
    "        self.dpad3 = (1,1)\n",
    "\n",
    "        self.dbn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.dconv4 = nn.Parameter(self.tensor(upscale_factor**2,32,3,3))\n",
    "\n",
    "        self.dpad4 = (1,1)\n",
    "\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        \n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "​\n",
    "\n",
    "    def forward(self, x):        \n",
    "\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv1, self.dpad1), self.dbn1))\n",
    "\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv2, self.dpad2), self.dbn2))\n",
    "\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv3, self.dpad3), self.dbn3))\n",
    "\n",
    "        x = self.vol_conv2d(x, self.dconv4, self.dpad4)\n",
    "\n",
    "        x = self.vol_PixelShuffle(x)\n",
    "\n",
    "        # add back single channel\n",
    "\n",
    "        x = x[:,:,None]\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "    def initialize_weights(self):\n",
    "\n",
    "        if self.tensor==T.cuda.FloatTensor:\n",
    "\n",
    "            nn.init.orthogonal_(self.dconv1, nn.init.calculate_gain('relu'))\n",
    "\n",
    "            nn.init.orthogonal_(self.dconv2, nn.init.calculate_gain('relu'))\n",
    "\n",
    "            nn.init.orthogonal_(self.dconv3, nn.init.calculate_gain('relu'))\n",
    "\n",
    "            nn.init.orthogonal_(self.dconv4)\n",
    "\n",
    "        else:\n",
    "\n",
    "            for m in [self.dconv1, self.dconv2, self.dconv3, self.dconv4]:\n",
    "\n",
    "                nn.init.kaiming_normal_(m, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "        for bn in [self.dbn1,self.dbn2,self.dbn3]:\n",
    "\n",
    "            nn.init.constant_(bn.weight, 1)\n",
    "\n",
    "            nn.init.constant_(bn.bias, 0)\n",
    "\n",
    "    \n",
    "\n",
    "def set_grad(params, params_with_grad):\n",
    "\n",
    "​\n",
    "\n",
    "    for param, param_w_grad in zip(params, params_with_grad):\n",
    "\n",
    "        if param.grad is None:\n",
    "\n",
    "            param.grad = torch.nn.Parameter(param.data.new().resize_(*param.data.size()))\n",
    "\n",
    "        param.grad.copy_(param_w_grad.grad.data)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "class tofp16(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Model wrapper that implements::\n",
    "\n",
    "        def forward(self, input):\n",
    "\n",
    "            return input.half()\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "​\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(tofp16, self).__init__()\n",
    "\n",
    "​\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        return input.cuda().half()\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "def BN_convert_float(module):\n",
    "\n",
    "    '''\n",
    "\n",
    "    Designed to work with network_to_half.\n",
    "\n",
    "    BatchNorm layers need parameters in single precision.\n",
    "\n",
    "    Find all layers and convert them back to float. This can't\n",
    "\n",
    "    be done with built in .apply as that function will apply\n",
    "\n",
    "    fn to all modules, parameters, and buffers. Thus we wouldn't\n",
    "\n",
    "    be able to guard the float conversion based on the module type.\n",
    "\n",
    "    '''\n",
    "\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "\n",
    "        module.float()\n",
    "\n",
    "    for child in module.children():\n",
    "\n",
    "        BN_convert_float(child)\n",
    "\n",
    "    return module\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "def network_to_half(network):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Convert model to half precision in a batchnorm-safe way.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return nn.Sequential(tofp16(), BN_convert_float(network.half()))\n",
    "\n",
    "class Conv(Vol2D):\n",
    "\n",
    "    def __init__(self, nZ=11, H=232, W=512, nEmbedding=20, tensor=T.cuda.FloatTensor):\n",
    "\n",
    "        super(Conv, self).__init__(tensor)\n",
    "\n",
    "        self.tensor = tensor\n",
    "\n",
    "        self.nZ = nZ\n",
    "\n",
    "        self.H = H\n",
    "\n",
    "        self.W = W\n",
    "\n",
    "        self.lowH = 8\n",
    "\n",
    "        self.lowW = 16\n",
    "\n",
    "        self.lowFeatures = 1\n",
    "\n",
    "        # batch x channel x Z x H x W\n",
    "\n",
    "        # Encoding\n",
    "\n",
    "        self.resnet = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "        self.resOut = 1\n",
    "\n",
    "        \n",
    "\n",
    "        # b x 11 x 32 x 11 x 25\n",
    "\n",
    "        self.encoding_mean = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "\n",
    "        self.encoding_logvar = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "\n",
    "        \n",
    "\n",
    "        # Prediction\n",
    "\n",
    "        self.pred1 = nn.Linear(nEmbedding, nEmbedding)\n",
    "\n",
    "        self.pred2 = nn.Linear(nEmbedding, nEmbedding)\n",
    "\n",
    "        self.pred_bn1 = nn.BatchNorm1d(nEmbedding)\n",
    "\n",
    "        \n",
    "\n",
    "        # Decoding\n",
    "\n",
    "        self.activation = nn.Tanh() # change on Jul 9\n",
    "\n",
    "#         self.activation = nn.ReLU()\n",
    "\n",
    "        self.decoding = nn.Linear(nEmbedding,self.lowFeatures*nZ*self.lowH*self.lowW)\n",
    "\n",
    "        self.upconv1 = SuperResBlock(2,tensor)\n",
    "\n",
    "        # 11 x 16 x 32\n",
    "\n",
    "        self.upconv2 = SuperResBlock(2,tensor)\n",
    "\n",
    "        # 11 x 32 x 64\n",
    "\n",
    "        self.upconv3 = SuperResBlock(2,tensor)\n",
    "\n",
    "        # 11 x 64 x 128\n",
    "\n",
    "        self.upconv4 = SuperResBlock(2,tensor)\n",
    "\n",
    "        # 11 x 128 x 256\n",
    "\n",
    "        self.upconv5 = SuperResBlock(2,tensor)\n",
    "\n",
    "        # 11 x 256 x 512\n",
    "\n",
    "        \n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "        \n",
    "\n",
    "    def _initialize_weights(self):\n",
    "\n",
    "        nn.init.xavier_normal_(self.encoding_mean.weight)\n",
    "\n",
    "        # TODO - make larger?\n",
    "\n",
    "        nn.init.xavier_normal_(self.encoding_logvar.weight,1e-3)\n",
    "\n",
    "    \n",
    "\n",
    "    def sample_embedding(self, mu, logvar):\n",
    "\n",
    "        if self.training:\n",
    "\n",
    "            # during training so far, had this implementation which lowers logvar (until Jul 7, 2018)\n",
    "\n",
    "#             std = torch.exp(0.1*logvar)\n",
    "\n",
    "#             dist = T.distributions.normal.Normal(T.zeros_like(std),T.ones_like(std))\n",
    "\n",
    "#             std_z = dist.sample()\n",
    "\n",
    "#             return mu + std*std_z\n",
    "\n",
    "            std = torch.exp(0.5*logvar)\n",
    "\n",
    "            eps = torch.randn_like(std)\n",
    "\n",
    "            return eps.mul(std).add_(mu)\n",
    "\n",
    "        else:\n",
    "\n",
    "            return mu\n",
    "\n",
    "    \n",
    "\n",
    "    def encode(self, x):\n",
    "\n",
    "        x = x[:,:,None]\n",
    "\n",
    "        out = self.tensor(x.shape[0],x.shape[1],self.resOut)\n",
    "\n",
    "        for z in range(x.shape[1]):\n",
    "\n",
    "            out[:,z] = self.resnet(x[:,z])\n",
    "\n",
    "        mean = self.encoding_mean(out.reshape(x.shape[0],-1))\n",
    "\n",
    "        logvar = self.encoding_logvar(out.reshape(x.shape[0],-1))\n",
    "\n",
    "        return mean, logvar\n",
    "\n",
    "     \n",
    "\n",
    "    def predict(self, x):\n",
    "\n",
    "        x = self.activation(self.pred1(x))\n",
    "\n",
    "        x = self.pred2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "        \n",
    "\n",
    "    def decode(self, x):\n",
    "\n",
    "        # b x 20\n",
    "\n",
    "        x = self.activation(self.decoding(x))\n",
    "\n",
    "        x = x.reshape(x.shape[0],self.nZ,self.lowFeatures,self.lowH,self.lowW)\n",
    "\n",
    "        x = self.upconv1(x)\n",
    "\n",
    "        x = self.upconv2(x)\n",
    "\n",
    "        x = self.upconv3(x)\n",
    "\n",
    "        x = self.upconv4(x)\n",
    "\n",
    "        x = self.upconv5(x)\n",
    "\n",
    "        x = self.crop(x[:,:,0])\n",
    "\n",
    "        # squeeze channel\n",
    "\n",
    "        return x\n",
    "\n",
    "​\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        \"Return Previous volume (denoised), next volume (prediction), latent mean and logvar.\"\n",
    "\n",
    "        mean, logvar = self.encode(x)\n",
    "\n",
    "        encoded = self.sample_embedding(mean, logvar)\n",
    "\n",
    "        encoded_pred = self.predict(encoded)\n",
    "\n",
    "        prev = self.decode(encoded)\n",
    "\n",
    "        pred = self.decode(encoded_pred)\n",
    "\n",
    "        return prev, pred, mean, logvar\n",
    "\n",
    "​\n",
    "\n",
    "    \n",
    "\n",
    "def unit_norm_KL_divergence(mu, logvar):\n",
    "\n",
    "    \"Reconstruction + KL divergence losses summed over all elements and batch.\"\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "\n",
    "    return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "def train(model,data,nepochs=10, lr=1e-3, half=False, cuda=True):\n",
    "\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    kl_schedule = T.from_numpy(sigmoid_schedule(nepochs))\n",
    "\n",
    "    if half:\n",
    "\n",
    "        optimizer = apex.fp16_utils.FP16_Optimizer(T.optim.Adam(model.parameters(),lr=lr))\n",
    "\n",
    "    else:\n",
    "\n",
    "        optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "\n",
    "        \n",
    "\n",
    "    if cuda:\n",
    "\n",
    "        kl_schedule = kl_schedule.cuda()\n",
    "\n",
    "    for e in range(nepochs):\n",
    "\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "\n",
    "        cum_loss = 0\n",
    "\n",
    "        cum_X_loss = 0\n",
    "\n",
    "        cum_Y_loss = 0\n",
    "\n",
    "        for batch_data in tqdm(dataloader):\n",
    "\n",
    "            X, Y = batch_data\n",
    "\n",
    "            # add 1 channel\n",
    "\n",
    "            if cuda:\n",
    "\n",
    "                # half will alrea\n",
    "\n",
    "                X = X.cuda()\n",
    "\n",
    "                Y = Y.cuda()\n",
    "\n",
    "            X_pred, Y_pred, mean, logvar = model(X)\n",
    "\n",
    "            if half:\n",
    "\n",
    "                X_pred = X_pred.float()\n",
    "\n",
    "                Y_pred = Y_pred.float()\n",
    "\n",
    "                mean = mean.float()\n",
    "\n",
    "                logvar = logvar.float()\n",
    "\n",
    "            kld = unit_norm_KL_divergence(mean, logvar)\n",
    "\n",
    "            mse_X = F.mse_loss(X_pred, X, size_average=False) # was size_average=False until July 9\n",
    "\n",
    "            mse_Y = F.mse_loss(Y_pred, Y,size_average=False)\n",
    "\n",
    "            loss = mse_X + mse_Y + kl_schedule[e] * kld\n",
    "\n",
    "            if e==0:\n",
    "\n",
    "                print(\"MSE_X: {:.3E}, MSE_Y: {:.3E}, KLD: {:.3E}\".format(float(mse_X),float(mse_Y),float(kld)))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if half:\n",
    "\n",
    "                optimizer.backward(loss)\n",
    "\n",
    "            else:\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            cum_loss += float(loss)\n",
    "\n",
    "            cum_X_loss += float(mse_X)\n",
    "\n",
    "            cum_Y_loss += float(mse_Y)\n",
    "\n",
    "​\n",
    "\n",
    "        print(\"avg_loss: {:3E}, X_loss: {:3E}, Y_loss: {:3E}\".format(\n",
    "\n",
    "            cum_loss/len(data), cum_X_loss/len(data), cum_Y_loss/len(data)))        \n",
    "\n",
    "​\n",
    "\n",
    "nEmbedding = 10\n",
    "\n",
    "batch_size = 6\n",
    "\n",
    "nZ, H, W = data[0][0].shape\n",
    "\n",
    "​\n",
    "\n",
    "tensorlib = T\n",
    "\n",
    "if cuda:\n",
    "\n",
    "    tensorlib = T.cuda\n",
    "\n",
    "​\n",
    "\n",
    "if half:\n",
    "\n",
    "    tensor = tensorlib.HalfTensor\n",
    "\n",
    "else:\n",
    "\n",
    "    tensor = tensorlib.FloatTensor\n",
    "\n",
    "​\n",
    "\n",
    "conv_model = Conv(nZ,H,W,nEmbedding,tensor=tensor)\n",
    "\n",
    "if cuda:\n",
    "\n",
    "    conv_model.cuda()\n",
    "\n",
    "if half:\n",
    "\n",
    "    conv_model = apex.fp16_utils.network_to_half(conv_model)\n",
    "\n",
    "print(\"total num params:\", np.sum([np.prod(x.shape) for x in conv_model.parameters()]))\n",
    "\n",
    "# conv_model(data[0][0][None,:,None].cuda()).shape\n",
    "\n",
    "train(conv_model,data,100,lr=1e-3, half=half, cuda=cuda)\n",
    "\n",
    "# 1.91E+02\n",
    "\n",
    "total num params: 919840\n",
    "epoch 0: \n",
    "\n",
    "100% 471/471 [09:06<00:00, 1.16s/it]\n",
    "\n",
    "MSE_X: 2.752E+10, MSE_Y: 3.992E+10, KLD: 2.277E+01\n",
    "MSE_X: 2.746E+10, MSE_Y: 3.924E+10, KLD: 2.214E+01\n",
    "MSE_X: 3.113E+10, MSE_Y: 4.124E+10, KLD: 2.237E+01\n",
    "MSE_X: 3.693E+10, MSE_Y: 4.407E+10, KLD: 2.371E+01\n",
    "MSE_X: 3.141E+10, MSE_Y: 4.013E+10, KLD: 2.398E+01\n",
    "MSE_X: 3.337E+10, MSE_Y: 4.249E+10, KLD: 2.445E+01\n",
    "MSE_X: 2.685E+10, MSE_Y: 3.921E+10, KLD: 2.444E+01\n",
    "MSE_X: 2.720E+10, MSE_Y: 3.911E+10, KLD: 2.462E+01\n",
    "MSE_X: 2.777E+10, MSE_Y: 3.871E+10, KLD: 2.472E+01\n",
    "MSE_X: 2.890E+10, MSE_Y: 3.887E+10, KLD: 2.465E+01\n",
    "MSE_X: 3.201E+10, MSE_Y: 4.181E+10, KLD: 2.491E+01\n",
    "MSE_X: 2.911E+10, MSE_Y: 4.000E+10, KLD: 2.488E+01\n",
    "MSE_X: 3.272E+10, MSE_Y: 4.272E+10, KLD: 2.507E+01\n",
    "MSE_X: 2.540E+10, MSE_Y: 3.845E+10, KLD: 2.515E+01\n",
    "MSE_X: 2.725E+10, MSE_Y: 3.850E+10, KLD: 2.512E+01\n",
    "MSE_X: 2.906E+10, MSE_Y: 4.003E+10, KLD: 2.504E+01\n",
    "MSE_X: 2.548E+10, MSE_Y: 3.796E+10, KLD: 2.514E+01\n",
    "MSE_X: 2.824E+10, MSE_Y: 3.944E+10, KLD: 2.521E+01\n",
    "MSE_X: 2.938E+10, MSE_Y: 4.229E+10, KLD: 2.515E+01\n",
    "MSE_X: 3.298E+10, MSE_Y: 4.188E+10, KLD: 2.523E+01\n",
    "MSE_X: 3.125E+10, MSE_Y: 4.146E+10, KLD: 2.521E+01\n",
    "MSE_X: 3.009E+10, MSE_Y: 3.791E+10, KLD: 2.527E+01\n",
    "MSE_X: 2.563E+10, MSE_Y: 3.803E+10, KLD: 2.517E+01\n",
    "MSE_X: 3.432E+10, MSE_Y: 4.463E+10, KLD: 2.546E+01\n",
    "MSE_X: 3.258E+10, MSE_Y: 4.188E+10, KLD: 2.554E+01\n",
    "MSE_X: 2.985E+10, MSE_Y: 3.991E+10, KLD: 2.567E+01\n",
    "MSE_X: 3.078E+10, MSE_Y: 4.316E+10, KLD: 2.579E+01\n",
    "MSE_X: 2.630E+10, MSE_Y: 3.899E+10, KLD: 2.549E+01\n",
    "MSE_X: 2.783E+10, MSE_Y: 3.945E+10, KLD: 2.583E+01\n",
    "MSE_X: 2.790E+10, MSE_Y: 4.037E+10, KLD: 2.642E+01\n",
    "MSE_X: 2.836E+10, MSE_Y: 3.801E+10, KLD: 2.573E+01\n",
    "MSE_X: 2.666E+10, MSE_Y: 3.811E+10, KLD: 2.818E+01\n",
    "MSE_X: 3.126E+10, MSE_Y: 4.111E+10, KLD: 3.278E+01\n",
    "MSE_X: 2.661E+10, MSE_Y: 3.918E+10, KLD: 3.112E+01\n",
    "MSE_X: 2.630E+10, MSE_Y: 3.906E+10, KLD: 2.769E+01\n",
    "MSE_X: 2.686E+10, MSE_Y: 3.924E+10, KLD: 3.267E+01\n",
    "MSE_X: 2.731E+10, MSE_Y: 3.925E+10, KLD: 3.251E+01\n",
    "MSE_X: 2.508E+10, MSE_Y: 3.639E+10, KLD: 3.282E+01\n",
    "MSE_X: 2.777E+10, MSE_Y: 3.898E+10, KLD: 4.160E+01\n",
    "MSE_X: 2.932E+10, MSE_Y: 3.960E+10, KLD: 4.396E+01\n",
    "MSE_X: 2.617E+10, MSE_Y: 3.887E+10, KLD: 4.699E+01\n",
    "MSE_X: 2.986E+10, MSE_Y: 4.031E+10, KLD: 5.295E+01\n",
    "MSE_X: 2.758E+10, MSE_Y: 3.935E+10, KLD: 3.922E+01\n",
    "MSE_X: 2.740E+10, MSE_Y: 3.974E+10, KLD: 6.267E+01\n",
    "MSE_X: 3.045E+10, MSE_Y: 4.202E+10, KLD: 5.935E+01\n",
    "MSE_X: 2.836E+10, MSE_Y: 3.945E+10, KLD: 5.602E+01\n",
    "MSE_X: 2.759E+10, MSE_Y: 4.020E+10, KLD: 6.146E+01\n",
    "MSE_X: 3.016E+10, MSE_Y: 3.960E+10, KLD: 5.646E+01\n",
    "MSE_X: 2.779E+10, MSE_Y: 3.826E+10, KLD: 6.846E+01\n",
    "MSE_X: 2.709E+10, MSE_Y: 3.862E+10, KLD: 6.898E+01\n",
    "MSE_X: 2.953E+10, MSE_Y: 3.867E+10, KLD: 6.894E+01\n",
    "MSE_X: 3.023E+10, MSE_Y: 4.082E+10, KLD: 8.006E+01\n",
    "MSE_X: 2.796E+10, MSE_Y: 3.705E+10, KLD: 7.629E+01\n",
    "MSE_X: 2.863E+10, MSE_Y: 4.127E+10, KLD: 7.883E+01\n",
    "MSE_X: 2.917E+10, MSE_Y: 3.906E+10, KLD: 1.183E+02\n",
    "MSE_X: 2.492E+10, MSE_Y: 3.755E+10, KLD: 6.366E+01\n",
    "MSE_X: 3.121E+10, MSE_Y: 4.202E+10, KLD: 1.030E+02\n",
    "MSE_X: 2.718E+10, MSE_Y: 3.863E+10, KLD: 8.794E+01\n",
    "MSE_X: 2.779E+10, MSE_Y: 4.091E+10, KLD: 1.176E+02\n",
    "MSE_X: 3.416E+10, MSE_Y: 4.258E+10, KLD: 1.061E+02\n",
    "MSE_X: 2.680E+10, MSE_Y: 3.751E+10, KLD: 9.163E+01\n",
    "MSE_X: 2.910E+10, MSE_Y: 3.912E+10, KLD: 8.174E+01\n",
    "MSE_X: 2.746E+10, MSE_Y: 4.047E+10, KLD: 9.201E+01\n",
    "MSE_X: 2.882E+10, MSE_Y: 4.091E+10, KLD: 1.350E+02\n",
    "MSE_X: 2.638E+10, MSE_Y: 3.861E+10, KLD: 6.321E+01\n",
    "MSE_X: 2.915E+10, MSE_Y: 3.971E+10, KLD: 1.340E+02\n",
    "MSE_X: 2.703E+10, MSE_Y: 3.910E+10, KLD: 1.192E+02\n",
    "MSE_X: 3.099E+10, MSE_Y: 4.213E+10, KLD: 6.632E+01\n",
    "MSE_X: 2.772E+10, MSE_Y: 3.852E+10, KLD: 8.288E+01\n",
    "MSE_X: 3.008E+10, MSE_Y: 3.893E+10, KLD: 1.023E+02\n",
    "MSE_X: 2.748E+10, MSE_Y: 3.917E+10, KLD: 1.255E+02\n",
    "MSE_X: 2.723E+10, MSE_Y: 3.939E+10, KLD: 5.588E+01\n",
    "MSE_X: 3.121E+10, MSE_Y: 4.212E+10, KLD: 9.928E+01\n",
    "MSE_X: 2.960E+10, MSE_Y: 4.086E+10, KLD: 1.292E+02\n",
    "MSE_X: 2.643E+10, MSE_Y: 3.827E+10, KLD: 1.016E+02\n",
    "MSE_X: 2.701E+10, MSE_Y: 4.001E+10, KLD: 9.955E+01\n",
    "MSE_X: 3.346E+10, MSE_Y: 4.159E+10, KLD: 1.266E+02\n",
    "MSE_X: 2.742E+10, MSE_Y: 3.843E+10, KLD: 1.029E+02\n",
    "MSE_X: 3.062E+10, MSE_Y: 3.988E+10, KLD: 1.115E+02\n",
    "MSE_X: 2.772E+10, MSE_Y: 3.793E+10, KLD: 6.619E+01\n",
    "MSE_X: 2.811E+10, MSE_Y: 3.994E+10, KLD: 7.543E+01\n",
    "MSE_X: 2.976E+10, MSE_Y: 4.212E+10, KLD: 1.221E+02\n",
    "MSE_X: 2.983E+10, MSE_Y: 4.023E+10, KLD: 1.345E+02\n",
    "MSE_X: 2.911E+10, MSE_Y: 3.974E+10, KLD: 1.023E+02\n",
    "MSE_X: 2.857E+10, MSE_Y: 3.920E+10, KLD: 1.220E+02\n",
    "MSE_X: 2.758E+10, MSE_Y: 3.966E+10, KLD: 1.067E+02\n",
    "MSE_X: 3.539E+10, MSE_Y: 4.326E+10, KLD: 1.101E+02\n",
    "MSE_X: 2.578E+10, MSE_Y: 4.010E+10, KLD: 6.440E+01\n",
    "MSE_X: 2.838E+10, MSE_Y: 4.091E+10, KLD: 1.234E+02\n",
    "MSE_X: 2.841E+10, MSE_Y: 4.012E+10, KLD: 1.380E+02\n",
    "MSE_X: 3.756E+10, MSE_Y: 4.402E+10, KLD: 1.195E+02\n",
    "MSE_X: 2.838E+10, MSE_Y: 3.871E+10, KLD: 1.033E+02\n",
    "MSE_X: 3.520E+10, MSE_Y: 4.350E+10, KLD: 1.214E+02\n",
    "MSE_X: 2.630E+10, MSE_Y: 3.842E+10, KLD: 1.181E+02\n",
    "MSE_X: 2.697E+10, MSE_Y: 3.974E+10, KLD: 1.136E+02\n",
    "MSE_X: 3.156E+10, MSE_Y: 4.263E+10, KLD: 1.411E+02\n",
    "MSE_X: 2.751E+10, MSE_Y: 3.965E+10, KLD: 1.175E+02\n",
    "MSE_X: 2.587E+10, MSE_Y: 3.735E+10, KLD: 1.051E+02\n",
    "MSE_X: 3.084E+10, MSE_Y: 3.928E+10, KLD: 1.517E+02\n",
    "MSE_X: 2.728E+10, MSE_Y: 3.976E+10, KLD: 1.401E+02\n",
    "MSE_X: 2.772E+10, MSE_Y: 4.049E+10, KLD: 8.850E+01\n",
    "MSE_X: 3.786E+10, MSE_Y: 4.729E+10, KLD: 9.385E+01\n",
    "MSE_X: 2.795E+10, MSE_Y: 4.037E+10, KLD: 1.076E+02\n",
    "MSE_X: 2.702E+10, MSE_Y: 4.099E+10, KLD: 1.009E+02\n",
    "MSE_X: 2.732E+10, MSE_Y: 3.818E+10, KLD: 6.378E+01\n",
    "MSE_X: 2.923E+10, MSE_Y: 3.896E+10, KLD: 9.235E+01\n",
    "MSE_X: 3.110E+10, MSE_Y: 4.285E+10, KLD: 1.156E+02\n",
    "MSE_X: 3.099E+10, MSE_Y: 4.253E+10, KLD: 1.574E+02\n",
    "MSE_X: 2.676E+10, MSE_Y: 3.726E+10, KLD: 8.804E+01\n",
    "MSE_X: 2.833E+10, MSE_Y: 3.851E+10, KLD: 9.212E+01\n",
    "MSE_X: 2.656E+10, MSE_Y: 3.833E+10, KLD: 7.495E+01\n",
    "MSE_X: 3.148E+10, MSE_Y: 4.416E+10, KLD: 1.104E+02\n",
    "MSE_X: 3.322E+10, MSE_Y: 4.317E+10, KLD: 1.294E+02\n",
    "MSE_X: 3.294E+10, MSE_Y: 4.251E+10, KLD: 1.610E+02\n",
    "MSE_X: 3.234E+10, MSE_Y: 4.127E+10, KLD: 1.389E+02\n",
    "MSE_X: 2.629E+10, MSE_Y: 3.836E+10, KLD: 1.040E+02\n",
    "MSE_X: 2.912E+10, MSE_Y: 3.974E+10, KLD: 1.135E+02\n",
    "MSE_X: 2.609E+10, MSE_Y: 4.018E+10, KLD: 1.145E+02\n",
    "MSE_X: 2.710E+10, MSE_Y: 3.961E+10, KLD: 7.289E+01\n",
    "MSE_X: 2.794E+10, MSE_Y: 3.950E+10, KLD: 1.046E+02\n",
    "MSE_X: 2.750E+10, MSE_Y: 3.919E+10, KLD: 1.364E+02\n",
    "MSE_X: 3.366E+10, MSE_Y: 4.316E+10, KLD: 1.769E+02\n",
    "MSE_X: 3.489E+10, MSE_Y: 4.291E+10, KLD: 1.872E+02\n",
    "MSE_X: 2.740E+10, MSE_Y: 3.896E+10, KLD: 1.008E+02\n",
    "MSE_X: 3.110E+10, MSE_Y: 4.042E+10, KLD: 1.277E+02\n",
    "MSE_X: 2.704E+10, MSE_Y: 3.887E+10, KLD: 1.730E+02\n",
    "MSE_X: 2.643E+10, MSE_Y: 3.942E+10, KLD: 1.217E+02\n",
    "MSE_X: 2.703E+10, MSE_Y: 3.837E+10, KLD: 7.796E+01\n",
    "MSE_X: 3.070E+10, MSE_Y: 4.070E+10, KLD: 1.448E+02\n",
    "MSE_X: 2.898E+10, MSE_Y: 3.997E+10, KLD: 1.735E+02\n",
    "MSE_X: 2.746E+10, MSE_Y: 3.772E+10, KLD: 1.167E+02\n",
    "MSE_X: 2.983E+10, MSE_Y: 4.283E+10, KLD: 1.309E+02\n",
    "MSE_X: 3.000E+10, MSE_Y: 4.091E+10, KLD: 7.798E+01\n",
    "MSE_X: 2.871E+10, MSE_Y: 3.885E+10, KLD: 1.155E+02\n",
    "MSE_X: 3.034E+10, MSE_Y: 4.181E+10, KLD: 1.172E+02\n",
    "MSE_X: 2.807E+10, MSE_Y: 3.899E+10, KLD: 7.809E+01\n",
    "MSE_X: 2.966E+10, MSE_Y: 3.949E+10, KLD: 1.184E+02\n",
    "MSE_X: 2.897E+10, MSE_Y: 4.112E+10, KLD: 1.008E+02\n",
    "MSE_X: 2.715E+10, MSE_Y: 3.894E+10, KLD: 1.183E+02\n",
    "MSE_X: 2.674E+10, MSE_Y: 3.894E+10, KLD: 1.119E+02\n",
    "MSE_X: 2.664E+10, MSE_Y: 3.928E+10, KLD: 9.092E+01\n",
    "MSE_X: 2.678E+10, MSE_Y: 3.997E+10, KLD: 8.506E+01\n",
    "MSE_X: 2.778E+10, MSE_Y: 3.880E+10, KLD: 1.568E+02\n",
    "MSE_X: 3.152E+10, MSE_Y: 4.327E+10, KLD: 1.487E+02\n",
    "MSE_X: 2.805E+10, MSE_Y: 4.010E+10, KLD: 1.708E+02\n",
    "MSE_X: 2.960E+10, MSE_Y: 3.905E+10, KLD: 2.122E+02\n",
    "MSE_X: 2.652E+10, MSE_Y: 3.863E+10, KLD: 1.497E+02\n",
    "MSE_X: 3.369E+10, MSE_Y: 4.197E+10, KLD: 2.145E+02\n",
    "MSE_X: 2.775E+10, MSE_Y: 3.747E+10, KLD: 1.211E+02\n",
    "MSE_X: 3.442E+10, MSE_Y: 4.188E+10, KLD: 2.133E+02\n",
    "MSE_X: 2.556E+10, MSE_Y: 3.971E+10, KLD: 1.048E+02\n",
    "MSE_X: 2.571E+10, MSE_Y: 3.937E+10, KLD: 1.063E+02\n",
    "MSE_X: 3.071E+10, MSE_Y: 4.140E+10, KLD: 1.787E+02\n",
    "MSE_X: 2.847E+10, MSE_Y: 3.921E+10, KLD: 1.532E+02\n",
    "MSE_X: 3.359E+10, MSE_Y: 4.270E+10, KLD: 1.590E+02\n",
    "MSE_X: 3.126E+10, MSE_Y: 4.187E+10, KLD: 1.800E+02\n",
    "MSE_X: 2.857E+10, MSE_Y: 3.928E+10, KLD: 1.576E+02\n",
    "MSE_X: 3.288E+10, MSE_Y: 4.264E+10, KLD: 1.991E+02\n",
    "MSE_X: 2.847E+10, MSE_Y: 4.020E+10, KLD: 2.019E+02\n",
    "MSE_X: 2.912E+10, MSE_Y: 4.073E+10, KLD: 1.648E+02\n",
    "MSE_X: 3.548E+10, MSE_Y: 4.417E+10, KLD: 1.929E+02\n",
    "MSE_X: 2.742E+10, MSE_Y: 3.923E+10, KLD: 1.685E+02\n",
    "MSE_X: 3.047E+10, MSE_Y: 4.052E+10, KLD: 1.977E+02\n",
    "MSE_X: 2.705E+10, MSE_Y: 3.851E+10, KLD: 1.169E+02\n",
    "MSE_X: 2.690E+10, MSE_Y: 3.696E+10, KLD: 1.544E+02\n",
    "MSE_X: 3.107E+10, MSE_Y: 4.127E+10, KLD: 1.666E+02\n",
    "MSE_X: 3.040E+10, MSE_Y: 4.088E+10, KLD: 1.623E+02\n",
    "MSE_X: 2.887E+10, MSE_Y: 4.167E+10, KLD: 1.489E+02\n",
    "MSE_X: 3.187E+10, MSE_Y: 4.111E+10, KLD: 2.131E+02\n",
    "MSE_X: 2.776E+10, MSE_Y: 3.911E+10, KLD: 1.312E+02\n",
    "MSE_X: 2.743E+10, MSE_Y: 3.958E+10, KLD: 1.647E+02\n",
    "MSE_X: 3.187E+10, MSE_Y: 4.164E+10, KLD: 1.960E+02\n",
    "MSE_X: 3.597E+10, MSE_Y: 4.426E+10, KLD: 1.961E+02\n",
    "MSE_X: 2.515E+10, MSE_Y: 3.753E+10, KLD: 9.930E+01\n",
    "MSE_X: 3.087E+10, MSE_Y: 4.326E+10, KLD: 1.870E+02\n",
    "MSE_X: 2.806E+10, MSE_Y: 4.040E+10, KLD: 1.785E+02\n",
    "MSE_X: 3.067E+10, MSE_Y: 3.833E+10, KLD: 1.471E+02\n",
    "MSE_X: 3.342E+10, MSE_Y: 4.240E+10, KLD: 2.288E+02\n",
    "MSE_X: 2.777E+10, MSE_Y: 3.897E+10, KLD: 1.521E+02\n",
    "MSE_X: 3.102E+10, MSE_Y: 4.146E+10, KLD: 1.793E+02\n",
    "MSE_X: 2.983E+10, MSE_Y: 3.993E+10, KLD: 1.670E+02\n",
    "MSE_X: 2.828E+10, MSE_Y: 4.113E+10, KLD: 1.573E+02\n",
    "MSE_X: 3.117E+10, MSE_Y: 3.943E+10, KLD: 1.670E+02\n",
    "MSE_X: 2.904E+10, MSE_Y: 3.913E+10, KLD: 1.232E+02\n",
    "MSE_X: 3.009E+10, MSE_Y: 4.038E+10, KLD: 1.430E+02\n",
    "MSE_X: 3.205E+10, MSE_Y: 4.145E+10, KLD: 1.965E+02\n",
    "MSE_X: 3.236E+10, MSE_Y: 4.286E+10, KLD: 2.112E+02\n",
    "MSE_X: 2.954E+10, MSE_Y: 4.174E+10, KLD: 1.555E+02\n",
    "MSE_X: 2.615E+10, MSE_Y: 3.863E+10, KLD: 1.209E+02\n",
    "MSE_X: 2.949E+10, MSE_Y: 4.221E+10, KLD: 1.391E+02\n",
    "MSE_X: 2.617E+10, MSE_Y: 3.915E+10, KLD: 1.250E+02\n",
    "MSE_X: 2.889E+10, MSE_Y: 3.900E+10, KLD: 1.498E+02\n",
    "MSE_X: 2.930E+10, MSE_Y: 4.277E+10, KLD: 1.783E+02\n",
    "MSE_X: 3.076E+10, MSE_Y: 4.082E+10, KLD: 1.716E+02\n",
    "MSE_X: 2.606E+10, MSE_Y: 3.983E+10, KLD: 1.340E+02\n",
    "MSE_X: 2.783E+10, MSE_Y: 3.955E+10, KLD: 1.326E+02\n",
    "MSE_X: 2.660E+10, MSE_Y: 3.990E+10, KLD: 1.375E+02\n",
    "MSE_X: 2.923E+10, MSE_Y: 4.045E+10, KLD: 1.932E+02\n",
    "MSE_X: 2.687E+10, MSE_Y: 3.926E+10, KLD: 1.661E+02\n",
    "MSE_X: 3.041E+10, MSE_Y: 4.028E+10, KLD: 2.301E+02\n",
    "MSE_X: 2.787E+10, MSE_Y: 3.862E+10, KLD: 1.440E+02\n",
    "MSE_X: 3.136E+10, MSE_Y: 4.185E+10, KLD: 1.985E+02\n",
    "MSE_X: 3.175E+10, MSE_Y: 4.251E+10, KLD: 2.622E+02\n",
    "MSE_X: 2.820E+10, MSE_Y: 3.923E+10, KLD: 1.918E+02\n",
    "MSE_X: 3.367E+10, MSE_Y: 4.138E+10, KLD: 2.416E+02\n",
    "MSE_X: 2.994E+10, MSE_Y: 4.160E+10, KLD: 2.008E+02\n",
    "MSE_X: 2.750E+10, MSE_Y: 3.911E+10, KLD: 1.606E+02\n",
    "MSE_X: 3.212E+10, MSE_Y: 4.317E+10, KLD: 2.455E+02\n",
    "MSE_X: 3.344E+10, MSE_Y: 4.279E+10, KLD: 2.437E+02\n",
    "MSE_X: 2.951E+10, MSE_Y: 4.188E+10, KLD: 1.949E+02\n",
    "MSE_X: 3.763E+10, MSE_Y: 4.476E+10, KLD: 2.523E+02\n",
    "MSE_X: 2.930E+10, MSE_Y: 4.056E+10, KLD: 1.640E+02\n",
    "MSE_X: 2.833E+10, MSE_Y: 3.646E+10, KLD: 1.349E+02\n",
    "MSE_X: 2.788E+10, MSE_Y: 3.865E+10, KLD: 1.365E+02\n",
    "MSE_X: 2.579E+10, MSE_Y: 3.817E+10, KLD: 1.454E+02\n",
    "MSE_X: 3.060E+10, MSE_Y: 4.123E+10, KLD: 1.640E+02\n",
    "MSE_X: 2.750E+10, MSE_Y: 4.121E+10, KLD: 1.408E+02\n",
    "MSE_X: 3.058E+10, MSE_Y: 4.192E+10, KLD: 1.983E+02\n",
    "MSE_X: 3.130E+10, MSE_Y: 3.959E+10, KLD: 1.839E+02\n",
    "MSE_X: 2.806E+10, MSE_Y: 3.940E+10, KLD: 1.998E+02\n",
    "MSE_X: 2.855E+10, MSE_Y: 3.908E+10, KLD: 1.607E+02\n",
    "MSE_X: 2.743E+10, MSE_Y: 3.975E+10, KLD: 1.689E+02\n",
    "MSE_X: 2.581E+10, MSE_Y: 3.898E+10, KLD: 1.556E+02\n",
    "MSE_X: 2.957E+10, MSE_Y: 4.074E+10, KLD: 2.482E+02\n",
    "MSE_X: 2.916E+10, MSE_Y: 3.968E+10, KLD: 1.557E+02\n",
    "MSE_X: 2.538E+10, MSE_Y: 3.882E+10, KLD: 1.329E+02\n",
    "MSE_X: 2.529E+10, MSE_Y: 3.870E+10, KLD: 1.240E+02\n",
    "MSE_X: 2.578E+10, MSE_Y: 3.735E+10, KLD: 1.615E+02\n",
    "MSE_X: 2.563E+10, MSE_Y: 3.782E+10, KLD: 1.701E+02\n",
    "MSE_X: 2.733E+10, MSE_Y: 3.818E+10, KLD: 1.979E+02\n",
    "MSE_X: 2.789E+10, MSE_Y: 3.993E+10, KLD: 1.240E+02\n",
    "MSE_X: 2.967E+10, MSE_Y: 3.953E+10, KLD: 2.416E+02\n",
    "MSE_X: 2.847E+10, MSE_Y: 4.025E+10, KLD: 1.841E+02\n",
    "MSE_X: 2.756E+10, MSE_Y: 3.928E+10, KLD: 1.820E+02\n",
    "MSE_X: 2.849E+10, MSE_Y: 3.833E+10, KLD: 1.882E+02\n",
    "MSE_X: 3.079E+10, MSE_Y: 4.243E+10, KLD: 1.390E+02\n",
    "MSE_X: 3.093E+10, MSE_Y: 4.343E+10, KLD: 2.221E+02\n",
    "MSE_X: 2.646E+10, MSE_Y: 3.906E+10, KLD: 2.013E+02\n",
    "MSE_X: 2.564E+10, MSE_Y: 3.877E+10, KLD: 1.728E+02\n",
    "MSE_X: 2.627E+10, MSE_Y: 3.987E+10, KLD: 1.412E+02\n",
    "MSE_X: 3.260E+10, MSE_Y: 4.018E+10, KLD: 2.027E+02\n",
    "MSE_X: 2.574E+10, MSE_Y: 3.909E+10, KLD: 1.428E+02\n",
    "MSE_X: 2.906E+10, MSE_Y: 3.971E+10, KLD: 1.828E+02\n",
    "MSE_X: 3.465E+10, MSE_Y: 4.407E+10, KLD: 2.028E+02\n",
    "MSE_X: 2.553E+10, MSE_Y: 3.899E+10, KLD: 1.378E+02\n",
    "MSE_X: 2.940E+10, MSE_Y: 4.093E+10, KLD: 1.931E+02\n",
    "MSE_X: 2.610E+10, MSE_Y: 3.899E+10, KLD: 1.428E+02\n",
    "MSE_X: 3.286E+10, MSE_Y: 4.489E+10, KLD: 2.016E+02\n",
    "MSE_X: 2.820E+10, MSE_Y: 4.174E+10, KLD: 1.618E+02\n",
    "MSE_X: 2.988E+10, MSE_Y: 3.994E+10, KLD: 1.530E+02\n",
    "MSE_X: 2.582E+10, MSE_Y: 3.859E+10, KLD: 1.466E+02\n",
    "MSE_X: 3.304E+10, MSE_Y: 4.335E+10, KLD: 2.160E+02\n",
    "MSE_X: 3.101E+10, MSE_Y: 4.263E+10, KLD: 1.599E+02\n",
    "MSE_X: 2.651E+10, MSE_Y: 3.827E+10, KLD: 1.528E+02\n",
    "MSE_X: 3.087E+10, MSE_Y: 4.127E+10, KLD: 1.992E+02\n",
    "MSE_X: 2.703E+10, MSE_Y: 3.751E+10, KLD: 1.750E+02\n",
    "MSE_X: 3.114E+10, MSE_Y: 4.209E+10, KLD: 2.439E+02\n",
    "MSE_X: 2.732E+10, MSE_Y: 3.975E+10, KLD: 1.622E+02\n",
    "MSE_X: 2.858E+10, MSE_Y: 3.961E+10, KLD: 1.607E+02\n",
    "MSE_X: 3.517E+10, MSE_Y: 4.256E+10, KLD: 2.530E+02\n",
    "MSE_X: 2.995E+10, MSE_Y: 4.326E+10, KLD: 2.046E+02\n",
    "MSE_X: 2.945E+10, MSE_Y: 4.092E+10, KLD: 2.451E+02\n",
    "MSE_X: 2.652E+10, MSE_Y: 3.863E+10, KLD: 1.620E+02\n",
    "MSE_X: 2.998E+10, MSE_Y: 4.365E+10, KLD: 2.460E+02\n",
    "MSE_X: 2.459E+10, MSE_Y: 3.787E+10, KLD: 1.686E+02\n",
    "MSE_X: 3.076E+10, MSE_Y: 4.094E+10, KLD: 2.467E+02\n",
    "MSE_X: 2.777E+10, MSE_Y: 3.919E+10, KLD: 2.049E+02\n",
    "MSE_X: 2.789E+10, MSE_Y: 4.013E+10, KLD: 1.928E+02\n",
    "MSE_X: 2.872E+10, MSE_Y: 3.997E+10, KLD: 2.107E+02\n",
    "MSE_X: 2.744E+10, MSE_Y: 4.065E+10, KLD: 1.797E+02\n",
    "MSE_X: 2.805E+10, MSE_Y: 3.991E+10, KLD: 1.847E+02\n",
    "MSE_X: 2.712E+10, MSE_Y: 3.744E+10, KLD: 1.893E+02\n",
    "MSE_X: 2.784E+10, MSE_Y: 4.052E+10, KLD: 2.052E+02\n",
    "MSE_X: 3.287E+10, MSE_Y: 4.021E+10, KLD: 2.815E+02\n",
    "MSE_X: 3.355E+10, MSE_Y: 4.192E+10, KLD: 3.179E+02\n",
    "MSE_X: 2.647E+10, MSE_Y: 3.768E+10, KLD: 1.684E+02\n",
    "MSE_X: 2.816E+10, MSE_Y: 3.482E+10, KLD: 1.627E+02\n",
    "MSE_X: 2.695E+10, MSE_Y: 3.794E+10, KLD: 1.633E+02\n",
    "MSE_X: 2.935E+10, MSE_Y: 4.075E+10, KLD: 2.211E+02\n",
    "MSE_X: 3.016E+10, MSE_Y: 4.149E+10, KLD: 2.357E+02\n",
    "MSE_X: 2.755E+10, MSE_Y: 4.092E+10, KLD: 2.032E+02\n",
    "MSE_X: 3.036E+10, MSE_Y: 4.239E+10, KLD: 2.735E+02\n",
    "MSE_X: 2.886E+10, MSE_Y: 4.077E+10, KLD: 3.291E+02\n",
    "MSE_X: 2.815E+10, MSE_Y: 3.808E+10, KLD: 2.515E+02\n",
    "MSE_X: 2.928E+10, MSE_Y: 3.934E+10, KLD: 2.382E+02\n",
    "MSE_X: 2.726E+10, MSE_Y: 4.032E+10, KLD: 2.132E+02\n",
    "MSE_X: 3.265E+10, MSE_Y: 4.235E+10, KLD: 2.877E+02\n",
    "MSE_X: 2.786E+10, MSE_Y: 3.990E+10, KLD: 1.823E+02\n",
    "MSE_X: 2.877E+10, MSE_Y: 3.842E+10, KLD: 1.941E+02\n",
    "MSE_X: 2.746E+10, MSE_Y: 3.784E+10, KLD: 1.819E+02\n",
    "MSE_X: 2.720E+10, MSE_Y: 4.007E+10, KLD: 1.646E+02\n",
    "MSE_X: 2.678E+10, MSE_Y: 3.981E+10, KLD: 1.590E+02\n",
    "MSE_X: 2.801E+10, MSE_Y: 4.037E+10, KLD: 2.389E+02\n",
    "MSE_X: 2.719E+10, MSE_Y: 3.861E+10, KLD: 1.980E+02\n",
    "MSE_X: 2.909E+10, MSE_Y: 4.012E+10, KLD: 2.172E+02\n",
    "MSE_X: 3.393E+10, MSE_Y: 4.372E+10, KLD: 2.853E+02\n",
    "MSE_X: 2.787E+10, MSE_Y: 3.944E+10, KLD: 1.887E+02\n",
    "MSE_X: 2.713E+10, MSE_Y: 3.869E+10, KLD: 2.080E+02\n",
    "MSE_X: 2.918E+10, MSE_Y: 4.050E+10, KLD: 2.477E+02\n",
    "MSE_X: 2.763E+10, MSE_Y: 3.910E+10, KLD: 1.908E+02\n",
    "MSE_X: 2.846E+10, MSE_Y: 4.126E+10, KLD: 2.450E+02\n",
    "MSE_X: 2.849E+10, MSE_Y: 3.878E+10, KLD: 1.864E+02\n",
    "MSE_X: 3.099E+10, MSE_Y: 4.093E+10, KLD: 3.141E+02\n",
    "MSE_X: 2.904E+10, MSE_Y: 3.802E+10, KLD: 1.752E+02\n",
    "MSE_X: 3.124E+10, MSE_Y: 4.025E+10, KLD: 2.835E+02\n",
    "MSE_X: 2.571E+10, MSE_Y: 3.886E+10, KLD: 1.673E+02\n",
    "MSE_X: 2.967E+10, MSE_Y: 3.984E+10, KLD: 1.773E+02\n",
    "MSE_X: 3.029E+10, MSE_Y: 4.158E+10, KLD: 2.730E+02\n",
    "MSE_X: 2.742E+10, MSE_Y: 3.767E+10, KLD: 1.877E+02\n",
    "MSE_X: 2.600E+10, MSE_Y: 3.972E+10, KLD: 1.745E+02\n",
    "MSE_X: 2.981E+10, MSE_Y: 3.864E+10, KLD: 2.219E+02\n",
    "MSE_X: 3.146E+10, MSE_Y: 3.944E+10, KLD: 1.694E+02\n",
    "MSE_X: 2.717E+10, MSE_Y: 3.948E+10, KLD: 1.814E+02\n",
    "MSE_X: 2.682E+10, MSE_Y: 4.005E+10, KLD: 1.689E+02\n",
    "MSE_X: 2.826E+10, MSE_Y: 4.101E+10, KLD: 2.114E+02\n",
    "MSE_X: 3.175E+10, MSE_Y: 3.994E+10, KLD: 2.816E+02\n",
    "MSE_X: 2.628E+10, MSE_Y: 3.954E+10, KLD: 1.839E+02\n",
    "MSE_X: 2.776E+10, MSE_Y: 3.980E+10, KLD: 1.721E+02\n",
    "MSE_X: 3.213E+10, MSE_Y: 4.245E+10, KLD: 2.156E+02\n",
    "MSE_X: 2.724E+10, MSE_Y: 4.025E+10, KLD: 2.055E+02\n",
    "MSE_X: 3.522E+10, MSE_Y: 4.479E+10, KLD: 2.796E+02\n",
    "MSE_X: 3.173E+10, MSE_Y: 4.068E+10, KLD: 2.703E+02\n",
    "MSE_X: 2.733E+10, MSE_Y: 4.033E+10, KLD: 1.984E+02\n",
    "MSE_X: 2.774E+10, MSE_Y: 3.797E+10, KLD: 1.800E+02\n",
    "MSE_X: 2.819E+10, MSE_Y: 3.613E+10, KLD: 1.602E+02\n",
    "MSE_X: 2.641E+10, MSE_Y: 3.912E+10, KLD: 1.716E+02\n",
    "MSE_X: 3.202E+10, MSE_Y: 4.205E+10, KLD: 2.636E+02\n",
    "MSE_X: 3.226E+10, MSE_Y: 4.265E+10, KLD: 2.237E+02\n",
    "MSE_X: 2.703E+10, MSE_Y: 3.781E+10, KLD: 1.687E+02\n",
    "MSE_X: 2.742E+10, MSE_Y: 3.946E+10, KLD: 1.729E+02\n",
    "MSE_X: 2.999E+10, MSE_Y: 4.163E+10, KLD: 3.319E+02\n",
    "MSE_X: 2.782E+10, MSE_Y: 3.915E+10, KLD: 2.048E+02\n",
    "MSE_X: 2.747E+10, MSE_Y: 3.940E+10, KLD: 1.793E+02\n",
    "MSE_X: 2.740E+10, MSE_Y: 3.856E+10, KLD: 1.871E+02\n",
    "MSE_X: 2.713E+10, MSE_Y: 3.967E+10, KLD: 1.864E+02\n",
    "MSE_X: 2.729E+10, MSE_Y: 3.791E+10, KLD: 1.638E+02\n",
    "MSE_X: 2.847E+10, MSE_Y: 3.959E+10, KLD: 1.672E+02\n",
    "MSE_X: 2.751E+10, MSE_Y: 3.918E+10, KLD: 1.668E+02\n",
    "MSE_X: 3.013E+10, MSE_Y: 3.962E+10, KLD: 2.264E+02\n",
    "MSE_X: 2.748E+10, MSE_Y: 3.932E+10, KLD: 2.178E+02\n",
    "MSE_X: 2.704E+10, MSE_Y: 3.816E+10, KLD: 1.721E+02\n",
    "MSE_X: 2.662E+10, MSE_Y: 3.848E+10, KLD: 1.907E+02\n",
    "MSE_X: 2.912E+10, MSE_Y: 4.026E+10, KLD: 2.385E+02\n",
    "MSE_X: 2.830E+10, MSE_Y: 4.042E+10, KLD: 3.178E+02\n",
    "MSE_X: 3.240E+10, MSE_Y: 4.297E+10, KLD: 3.230E+02\n",
    "MSE_X: 2.985E+10, MSE_Y: 3.891E+10, KLD: 3.314E+02\n",
    "MSE_X: 2.910E+10, MSE_Y: 4.102E+10, KLD: 2.305E+02\n",
    "MSE_X: 2.740E+10, MSE_Y: 3.916E+10, KLD: 2.933E+02\n",
    "MSE_X: 2.488E+10, MSE_Y: 3.766E+10, KLD: 2.053E+02\n",
    "MSE_X: 2.892E+10, MSE_Y: 4.075E+10, KLD: 2.608E+02\n",
    "MSE_X: 2.810E+10, MSE_Y: 3.943E+10, KLD: 2.904E+02\n",
    "MSE_X: 2.816E+10, MSE_Y: 3.804E+10, KLD: 1.902E+02\n",
    "MSE_X: 2.916E+10, MSE_Y: 4.180E+10, KLD: 2.988E+02\n",
    "MSE_X: 2.701E+10, MSE_Y: 3.875E+10, KLD: 2.197E+02\n",
    "MSE_X: 2.577E+10, MSE_Y: 3.946E+10, KLD: 1.922E+02\n",
    "MSE_X: 2.687E+10, MSE_Y: 3.928E+10, KLD: 2.648E+02\n",
    "MSE_X: 2.891E+10, MSE_Y: 4.145E+10, KLD: 2.629E+02\n",
    "MSE_X: 2.737E+10, MSE_Y: 4.025E+10, KLD: 1.956E+02\n",
    "MSE_X: 2.937E+10, MSE_Y: 4.294E+10, KLD: 2.638E+02\n",
    "MSE_X: 3.116E+10, MSE_Y: 4.178E+10, KLD: 3.040E+02\n",
    "MSE_X: 3.142E+10, MSE_Y: 4.161E+10, KLD: 3.315E+02\n",
    "MSE_X: 2.799E+10, MSE_Y: 3.722E+10, KLD: 2.319E+02\n",
    "MSE_X: 2.835E+10, MSE_Y: 4.093E+10, KLD: 2.509E+02\n",
    "MSE_X: 2.530E+10, MSE_Y: 3.772E+10, KLD: 1.993E+02\n",
    "MSE_X: 2.709E+10, MSE_Y: 3.922E+10, KLD: 2.544E+02\n",
    "MSE_X: 2.903E+10, MSE_Y: 3.893E+10, KLD: 2.301E+02\n",
    "MSE_X: 2.946E+10, MSE_Y: 4.148E+10, KLD: 2.228E+02\n",
    "MSE_X: 2.597E+10, MSE_Y: 3.797E+10, KLD: 2.043E+02\n",
    "MSE_X: 2.551E+10, MSE_Y: 3.878E+10, KLD: 2.189E+02\n",
    "MSE_X: 3.607E+10, MSE_Y: 4.300E+10, KLD: 3.786E+02\n",
    "MSE_X: 2.857E+10, MSE_Y: 4.127E+10, KLD: 3.111E+02\n",
    "MSE_X: 2.988E+10, MSE_Y: 3.864E+10, KLD: 3.445E+02\n",
    "MSE_X: 3.023E+10, MSE_Y: 4.103E+10, KLD: 2.609E+02\n",
    "MSE_X: 3.027E+10, MSE_Y: 3.927E+10, KLD: 3.327E+02\n",
    "MSE_X: 2.857E+10, MSE_Y: 4.106E+10, KLD: 3.149E+02\n",
    "MSE_X: 3.117E+10, MSE_Y: 4.293E+10, KLD: 2.461E+02\n",
    "MSE_X: 2.814E+10, MSE_Y: 4.013E+10, KLD: 3.358E+02\n",
    "MSE_X: 2.758E+10, MSE_Y: 3.990E+10, KLD: 2.688E+02\n",
    "MSE_X: 2.923E+10, MSE_Y: 4.082E+10, KLD: 2.833E+02\n",
    "MSE_X: 2.769E+10, MSE_Y: 3.962E+10, KLD: 2.691E+02\n",
    "MSE_X: 2.621E+10, MSE_Y: 3.837E+10, KLD: 2.697E+02\n",
    "MSE_X: 2.807E+10, MSE_Y: 3.625E+10, KLD: 2.367E+02\n",
    "MSE_X: 3.507E+10, MSE_Y: 4.379E+10, KLD: 3.445E+02\n",
    "MSE_X: 2.855E+10, MSE_Y: 3.982E+10, KLD: 2.541E+02\n",
    "MSE_X: 2.877E+10, MSE_Y: 3.929E+10, KLD: 2.333E+02\n",
    "MSE_X: 2.698E+10, MSE_Y: 3.977E+10, KLD: 2.611E+02\n",
    "MSE_X: 2.927E+10, MSE_Y: 4.219E+10, KLD: 3.140E+02\n",
    "MSE_X: 2.593E+10, MSE_Y: 3.705E+10, KLD: 2.224E+02\n",
    "MSE_X: 2.712E+10, MSE_Y: 3.812E+10, KLD: 2.171E+02\n",
    "MSE_X: 2.723E+10, MSE_Y: 3.897E+10, KLD: 2.823E+02\n",
    "MSE_X: 2.576E+10, MSE_Y: 3.855E+10, KLD: 2.550E+02\n",
    "MSE_X: 2.875E+10, MSE_Y: 4.143E+10, KLD: 3.095E+02\n",
    "MSE_X: 2.732E+10, MSE_Y: 4.001E+10, KLD: 3.131E+02\n",
    "MSE_X: 2.909E+10, MSE_Y: 3.866E+10, KLD: 2.881E+02\n",
    "MSE_X: 3.026E+10, MSE_Y: 4.096E+10, KLD: 3.084E+02\n",
    "MSE_X: 3.134E+10, MSE_Y: 4.101E+10, KLD: 3.261E+02\n",
    "MSE_X: 2.706E+10, MSE_Y: 3.790E+10, KLD: 2.569E+02\n",
    "MSE_X: 2.890E+10, MSE_Y: 3.975E+10, KLD: 2.278E+02\n",
    "MSE_X: 2.607E+10, MSE_Y: 3.864E+10, KLD: 2.320E+02\n",
    "MSE_X: 2.643E+10, MSE_Y: 3.787E+10, KLD: 2.650E+02\n",
    "MSE_X: 2.612E+10, MSE_Y: 3.876E+10, KLD: 2.378E+02\n",
    "MSE_X: 2.617E+10, MSE_Y: 3.889E+10, KLD: 2.610E+02\n",
    "MSE_X: 2.951E+10, MSE_Y: 4.147E+10, KLD: 3.632E+02\n",
    "MSE_X: 2.558E+10, MSE_Y: 3.855E+10, KLD: 2.414E+02\n",
    "MSE_X: 2.690E+10, MSE_Y: 3.873E+10, KLD: 2.578E+02\n",
    "MSE_X: 2.596E+10, MSE_Y: 3.927E+10, KLD: 2.617E+02\n",
    "MSE_X: 3.067E+10, MSE_Y: 4.259E+10, KLD: 3.075E+02\n",
    "MSE_X: 2.780E+10, MSE_Y: 3.789E+10, KLD: 2.770E+02\n",
    "MSE_X: 2.827E+10, MSE_Y: 4.138E+10, KLD: 3.237E+02\n",
    "MSE_X: 3.061E+10, MSE_Y: 4.195E+10, KLD: 3.232E+02\n",
    "MSE_X: 2.994E+10, MSE_Y: 4.124E+10, KLD: 3.791E+02\n",
    "MSE_X: 2.702E+10, MSE_Y: 3.962E+10, KLD: 2.909E+02\n",
    "MSE_X: 3.014E+10, MSE_Y: 4.108E+10, KLD: 3.666E+02\n",
    "MSE_X: 2.720E+10, MSE_Y: 3.937E+10, KLD: 2.615E+02\n",
    "MSE_X: 2.714E+10, MSE_Y: 4.007E+10, KLD: 2.947E+02\n",
    "MSE_X: 2.722E+10, MSE_Y: 3.732E+10, KLD: 2.749E+02\n",
    "MSE_X: 2.711E+10, MSE_Y: 4.072E+10, KLD: 2.830E+02\n",
    "MSE_X: 2.823E+10, MSE_Y: 3.956E+10, KLD: 3.252E+02\n",
    "MSE_X: 3.268E+10, MSE_Y: 4.337E+10, KLD: 3.724E+02\n",
    "MSE_X: 3.007E+10, MSE_Y: 4.291E+10, KLD: 3.768E+02\n",
    "MSE_X: 3.161E+10, MSE_Y: 4.358E+10, KLD: 3.622E+02\n",
    "MSE_X: 2.784E+10, MSE_Y: 3.960E+10, KLD: 2.611E+02\n",
    "MSE_X: 2.637E+10, MSE_Y: 3.981E+10, KLD: 3.502E+02\n",
    "MSE_X: 2.596E+10, MSE_Y: 3.763E+10, KLD: 2.742E+02\n",
    "MSE_X: 2.572E+10, MSE_Y: 3.669E+10, KLD: 2.547E+02\n",
    "MSE_X: 2.959E+10, MSE_Y: 4.108E+10, KLD: 3.649E+02\n",
    "MSE_X: 3.204E+10, MSE_Y: 4.204E+10, KLD: 3.902E+02\n",
    "MSE_X: 3.413E+10, MSE_Y: 4.243E+10, KLD: 4.245E+02\n",
    "MSE_X: 2.604E+10, MSE_Y: 3.878E+10, KLD: 2.734E+02\n",
    "MSE_X: 3.167E+10, MSE_Y: 4.357E+10, KLD: 4.003E+02\n",
    "MSE_X: 3.134E+10, MSE_Y: 4.167E+10, KLD: 3.741E+02\n",
    "MSE_X: 2.519E+10, MSE_Y: 3.800E+10, KLD: 2.587E+02\n",
    "MSE_X: 2.754E+10, MSE_Y: 4.056E+10, KLD: 2.592E+02\n",
    "MSE_X: 2.673E+10, MSE_Y: 3.886E+10, KLD: 2.807E+02\n",
    "MSE_X: 2.974E+10, MSE_Y: 3.962E+10, KLD: 2.574E+02\n",
    "MSE_X: 2.739E+10, MSE_Y: 4.023E+10, KLD: 2.740E+02\n",
    "MSE_X: 2.670E+10, MSE_Y: 3.931E+10, KLD: 2.797E+02\n",
    "MSE_X: 3.894E+10, MSE_Y: 4.645E+10, KLD: 3.774E+02\n",
    "MSE_X: 2.682E+10, MSE_Y: 4.037E+10, KLD: 2.812E+02\n",
    "MSE_X: 3.035E+10, MSE_Y: 4.393E+10, KLD: 2.964E+02\n",
    "MSE_X: 2.683E+10, MSE_Y: 3.843E+10, KLD: 3.496E+02\n",
    "MSE_X: 2.588E+10, MSE_Y: 3.895E+10, KLD: 2.714E+02\n",
    "MSE_X: 2.910E+10, MSE_Y: 4.064E+10, KLD: 3.481E+02\n",
    "MSE_X: 2.937E+10, MSE_Y: 4.102E+10, KLD: 3.640E+02\n",
    "MSE_X: 2.767E+10, MSE_Y: 4.027E+10, KLD: 3.662E+02\n",
    "MSE_X: 2.620E+10, MSE_Y: 3.756E+10, KLD: 2.941E+02\n",
    "MSE_X: 3.161E+10, MSE_Y: 4.234E+10, KLD: 3.858E+02\n",
    "MSE_X: 2.508E+10, MSE_Y: 3.802E+10, KLD: 2.976E+02\n",
    "MSE_X: 2.876E+10, MSE_Y: 4.149E+10, KLD: 2.921E+02\n",
    "MSE_X: 2.910E+10, MSE_Y: 4.257E+10, KLD: 3.991E+02\n",
    "MSE_X: 2.493E+10, MSE_Y: 3.783E+10, KLD: 3.143E+02\n",
    "MSE_X: 2.829E+10, MSE_Y: 3.873E+10, KLD: 2.852E+02\n",
    "MSE_X: 2.619E+10, MSE_Y: 3.950E+10, KLD: 3.104E+02\n",
    "MSE_X: 2.806E+10, MSE_Y: 4.091E+10, KLD: 3.750E+02\n",
    "MSE_X: 2.885E+10, MSE_Y: 3.975E+10, KLD: 3.346E+02\n",
    "MSE_X: 3.246E+10, MSE_Y: 4.309E+10, KLD: 4.333E+02\n",
    "MSE_X: 3.105E+10, MSE_Y: 4.095E+10, KLD: 4.217E+02\n",
    "MSE_X: 2.889E+10, MSE_Y: 4.150E+10, KLD: 4.175E+02\n",
    "MSE_X: 2.648E+10, MSE_Y: 4.099E+10, KLD: 3.054E+02\n",
    "MSE_X: 2.615E+10, MSE_Y: 3.765E+10, KLD: 3.221E+02\n",
    "MSE_X: 2.918E+10, MSE_Y: 4.025E+10, KLD: 3.719E+02\n",
    "MSE_X: 2.863E+10, MSE_Y: 4.072E+10, KLD: 3.939E+02\n",
    "MSE_X: 2.627E+10, MSE_Y: 3.931E+10, KLD: 3.095E+02\n",
    "MSE_X: 2.820E+10, MSE_Y: 3.902E+10, KLD: 3.029E+02\n",
    "MSE_X: 2.547E+10, MSE_Y: 3.912E+10, KLD: 2.988E+02\n",
    "MSE_X: 3.053E+10, MSE_Y: 4.114E+10, KLD: 3.725E+02\n",
    "MSE_X: 3.254E+10, MSE_Y: 4.345E+10, KLD: 3.721E+02\n",
    "MSE_X: 2.747E+10, MSE_Y: 3.947E+10, KLD: 3.591E+02\n",
    "MSE_X: 3.097E+10, MSE_Y: 4.226E+10, KLD: 3.416E+02\n",
    "MSE_X: 2.604E+10, MSE_Y: 3.768E+10, KLD: 3.077E+02\n",
    "MSE_X: 2.301E+10, MSE_Y: 3.281E+10, KLD: 2.301E+02\n",
    "\n",
    "avg_loss: 1.150179E+10, X_loss: 4.812970E+09, Y_loss: 6.688824E+09\n",
    "epoch 1: \n",
    "\n",
    "100% 471/471 [09:04<00:00, 1.16s/it]\n",
    "\n",
    "avg_loss: 1.123066E+10, X_loss: 4.541250E+09, Y_loss: 6.689410E+09\n",
    "epoch 2: \n",
    "\n",
    "100% 471/471 [09:03<00:00, 1.15s/it]\n",
    "\n",
    "avg_loss: 1.105354E+10, X_loss: 4.364532E+09, Y_loss: 6.689006E+09\n",
    "epoch 3: \n",
    "\n",
    "100% 471/471 [09:11<00:00, 1.17s/it]\n",
    "\n",
    "avg_loss: 1.095284E+10, X_loss: 4.263896E+09, Y_loss: 6.688943E+09\n",
    "epoch 4: \n",
    "\n",
    "100% 471/471 [09:12<00:00, 1.17s/it]\n",
    "\n",
    "avg_loss: 1.088766E+10, X_loss: 4.198698E+09, Y_loss: 6.688961E+09\n",
    "epoch 5: \n",
    "\n",
    "100% 471/471 [09:02<00:00, 1.15s/it]\n",
    "\n",
    "avg_loss: 1.084336E+10, X_loss: 4.154663E+09, Y_loss: 6.688696E+09\n",
    "epoch 6: \n",
    "\n",
    "100% 471/471 [09:03<00:00, 1.15s/it]\n",
    "\n",
    "avg_loss: 1.080775E+10, X_loss: 4.119094E+09, Y_loss: 6.688658E+09\n",
    "epoch 7: \n",
    "\n",
    "100% 471/471 [09:01<00:00, 1.15s/it]\n",
    "\n",
    "avg_loss: 1.077853E+10, X_loss: 4.090179E+09, Y_loss: 6.688350E+09\n",
    "epoch 8: \n",
    "\n",
    "100% 471/471 [09:05<00:00, 1.16s/it]\n",
    "\n",
    "avg_loss: 1.075838E+10, X_loss: 4.070065E+09, Y_loss: 6.688318E+09\n",
    "epoch 9: \n",
    "\n",
    "100% 471/471 [09:05<00:00, 1.16s/it]\n",
    "\n",
    "avg_loss: 1.073775E+10, X_loss: 4.049412E+09, Y_loss: 6.688342E+09\n",
    "epoch 10: \n",
    "\n",
    "100% 471/471 [09:02<00:00, 1.15s/it]\n",
    "\n",
    "avg_loss: 1.072273E+10, X_loss: 4.034485E+09, Y_loss: 6.688246E+09\n",
    "epoch 11: \n",
    "\n",
    "100% 471/471 [09:06<00:00, 1.16s/it]\n",
    "\n",
    "avg_loss: 1.070848E+10, X_loss: 4.020310E+09, Y_loss: 6.688167E+09\n",
    "epoch 12: \n",
    "\n",
    "100% 471/471 [09:08<00:00, 1.16s/it]\n",
    "\n",
    "avg_loss: 1.069424E+10, X_loss: 4.006011E+09, Y_loss: 6.688231E+09\n",
    "epoch 13: \n",
    "\n",
    "100% 471/471 [09:06<00:00, 1.16s/it]\n",
    "\n",
    "avg_loss: 1.068459E+10, X_loss: 3.996408E+09, Y_loss: 6.688179E+09\n",
    "epoch 14: \n",
    "\n",
    "100% 471/471 [09:04<00:00, 1.16s/it]\n",
    "\n",
    "avg_loss: 1.067316E+10, X_loss: 3.985030E+09, Y_loss: 6.688126E+09\n",
    "epoch 15: \n",
    "\n",
    "100% 471/471 [09:12<00:00, 1.17s/it]\n",
    "\n",
    "avg_loss: 1.066187E+10, X_loss: 3.973817E+09, Y_loss: 6.688053E+09\n",
    "epoch 16: \n",
    "\n",
    "100% 471/471 [09:07<00:00, 1.16s/it]\n",
    "\n",
    "avg_loss: 1.065911E+10, X_loss: 3.971063E+09, Y_loss: 6.688052E+09\n",
    "epoch 17: \n",
    "\n",
    "100% 471/471 [09:07<00:00, 1.16s/it]\n",
    "\n",
    "avg_loss: 1.064352E+10, X_loss: 3.955505E+09, Y_loss: 6.688014E+09\n",
    "epoch 18: \n",
    "\n",
    "100% 471/471 [09:02<00:00, 1.15s/it]\n",
    "\n",
    "avg_loss: 1.063551E+10, X_loss: 3.947519E+09, Y_loss: 6.687990E+09\n",
    "epoch 19: \n",
    "\n",
    "100% 471/471 [09:00<00:00, 1.15s/it]\n",
    "\n",
    "avg_loss: 1.063286E+10, X_loss: 3.944884E+09, Y_loss: 6.687973E+09\n",
    "epoch 20: \n",
    "\n",
    "100% 471/471 [09:00<00:00, 1.15s/it]\n",
    "\n",
    "avg_loss: 1.062158E+10, X_loss: 3.933637E+09, Y_loss: 6.687938E+09\n",
    "epoch 21: \n",
    "\n",
    "100% 471/471 [09:01<00:00, 1.15s/it]\n",
    "\n",
    "avg_loss: 1.061390E+10, X_loss: 3.926065E+09, Y_loss: 6.687837E+09\n",
    "epoch 22: \n",
    "\n",
    "100% 471/471 [09:00<00:00, 1.15s/it]\n",
    "\n",
    "avg_loss: 1.061402E+10, X_loss: 3.926080E+09, Y_loss: 6.687936E+09\n",
    "epoch 23: \n",
    "\n",
    "1% 3/471 [00:03<09:02, 1.16s/it]\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "KeyboardInterrupt                         Traceback (most recent call last)\n",
    "<ipython-input-15-eaa352e13c44> in <module>()\n",
    "    171 print(\"total num params:\", np.sum([np.prod(x.shape) for x in conv_model.parameters()]))\n",
    "    172 # conv_model(data[0][0][None,:,None].cuda()).shape\n",
    "--> 173 train(conv_model,data,100,lr=1e-3, half=half, cuda=cuda)\n",
    "    174 # 1.91E+02\n",
    "\n",
    "<ipython-input-15-eaa352e13c44> in train(model, data, nepochs, lr, half, cuda)\n",
    "    142                 optimizer.backward(loss)\n",
    "    143             else:\n",
    "--> 144                 loss.backward()\n",
    "    145             optimizer.step()\n",
    "    146             cum_loss += float(loss)\n",
    "\n",
    "/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/tensor.pyc in backward(self, gradient, retain_graph, create_graph)\n",
    "     91                 products. Defaults to ``False``.\n",
    "     92         \"\"\"\n",
    "---> 93         torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
    "     94 \n",
    "     95     def register_hook(self, hook):\n",
    "\n",
    "/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/autograd/__init__.pyc in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\n",
    "     87     Variable._execution_engine.run_backward(\n",
    "     88         tensors, grad_tensors, retain_graph, create_graph,\n",
    "---> 89         allow_unreachable=True)  # allow_unreachable flag\n",
    "     90 \n",
    "     91 \n",
    "\n",
    "KeyboardInterrupt: \n",
    "\n",
    "​\n",
    "\n",
    "sz_avg=False:\n",
    "\n",
    "epoch 1: avg_loss: 9.025106E+09, X_loss: 4.514291E+09, Y_loss: 4.510816E+09\n",
    "\n",
    "epoch 2: avg_loss: 8.635393E+09, X_loss: 4.316321E+09, Y_loss: 4.319072E+09\n",
    "\n",
    "epoch 3: avg_loss: 8.425725E+09, X_loss: 4.211480E+09, Y_loss: 4.214245E+09\n",
    "\n",
    "epoch 4: avg_loss: 8.304267E+09, X_loss: 4.150881E+09, Y_loss: 4.153385E+09\n",
    "\n",
    "epoch 5: avg_loss: 8.211217E+09, X_loss: 4.104135E+09, Y_loss: 4.107081E+09\n",
    "\n",
    "epoch 6: avg_loss: 8.154908E+09, X_loss: 4.075904E+09, Y_loss: 4.079004E+09\n",
    "\n",
    "epoch 7: avg_loss: 8.105444E+09, X_loss: 4.051218E+09, Y_loss: 4.054226E+09\n",
    "\n",
    "epoch 8: avg_loss: 8.059247E+09, X_loss: 4.028319E+09, Y_loss: 4.030929E+09\n",
    "\n",
    "epoch 9: avg_loss: 8.023846E+09, X_loss: 4.010521E+09, Y_loss: 4.013325E+09\n",
    "\n",
    "epoch 10: avg_loss: 7.959344E+09, X_loss: 3.978424E+09, Y_loss: 3.980920E+09\n",
    "\n",
    "epoch 12: avg_loss: 7.937324E+09, X_loss: 3.966849E+09, Y_loss: 3.970475E+09\n",
    "\n",
    "epoch 13: avg_loss: 7.913101E+09, X_loss: 3.954937E+09, Y_loss: 3.958164E+09\n",
    "\n",
    "epoch 14: avg_loss: 7.887365E+09, X_loss: 3.942145E+09, Y_loss: 3.945220E+09\n",
    "\n",
    "epoch 15: avg_loss: 7.866695E+09, X_loss: 3.931801E+09, Y_loss: 3.934894E+09\n",
    "\n",
    "epoch 16: avg_loss: 7.850621E+09, X_loss: 3.923779E+09, Y_loss: 3.926842E+09\n",
    "\n",
    "epoch 17: avg_loss: 7.832272E+09, X_loss: 3.914669E+09, Y_loss: 3.917603E+09\n",
    "\n",
    "epoch 18: avg_loss: 7.811225E+09, X_loss: 3.904124E+09, Y_loss: 3.907101E+09\n",
    "\n",
    "epoch 19: avg_loss: 7.797960E+09, X_loss: 3.897282E+09, Y_loss: 3.900678E+09\n",
    "\n",
    "epoch 20: avg_loss: 7.784135E+09, X_loss: 3.890460E+09, Y_loss: 3.893674E+09\n",
    "\n",
    "epoch 21: avg_loss: 7.769884E+09, X_loss: 3.883294E+09, Y_loss: 3.886589E+09\n",
    "\n",
    "epoch 22: avg_loss: 7.757159E+09, X_loss: 3.876780E+09, Y_loss: 3.880379E+09\n",
    "\n",
    "epoch 23: avg_loss: 7.741684E+09, X_loss: 3.869390E+09, Y_loss: 3.872294E+09\n",
    "\n",
    "epoch 24: avg_loss: 7.733636E+09, X_loss: 3.865235E+09, Y_loss: 3.868401E+09\n",
    "\n",
    "epoch 25: avg_loss: 7.721238E+09, X_loss: 3.859067E+09, Y_loss: 3.862171E+09\n",
    "\n",
    "epoch 26: avg_loss: 7.714142E+09, X_loss: 3.855281E+09, Y_loss: 3.858861E+09\n",
    "\n",
    "epoch 27: avg_loss: 7.696866E+09, X_loss: 3.846964E+09, Y_loss: 3.849902E+09\n",
    "\n",
    "epoch 28: avg_loss: 7.694627E+09, X_loss: 3.845731E+09, Y_loss: 3.848896E+09\n",
    "\n",
    "epoch 29: avg_loss: 7.693011E+09, X_loss: 3.844707E+09, Y_loss: 3.848303E+09\n",
    "\n",
    "epoch 30: avg_loss: 7.678288E+09, X_loss: 3.837486E+09, Y_loss: 3.840802E+09\n",
    "\n",
    "epoch 31: avg_loss: 7.673711E+09, X_loss: 3.835244E+09, Y_loss: 3.838467E+09\n",
    "\n",
    "epoch 32: avg_loss: 7.659816E+09, X_loss: 3.828260E+09, Y_loss: 3.831556E+09\n",
    "\n",
    "epoch 33: avg_loss: 7.652663E+09, X_loss: 3.824838E+09, Y_loss: 3.827825E+09\n",
    "\n",
    "epoch 34: avg_loss: 7.649366E+09, X_loss: 3.822814E+09, Y_loss: 3.826553E+09\n",
    "\n",
    "epoch 35: avg_loss: 7.648862E+09, X_loss: 3.822572E+09, Y_loss: 3.826290E+09\n",
    "\n",
    "epoch 36: avg_loss: 7.631035E+09, X_loss: 3.813897E+09, Y_loss: 3.817138E+09\n",
    "\n",
    "epoch 37: avg_loss: 7.629297E+09, X_loss: 3.813052E+09, Y_loss: 3.816245E+09\n",
    "\n",
    "epoch 38: avg_loss: 7.621552E+09, X_loss: 3.809175E+09, Y_loss: 3.812377E+09\n",
    "\n",
    "epoch 39: avg_loss: 7.618369E+09, X_loss: 3.807585E+09, Y_loss: 3.810784E+09\n",
    "\n",
    "epoch 40: avg_loss: 7.614441E+09, X_loss: 3.805569E+09, Y_loss: 3.808872E+09\n",
    "\n",
    "epoch 41: avg_loss: 7.605903E+09, X_loss: 3.801374E+09, Y_loss: 3.804529E+09\n",
    "\n",
    "epoch 42: avg_loss: 7.596602E+09, X_loss: 3.796889E+09, Y_loss: 3.799714E+09\n",
    "\n",
    "epoch 43: avg_loss: 7.595028E+09, X_loss: 3.795907E+09, Y_loss: 3.799121E+09\n",
    "\n",
    "epoch 44: avg_loss: 7.587319E+09, X_loss: 3.792189E+09, Y_loss: 3.795130E+09\n",
    "\n",
    "epoch 45: avg_loss: 7.598296E+09, X_loss: 3.797229E+09, Y_loss: 3.801067E+09\n",
    "\n",
    "epoch 46: avg_loss: 7.579427E+09, X_loss: 3.788251E+09, Y_loss: 3.791176E+09\n",
    "\n",
    "epoch 47: avg_loss: 7.575313E+09, X_loss: 3.786312E+09, Y_loss: 3.789001E+09\n",
    "\n",
    "epoch 48: avg_loss: 7.578403E+09, X_loss: 3.787612E+09, Y_loss: 3.790791E+09\n",
    "\n",
    "epoch 49: avg_loss: 7.573361E+09, X_loss: 3.785110E+09, Y_loss: 3.788251E+09\n",
    "\n",
    "epoch 50: avg_loss: 7.567872E+09, X_loss: 3.782383E+09, Y_loss: 3.785490E+09\n",
    "\n",
    "epoch 51: avg_loss: 7.560295E+09, X_loss: 3.778831E+09, Y_loss: 3.781463E+09\n",
    "\n",
    "epoch 52: avg_loss: 7.558993E+09, X_loss: 3.777954E+09, Y_loss: 3.781039E+09\n",
    "\n",
    "epoch 53: avg_loss: 7.553727E+09, X_loss: 3.775370E+09, Y_loss: 3.778356E+09\n",
    "\n",
    "epoch 54: avg_loss: 7.550731E+09, X_loss: 3.773893E+09, Y_loss: 3.776838E+09\n",
    "\n",
    "epoch 55: avg_loss: 7.546114E+09, X_loss: 3.771349E+09, Y_loss: 3.774765E+09\n",
    "\n",
    "epoch 56: avg_loss: 7.548885E+09, X_loss: 3.772754E+09, Y_loss: 3.776131E+09\n",
    "\n",
    "epoch 57: avg_loss: 7.543435E+09, X_loss: 3.770278E+09, Y_loss: 3.773157E+09\n",
    "\n",
    "epoch 58: avg_loss: 7.534256E+09, X_loss: 3.765740E+09, Y_loss: 3.768516E+09\n",
    "\n",
    "epoch 59: avg_loss: 7.537990E+09, X_loss: 3.767338E+09, Y_loss: 3.770652E+09\n",
    "\n",
    "epoch 60: avg_loss: 7.529663E+09, X_loss: 3.763306E+09, Y_loss: 3.766357E+09\n",
    "\n",
    "epoch 61: avg_loss: 7.527268E+09, X_loss: 3.762269E+09, Y_loss: 3.764998E+09\n",
    "\n",
    "epoch 62: avg_loss: 7.526392E+09, X_loss: 3.761935E+09, Y_loss: 3.764457E+09\n",
    "\n",
    "epoch 63: avg_loss: 7.524954E+09, X_loss: 3.760874E+09, Y_loss: 3.764079E+09\n",
    "\n",
    "epoch 64: avg_loss: 7.520553E+09, X_loss: 3.758764E+09, Y_loss: 3.761789E+09\n",
    "\n",
    "epoch 65: avg_loss: 7.515540E+09, X_loss: 3.756169E+09, Y_loss: 3.759371E+09\n",
    "\n",
    "​\n",
    "\n",
    "sz_avg: \n",
    "\n",
    "epoch 1: avg_loss: 1.169001E+03, X_loss: 5.847401E+02, Y_loss: 5.839871E+02\n",
    "\n",
    "epoch 2: avg_loss: 1.140517E+03, X_loss: 5.699434E+02, Y_loss: 5.702196E+02\n",
    "\n",
    "epoch 3: avg_loss: 1.120446E+03, X_loss: 5.594596E+02, Y_loss: 5.605708E+02\n",
    "\n",
    "epoch 4: avg_loss: 1.095087E+03, X_loss: 5.469551E+02, Y_loss: 5.476533E+02\n",
    "\n",
    "epoch 5: avg_loss: 1.082718E+03, X_loss: 5.406462E+02, Y_loss: 5.415279E+02\n",
    "\n",
    "epoch 6: avg_loss: 1.069817E+03, X_loss: 5.341444E+02, Y_loss: 5.350492E+02\n",
    "\n",
    "​\n",
    "epoch 30: avg_loss: 7.678288E+09, X_loss: 3.837486E+09, Y_loss: 3.840802E+09\n",
    "epoch 31: avg_loss: 7.673711E+09, X_loss: 3.835244E+09, Y_loss: 3.838467E+09\n",
    "epoch 32: avg_loss: 7.659816E+09, X_loss: 3.828260E+09, Y_loss: 3.831556E+09\n",
    "epoch 33: avg_loss: 7.652663E+09, X_loss: 3.824838E+09, Y_loss: 3.827825E+09\n",
    "epoch 34: avg_loss: 7.649366E+09, X_loss: 3.822814E+09, Y_loss: 3.826553E+09\n",
    "epoch 35: avg_loss: 7.648862E+09, X_loss: 3.822572E+09, Y_loss: 3.826290E+09\n",
    "epoch 36: avg_loss: 7.631035E+09, X_loss: 3.813897E+09, Y_loss: 3.817138E+09\n",
    "epoch 37: avg_loss: 7.629297E+09, X_loss: 3.813052E+09, Y_loss: 3.816245E+09\n",
    "epoch 38: avg_loss: 7.621552E+09, X_loss: 3.809175E+09, Y_loss: 3.812377E+09\n",
    "epoch 39: avg_loss: 7.618369E+09, X_loss: 3.807585E+09, Y_loss: 3.810784E+09\n",
    "epoch 40: avg_loss: 7.614441E+09, X_loss: 3.805569E+09, Y_loss: 3.808872E+09\n",
    "epoch 41: avg_loss: 7.605903E+09, X_loss: 3.801374E+09, Y_loss: 3.804529E+09\n",
    "epoch 42: avg_loss: 7.596602E+09, X_loss: 3.796889E+09, Y_loss: 3.799714E+09\n",
    "epoch 43: avg_loss: 7.595028E+09, X_loss: 3.795907E+09, Y_loss: 3.799121E+09\n",
    "epoch 44: avg_loss: 7.587319E+09, X_loss: 3.792189E+09, Y_loss: 3.795130E+09\n",
    "epoch 45: avg_loss: 7.598296E+09, X_loss: 3.797229E+09, Y_loss: 3.801067E+09\n",
    "epoch 46: avg_loss: 7.579427E+09, X_loss: 3.788251E+09, Y_loss: 3.791176E+09\n",
    "epoch 47: avg_loss: 7.575313E+09, X_loss: 3.786312E+09, Y_loss: 3.789001E+09\n",
    "epoch 48: avg_loss: 7.578403E+09, X_loss: 3.787612E+09, Y_loss: 3.790791E+09\n",
    "epoch 49: avg_loss: 7.573361E+09, X_loss: 3.785110E+09, Y_loss: 3.788251E+09\n",
    "epoch 50: avg_loss: 7.567872E+09, X_loss: 3.782383E+09, Y_loss: 3.785490E+09\n",
    "epoch 51: avg_loss: 7.560295E+09, X_loss: 3.778831E+09, Y_loss: 3.781463E+09\n",
    "epoch 52: avg_loss: 7.558993E+09, X_loss: 3.777954E+09, Y_loss: 3.781039E+09\n",
    "epoch 53: avg_loss: 7.553727E+09, X_loss: 3.775370E+09, Y_loss: 3.778356E+09\n",
    "epoch 54: avg_loss: 7.550731E+09, X_loss: 3.773893E+09, Y_loss: 3.776838E+09\n",
    "epoch 55: avg_loss: 7.546114E+09, X_loss: 3.771349E+09, Y_loss: 3.774765E+09\n",
    "epoch 56: avg_loss: 7.548885E+09, X_loss: 3.772754E+09, Y_loss: 3.776131E+09\n",
    "epoch 57: avg_loss: 7.543435E+09, X_loss: 3.770278E+09, Y_loss: 3.773157E+09\n",
    "epoch 58: avg_loss: 7.534256E+09, X_loss: 3.765740E+09, Y_loss: 3.768516E+09\n",
    "epoch 59: avg_loss: 7.537990E+09, X_loss: 3.767338E+09, Y_loss: 3.770652E+09\n",
    "epoch 60: avg_loss: 7.529663E+09, X_loss: 3.763306E+09, Y_loss: 3.766357E+09\n",
    "epoch 61: avg_loss: 7.527268E+09, X_loss: 3.762269E+09, Y_loss: 3.764998E+09\n",
    "epoch 62: avg_loss: 7.526392E+09, X_loss: 3.761935E+09, Y_loss: 3.764457E+09\n",
    "epoch 63: avg_loss: 7.524954E+09, X_loss: 3.760874E+09, Y_loss: 3.764079E+09\n",
    "epoch 64: avg_loss: 7.520553E+09, X_loss: 3.758764E+09, Y_loss: 3.761789E+09\n",
    "epoch 65: avg_loss: 7.515540E+09, X_loss: 3.756169E+09, Y_loss: 3.759371E+09\n",
    "\n",
    "sz_avg: \n",
    "epoch 1: avg_loss: 1.169001E+03, X_loss: 5.847401E+02, Y_loss: 5.839871E+02\n",
    "epoch 2: avg_loss: 1.140517E+03, X_loss: 5.699434E+02, Y_loss: 5.702196E+02\n",
    "epoch 3: avg_loss: 1.120446E+03, X_loss: 5.594596E+02, Y_loss: 5.605708E+02\n",
    "epoch 4: avg_loss: 1.095087E+03, X_loss: 5.469551E+02, Y_loss: 5.476533E+02\n",
    "epoch 5: avg_loss: 1.082718E+03, X_loss: 5.406462E+02, Y_loss: 5.415279E+02\n",
    "epoch 6: avg_loss: 1.069817E+03, X_loss: 5.341444E+02, Y_loss: 5.350492E+02\n",
    "\n",
    "ReLU:\n",
    "epoch 1: avg_loss: 1.178547E+03, X_loss: 5.894318E+02, Y_loss: 5.886180E+02\n",
    "epoch 2: avg_loss: 1.138638E+03, X_loss: 5.691905E+02, Y_loss: 5.687600E+02\n",
    "epoch 3: avg_loss: 1.113760E+03, X_loss: 5.565547E+02, Y_loss: 5.564679E+02\n",
    "epoch 4: avg_loss: 1.099022E+03, X_loss: 5.490661E+02, Y_loss: 5.491667E+02\n",
    "epoch 5: avg_loss: 1.088752E+03, X_loss: 5.438770E+02, Y_loss: 5.440500E+02\n",
    "epoch 6: avg_loss: 1.078698E+03, X_loss: 5.387720E+02, Y_loss: 5.390413E+02\n",
    "epoch 7: avg_loss: 1.076399E+03, X_loss: 5.375281E+02, Y_loss: 5.378981E+02\n",
    "epoch 8: avg_loss: 1.073367E+03, X_loss: 5.359095E+02, Y_loss: 5.364334E+02\n",
    "epoch 9: avg_loss: 1.068188E+03, X_loss: 5.333630E+02, Y_loss: 5.337301E+02\n",
    "epoch 10: avg_loss: 1.065971E+03, X_loss: 5.321542E+02, Y_loss: 5.326359E+02\n",
    "epoch 11: avg_loss: 1.064372E+03, X_loss: 5.312989E+02, Y_loss: 5.318276E+02\n",
    "epoch 12: avg_loss: 1.059669E+03, X_loss: 5.289123E+02, Y_loss: 5.294377E+02\n",
    "epoch 13: avg_loss: 1.057942E+03, X_loss: 5.279874E+02, Y_loss: 5.285477E+02\n",
    "epoch 14: avg_loss: 1.054987E+03, X_loss: 5.263777E+02, Y_loss: 5.270772E+02\n",
    "epoch 15: avg_loss: 1.053578E+03, X_loss: 5.254850E+02, Y_loss: 5.264909E+02\n",
    "epoch 16: avg_loss: 1.049772E+03, X_loss: 5.233617E+02, Y_loss: 5.246709E+02\n",
    "epoch 17: avg_loss: 1.047307E+03, X_loss: 5.221540E+02, Y_loss: 5.232820E+02\n",
    "epoch 18: avg_loss: 1.042483E+03, X_loss: 5.198569E+02, Y_loss: 5.205850E+02\n",
    "epoch 19: avg_loss: 1.039948E+03, X_loss: 5.186033E+02, Y_loss: 5.191108E+02\n",
    "epoch 20: avg_loss: 1.035753E+03, X_loss: 5.164451E+02, Y_loss: 5.168867E+02\n",
    "epoch 21: avg_loss: 1.035532E+03, X_loss: 5.162011E+02, Y_loss: 5.167450E+02\n",
    "epoch 22: avg_loss: 1.033143E+03, X_loss: 5.149666E+02, Y_loss: 5.154507E+02\n",
    "epoch 23: avg_loss: 1.029338E+03, X_loss: 5.130508E+02, Y_loss: 5.133723E+02\n",
    "epoch 24: avg_loss: 1.029707E+03, X_loss: 5.130586E+02, Y_loss: 5.135003E+02\n",
    "epoch 25: avg_loss: 1.026415E+03, X_loss: 5.113178E+02, Y_loss: 5.116632E+02\n",
    "epoch 26: avg_loss: 1.025012E+03, X_loss: 5.104740E+02, Y_loss: 5.108761E+02\n",
    "epoch 27: avg_loss: 1.023656E+03, X_loss: 5.097137E+02, Y_loss: 5.100623E+02\n",
    "epoch 28: avg_loss: 1.022829E+03, X_loss: 5.091517E+02, Y_loss: 5.094488E+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"180710_latentpreddiff_sz_avg_false_6.68E+09\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.save(conv_model.state_dict(),model_name+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_quality(model,data, batch_size=16):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    with T.no_grad():\n",
    "        for i in range(4):\n",
    "            time = np.random.randint(len(data))\n",
    "            z = np.random.randint(nZ)\n",
    "            mse_X = 0\n",
    "            mse_X_pred_to_Y = 0\n",
    "            mse_Y_pred_to_X = 0\n",
    "            mse_Y = 0\n",
    "            for batch_data in dataloader:\n",
    "                X, Y = batch_data\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "                X_pred, Y_pred, _, _ = model(X)\n",
    "                mse_X += float(F.mse_loss(X_pred,X).cpu())\n",
    "                mse_X_pred_to_Y += float(F.mse_loss(X_pred,Y).cpu())\n",
    "                mse_Y_pred_to_X += float(F.mse_loss(Y_pred,X).cpu())\n",
    "                mse_Y += float(F.mse_loss(Y_pred,Y).cpu())\n",
    "        return mse_X, mse_X_pred_to_Y, mse_Y_pred_to_X, mse_Y\n",
    "\n",
    "pred_quality = prediction_quality(conv_model, data)\n",
    "print(\"MSE(X_pred,X)={:.0f}, MSE(X_pred,Y)={:.0f}\\nMSE(Y_pred,Y)={:.0f}, MSE(Y_pred,X)={:.0f}\".format(*pred_quality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_vs_real(model,data):\n",
    "    plt.figure(figsize=(30,15))\n",
    "\n",
    "    with T.no_grad():\n",
    "        for i in range(4):\n",
    "            time = np.random.randint(len(data))\n",
    "            z = np.random.randint(nZ)\n",
    "            X, Y = data[time]\n",
    "            x = X[None].cuda()\n",
    "            y = Y[None].cuda()\n",
    "            X_pred, Y_pred, _, _ = model(x)\n",
    "            mse_X = float(F.mse_loss(X_pred,x).cpu())\n",
    "            mse_X_pred_to_Y = float(F.mse_loss(X_pred,y).cpu())\n",
    "            mse_Y_pred_to_X = float(F.mse_loss(Y_pred,x).cpu())\n",
    "            mse_Y = float(F.mse_loss(Y_pred,y).cpu())\n",
    "            prev_loss = float(F.mse_loss(x,y).cpu())\n",
    "#             x_zero_loss = float(F.mse_loss(x,T.zeros_like(x)).cpu())\n",
    "#             y_zero_loss = float(F.mse_loss(y,T.zeros_like(y)).cpu())\n",
    "            mymin = min(float(y[0,z].min()[0]),float(x[0,z].min()[0]),float(X_pred[0,z].min()[0]))\n",
    "            mymax = max(float(y[0,z].max()[0]),float(x[0,z].max()[0]),float(X_pred[0,z].max()[0]))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+1)\n",
    "            plt.imshow(X[z].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"Time=\"+str(time) + \", z=\"+str(z))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+2)\n",
    "            plt.imshow(Y[z].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"Time=\"+str(time+1) + \", z=\"+str(z))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+3)\n",
    "            plt.imshow(X_pred[0,z].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"MSE: (X_pred,X)={:.0f}, (X_pred,Y)={:.0f}\".format(mse_X,mse_X_pred_to_Y))\n",
    "            \n",
    "            plt.subplot(4,4,i*4+4)\n",
    "            plt.imshow(Y_pred[0,z].cpu().numpy(), vmin=mymin, vmax=mymax)\n",
    "            plt.title(\"MSE: (Y_pred,Y)={:.0f}, (Y_pred,X)={:.0f}\".format(mse_Y,mse_Y_pred_to_X))\n",
    "\n",
    "plot_model_vs_real(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_from_embedding(model,frame,embedding,niters=20, lr=1e-3):\n",
    "    model.eval()\n",
    "    frame = frame.cuda()\n",
    "    frame.requires_grad = True\n",
    "    embedding_pred, _ = model.encode(frame)\n",
    "    print(embedding_pred.shape)\n",
    "    embedding_pred.backward(gradient=embedding)\n",
    "    return frame.grad[0]\n",
    "\n",
    "# frame = data[0][0]\n",
    "# embedding = T.from_numpy(np.eye(10)[0].astype(np.float32)).cuda()\n",
    "# prev_img = get_gradient_from_embedding(conv_model, frame[None], embedding[None])\n",
    "# with T.no_grad():\n",
    "#     next_img = conv_model.decode(embedding[None])[0]\n",
    "# plt.imshow(prev_img[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_from_embedding(model,frame,embedding,niters=75, lr=1e-1, rand=False):\n",
    "    \"Take an embedding vector, and use backprop to find the volume\"\n",
    "    if rand:\n",
    "        prev_img = T.rand_like(frame[None], requires_grad=True).cuda()\n",
    "    else:\n",
    "        prev_img = frame[None].cuda()\n",
    "        prev_img.requires_grad = True\n",
    "    optimizer = T.optim.Adam([prev_img],lr=lr)\n",
    "    model.eval()\n",
    "    for i in range(niters):\n",
    "        embedding_pred, _ = model.encode(prev_img)\n",
    "        loss = F.mse_loss(embedding_pred,embedding[None]) #+ 1e-7*T.norm(prev_img,1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(\"iter {} loss: \".format(i), float(loss))\n",
    "    model.train()\n",
    "    return prev_img[0].detach().cpu().numpy()\n",
    "\n",
    "# frame = data[0][0].cuda()\n",
    "# embedding = T.from_numpy(1000*np.eye(10)[1].astype(np.float32)).cuda()\n",
    "# prev_img = get_input_from_embedding(conv_model, frame, embedding,niters=81, rand=True)\n",
    "# plt.imshow(prev_img[6])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imgs = []\n",
    "for _ in range(10):\n",
    "    imgs.append(get_input_from_embedding(conv_model, frame, embedding,niters=81, rand=True)[[6]])\n",
    "plt.imshow(np.vstack(imgs).mean(0))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "frame = data[500][0]\n",
    "# frame = 'rand'\n",
    "embedding = T.from_numpy(1000*np.eye(10)[1].astype(np.float32)).cuda()\n",
    "prev_img = get_input_from_embedding(conv_model, frame, embedding,niters=100)\n",
    "plt.imshow(prev_img[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret(model,prev_vol, next_vol, nEmbedding, prev_func):\n",
    "    \"Plot prev & next frame for each latent dimension\"\n",
    "    plt.figure(figsize=(10,20))\n",
    "    \n",
    "    embedding = T.from_numpy(np.zeros(nEmbedding).astype(np.float32)).cuda()[None]\n",
    "    with T.no_grad():\n",
    "        prev_img = model.decode(embedding)[0]\n",
    "        next_img = model.decode(model.predict(embedding))[0]\n",
    "    plt.subplot(1+nEmbedding,3,1)\n",
    "    plt.imshow(prev_img[6])\n",
    "    plt.title(\"Prev (Zero Vector)\")\n",
    "    plt.subplot(1+nEmbedding,3,2)\n",
    "    plt.imshow(next_img[6])\n",
    "    plt.title(\"Next (Zero Vector)\")\n",
    "    plt.subplot(1+nEmbedding,3,3)\n",
    "    plt.imshow(next_img[6] - prev_img[6])\n",
    "    plt.title(\"Diff (Zero Vector)\")\n",
    "    for i in range(nEmbedding):\n",
    "        embedding = T.from_numpy(np.eye(nEmbedding)[i].astype(np.float32)).cuda()[None]\n",
    "        with T.no_grad():\n",
    "            prev_img = model.decode(embedding)[0]\n",
    "            next_img = model.decode(model.predict(embedding))[0]\n",
    "        plt.subplot(1+nEmbedding,3,i*3+4)\n",
    "        plt.imshow(prev_img[6])\n",
    "        plt.title(\"Prev (Dim {})\".format(i))\n",
    "        plt.subplot(1+nEmbedding,3,i*3+5)\n",
    "        plt.imshow(next_img[6])\n",
    "        plt.title(\"Next (Dim {})\".format(i))\n",
    "        plt.subplot(1+nEmbedding,3,i*3+6)\n",
    "        plt.imshow(next_img[6]-prev_img[6])\n",
    "        plt.title(\"Diff (Dim {})\".format(i))\n",
    "    plt.tight_layout()\n",
    "\n",
    "x, y = data[1000]\n",
    "interpret(conv_model,x,y,10,get_gradient_from_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_over_time(model,data, batch_size=64):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    embeddings = []\n",
    "#     model.eval()\n",
    "    for batch_data in dataloader:\n",
    "        X, _ = batch_data\n",
    "        # add 1 channel\n",
    "        with T.no_grad():\n",
    "            embedding, _ = model.encode(X.cuda())\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "#     model.train()\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    nEmbeddings = embeddings.shape[1]\n",
    "    half = int(np.ceil(nEmbeddings / 2))\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(embeddings[:,0:half])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(embeddings[:,half:])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    plt.tight_layout()\n",
    "    return embeddings\n",
    "embeddings = plot_embedding_over_time(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del imaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo.io\n",
    "def makePredVideo(model, data, batch_size=6):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    writer = skvideo.io.FFmpegWriter(model_name + \".mp4\",outputdict={\n",
    "        '-b': '30000000', '-vcodec': 'libx264'})\n",
    "    for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "        with T.no_grad():\n",
    "            _, vol_preds, _, _= model(X.cuda())\n",
    "        for actual,pred in zip(Y,vol_preds):\n",
    "            # 7th z layer\n",
    "            f = pred[6]\n",
    "            H = f.shape[0]\n",
    "            frame = np.zeros([H*2,f.shape[1]])\n",
    "            frame[:H] = actual[6]\n",
    "            frame[H:] = pred[6]\n",
    "            writer.writeFrame(frame)\n",
    "            \n",
    "    writer.close()\n",
    "    return frame, actual[6], pred[6]\n",
    "frame, actual, pred = makePredVideo(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with T.no_grad():\n",
    "    time = 1864\n",
    "    z = 6\n",
    "    X, Y = data[time]\n",
    "    x = X[None].cuda()\n",
    "    y = Y[None].cuda()\n",
    "    X_pred, _, _ = conv_model(x)\n",
    "    loss = float(F.mse_loss(X_pred,y).cpu())\n",
    "    prev_loss = float(F.mse_loss(x,y).cpu())\n",
    "    zero_loss = float(F.mse_loss(y,T.zeros_like(y)).cpu())\n",
    "    mymax = max(float(y[0,z].max()[0]),float(x[0,z].max()[0]),float(X_pred[0,z].max()[0]))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(X[z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "    plt.title(\"Time=\"+str(time) + \", z=\"+str(z))\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(Y[z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "    plt.title(\"Time=\"+str(time+1) + \", z=\"+str(z))\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(X_pred[0,z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "    plt.title(\"MSE: Pred={:.0f}, Prev={:.0f}, Zero={:.0f}\".format(loss,prev_loss,zero_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) avg (Y_pred, Y) and (Y_pred, X)\n",
    "# 1) need to optimize X,X_pred vs (Y_pred, Y) and (Y_pred, X)\n",
    "# a) add adiitional frames\n",
    "# b) add 3D conv\n",
    "\n",
    "# 2) fix test/train weirdness\n",
    "# 3) out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_over_time(model,data, batch_size=8):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    embeddings = []\n",
    "    with T.no_grad():\n",
    "        for batch_data in dataloader:\n",
    "        X, Y = batch_data\n",
    "            embedding, _ = model.encode(X.cuda())\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "#     model.train()\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    nEmbeddings = embeddings.shape[1]\n",
    "    half = int(np.ceil(nEmbeddings / 2))\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(embeddings[:,0:half])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(embeddings[:,half:])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    plt.tight_layout()\n",
    "    return embeddings\n",
    "embeddings = plot_embedding_over_time(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(actual.min(),actual.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(actual.min(),actual.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred.min(),pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(actual,vmin=0,vmax=862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred,vmin=0,vmax=862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
