{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment the PythonPath so python can find necessary code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime\n",
    "LF_CODE_PATH = os.path.expanduser('/home/andalman/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('/home/andalman/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('/home/andalman/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import useful python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import skimage.io\n",
    "import visualization_utils as vizutil\n",
    "import seaborn as sns\n",
    "from skimage.filters import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "hbstim_imaging_utils provides a list of all the datasets and provides a helper class to make loading the data easy.\n",
    "\n",
    "The data_sets are split into two conditions:  \n",
    "'c': chr2 negative fish (n=4)  \n",
    "'e': chr2 positive fish (n=6)  \n",
    "  \n",
    "all_data is a dictionary keyed by the condition.  \n",
    "all_data[condition] contains a list of HbStim_Fish objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hbstim_imaging_utils as hbutils\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "# reload(hbutils)\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "# all_data = hbutils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "print 'c, n =', len(all_data['c'])\n",
    "print 'e, n =', len(all_data['e'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grab the first experimental fish\n",
    "print('p2_fish')\n",
    "f = all_data.e[1] \n",
    "print 'Num z-planes imaged:', f.num_zplanes\n",
    "print 'Volume-Rate:', 1/np.diff(f.frame_st[:,0]).mean() #frame_st is #frames x #slices, we examine interval between imaging first slice\n",
    "print 'Movement Times', f.forward_swim_times\n",
    "print 'Shock times', f.shock_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = all_data.e[1] \n",
    "# print 'Num z-planes imaged:', f.num_zplanes\n",
    "# print 'Number of stimulation trials:', f.numtrials\n",
    "print 'Num z-planes imaged:', f.num_zplanes\n",
    "print 'Volume-Rate:', 1/np.diff(f.frame_st[:,0]).mean() #frame_st is #frames x #slices, we examine interval between imaging first slice\n",
    "print 'Movement Times', f.forward_swim_times\n",
    "print 'Shock times', f.shock_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_roi_table` method returns a dataframe of all the rois for teh fish.  Each row of this table represents an ROI and specified the place the ROI is in, the pixels that are included in the ROI, the centroid of the ROI, and which brain regions the ROI is in.  \n",
    "\n",
    "Note, this data is older and was processed by simply segmenting the anatomical images.  Thus the data is does not look as clean as data that is cleaned up and processed using CNMF, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = f.get_roi_table() #this can be slow to run the first time as data is loaded from files\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'get_signals_raw' returns a matrix containing the raw fluorescent signal associated with each ROI.  Each row of this matrix is associated with the corresponding row of the ROI table.  \n",
    "\n",
    "Note, I only use the second half of the signal matrix, because the agarose had not fully hardened during the first of imaging which cause the fish to drift in z slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = f.get_signals_raw(z=None)\n",
    "#M = hbutils.df_over_f(M)\n",
    "print 'Num ROIs:', df.shape[0]\n",
    "print 'Shape of signal matrix', M.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also various methods for grabbing the raw imaging data:  \n",
    "get_tif_as_vol  \n",
    "get_tif_rasl\n",
    "\n",
    "We can use this to visualize a few ROIs in particular plane/slice and brain region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.stattools as stat\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcause_pval(X,lag=1):\n",
    "    gc = stat.grangercausalitytests(X,lag, verbose=False)\n",
    "    x = list(gc.values())[0]\n",
    "    return x[0][\"params_ftest\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a,0)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    rm = ret[n - 1:] / n\n",
    "    pad_start = np.full((n-1,rm.shape[1]), rm[0])\n",
    "    return np.vstack([pad_start, rm])\n",
    "\n",
    "def ewma(data,span):\n",
    "    df = DataFrame(data)\n",
    "    return df.ewm(span).mean().values\n",
    "\n",
    "def df_f(x,ma_window=60,span=60):\n",
    "    u = moving_average(x,ma_window)\n",
    "    return ewma((x - u)/(u+1e-10), span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(M[0,0:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_f(M[[0],0:400].T,6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mdf = df_f(M.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis(M.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew(M.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurtosis(Mdf.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew(Mdf.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Mdf.reshape(-1)\n",
    "mu, std = norm.fit(data)\n",
    "\n",
    "# Plot the histogram.\n",
    "plt.hist(data, bins=1000, normed=True, alpha=0.6)\n",
    "\n",
    "# Plot the PDF.\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 1000)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "title = \"Fit results: mu = %.2f,  std = %.2f\" % (mu, std)\n",
    "plt.title(title)\n",
    "plt.xlim(-.5,.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(-.5,.5,0.01)\n",
    "plt.hist(Mdf[0:1000,0:1000].reshape(-1),bins);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(M[0:1000,0:1000].reshape(-1),50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,100,5)\n",
    "g = np.random.normal(0,1,100000)\n",
    "y = [np.percentile(g,i) for i in x]\n",
    "plt.hist(g,50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcause_pval(Mdf[:,0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "niter = 10000\n",
    "pvals = np.zeros(niter)\n",
    "nroi = M.shape[0]\n",
    "for n in range(niter):\n",
    "    i, j = np.random.choice(nroi,2,False)\n",
    "    pvals[n] = gcause_pval(Mdf[:,[i,j]])\n",
    "plt.hist(pvals,100, density=True)\n",
    "plt.title(\"Granger causality of random neuron pairs\")\n",
    "plt.xlabel(\"p val\")\n",
    "plt.ylabel(\"density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho_regions = [u'in_r_cerebellum', u'in_l_cerebellum', u'in_l_vthal',\n",
    "       u'in_l_tectum', u'in_l_raphe', u'in_r_hind', u'in_l_hind',\n",
    "       u'in_l_dthal', u'in_r_tectum', u'in_r_LHb', u'in_r_dthal',\n",
    "       u'in_r_raphe', u'in_r_tel',\n",
    "       u'in_l_MHb', u'in_l_tel', u'in_r_MHb', u'in_l_LHb', u'in_r_vthal']\n",
    "\n",
    "regions = df.columns[np.where([c in ortho_regions for c in df.columns])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[regions].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_in_one_region = np.where(df[regions].sum(axis=1)==1)[0]\n",
    "neurons_in_Hb = np.array(df.query(\"in_r_LHb==1 | in_l_LHb==1\").index)\n",
    "neurons_in_Ra = np.array(df.query(\"in_r_raphe==1 | in_l_raphe==1\").index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhab = len(neurons_in_Hb)\n",
    "nra = len(neurons_in_Ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region(row,regions):\n",
    "    return np.where(row[regions])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niter = 100000\n",
    "nroi = neurons_in_one_region.shape[0]\n",
    "def g_draw(n):\n",
    "    np.random.seed(None)\n",
    "    ii, jj = np.random.choice(nroi,2,False)\n",
    "#     ii = np.random.choice(nra,1,False)[0]\n",
    "    i, j = neurons_in_one_region[[ii,jj]]\n",
    "#     i = neurons_in_Ra[ii]\n",
    "    i_region = get_region(df.iloc[i],regions)\n",
    "    j_region = get_region(df.iloc[j],regions)\n",
    "    pval = gcause_pval(Mdf[:,[i,j]])\n",
    "    return [i_region, j_region,pval]\n",
    "    \n",
    "granger_list = Parallel(n_jobs=24)(delayed(g_draw)(n) for n in range(niter))\n",
    "granger = DataFrame(granger_list,columns=[\"from\",\"to\",\"pval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_idx = np.where(granger.pval < 0.05)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sig_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "from bokeh.sampledata.airport_routes import routes, airports\n",
    "\n",
    "hv.extension('matplotlib')\n",
    "%output fig='svg' size=300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = granger.iloc[sig_idx].groupby(['from', 'to']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_names = map(lambda x: x[3:], ortho_regions)\n",
    "nodes = hv.Dataset(DataFrame(data={\"index\": np.arange(len(ortho_regions)), \"name\": region_names}),'index')\n",
    "chord = hv.Chord((links,nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Chord [edge_color_index='from' label_index='name' color_index='name']\n",
    "# %%opts Chord (cmap='default_colors' edge_cmap='default_colors')\n",
    "chord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparsity records\n",
    "alpha 0.5: 100% sparse\n",
    "alpha 1e-3: 99.9999% sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(Mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(Mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "might need to use: http://foges.github.io/pogs/\n",
    "currently ignoring intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimated end: \" + str(datetime.now() + timedelta(hours=2,minutes=24)))\n",
    "dynamics_lasso = Lasso(alpha=1e-5,fit_intercept=False)\n",
    "dynamics_lasso.fit(X,Y)\n",
    "np.savez(\"dynamics_lasso_coef_alpha=1e-5_nointercept_uwindow=6_expwindow=6\",dynamics_lasso.coef_)\n",
    "percent_sparse = np.nonzero(dynamics_lasso.coef_)[0].shape[0]/np.prod(dynamics_lasso.coef_.shape)\n",
    "print(\"Finished at: \" + str(datetime.now()))\n",
    "print(\"percent sparse: \" + str(percent_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = np.load(\"dynamics_lasso_coef_alpha=5e-4_nointercept_uwindow=6_expwindow=6.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(coef)[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - np.nonzero(coef)[0].shape[0]/np.prod(coef.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=4\n",
    "\n",
    "#Create a background image by averaging 200 frames and adjusting the gamma.\n",
    "back_img = np.power(f.get_tif_as_vol(z,range(1000,1200)).mean(axis=2),.4)\n",
    "\n",
    "#Select rois in raphe in this slices, and get their coordinates.\n",
    "coords = df[(df.in_l_LHb) & (df.z==z)].coords\n",
    "\n",
    "#Overlay the ROIs on the background image and display:\n",
    "img = vizutil.overlay_coords(back_img, coords, [0,0,1], alpha=.5)\n",
    "plt.figure(figsize=[20,20])\n",
    "plt.imshow(img,interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the imaging, 1P Scanning stimulation light is rotated between three locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print f.stim_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chr2- fish none of these locations contained ChR2.  \n",
    "  \n",
    "In Chr2+ fish, the left LHb and the right LHb contained ChR2 positive cells.   \n",
    "  \n",
    "The forebrain never has ChR2 positive cells. It serves as control stimulation location.  It controls for the fact that the stimulation light is visible to the fish, and thus acts as a visual stimulus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'num_frames_per_stim' indicates the number of volumes that are collected between stimulation locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print f.num_frames_per_stim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets call this number N.  Thus an experiment looks like:\n",
    "    \n",
    "Image N frames - Stim lHb - Image N frames - Stim forebrain - Image N frames - Stim rHb ...\n",
    "\n",
    "This repeated is `numtrials` times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print f.numtrials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frame numbers of all frames immediately following stimulation at a particular location is therefore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 'lHb'\n",
    "pos = (np.where(f.stim_locations == 'lHb')[0]+1) * f.num_frames_per_stim\n",
    "ndx = np.arange(pos, M.shape[1], f.trialsize)\n",
    "print ndx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ROI, I have computed whether the response to lHb (and rHb) stim is significantly different from the response to stimulation at the control location (forebrain).  \n",
    "\n",
    "The response on each trial is taken as the change in flourescence between a baseline window and a response window.  In the example below, the baseline window is the 10 volumes prior to stimulation, and the response windows is the first 3 volumes following stimulation.\n",
    "\n",
    "pvalues is a list of length # planes.  Each element is a list of the p-values of all the ROIs in that plane.\n",
    "\n",
    "Note, because `get_norm_response_stats` can be slow to run, it caches results for particular baseline and response windows.  If you specify windows, I haven't run before it can be slow to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues, rel_resps, abs_resps = f.get_norm_response_stats(stim_location='lHb', \n",
    "                                                          base_window_ndx=[-10,-9,-8,-7,-6,-5,-4,-3,-2,-1], \n",
    "                                                          resp_window_ndx=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_z = f.get_roi_table(z=0)\n",
    "print df_z.shape\n",
    "print pvalues[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(5)[:-1]"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
