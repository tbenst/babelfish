{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scipy.linalg\n",
    "from functools import partial\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import scipy.sparse as sparse\n",
    "from scipy import stats\n",
    "from __future__ import print_function\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pandas import DataFrame\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from torchvision.transforms import Resize\n",
    "import dill\n",
    "from joblib import Parallel, delayed\n",
    "import cv2\n",
    "import resource\n",
    "\n",
    "import os, sys, datetime\n",
    "LF_CODE_PATH = os.path.expanduser('~/projects/LFAnalyze/code')\n",
    "FT_CODE_PATH = os.path.expanduser('~/projects/fishTrax/code/analysis/')\n",
    "FD_CODE_PATH = os.path.expanduser('~/projects/fish_despair_notebooks/src/')\n",
    "sys.path.insert(0,LF_CODE_PATH)\n",
    "sys.path.insert(0,FT_CODE_PATH)\n",
    "sys.path.insert(0,FD_CODE_PATH)\n",
    "\n",
    "import passivity_2p_imaging_utils as p2putils\n",
    "reload(p2putils)\n",
    "tmp_dir = '/tmp/'\n",
    "all_data = p2putils.get_all_datasets(tmp_dir=tmp_dir)\n",
    "\n",
    "f = all_data['e'][2]\n",
    "\n",
    "# time_fish = T.from_numpy(f.frame_st.mean(1).astype(np.float32)).cuda()\n",
    "# u_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "# p_fish = T.cuda.FloatTensor(time_fish.shape).zero_()\n",
    "# u_fish[numpy.searchsorted(f.frame_et[:,-1], f.shock_st,side=\"left\")] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_gpu_memory_map():\n",
    "    \"\"\"Get the current gpu usage.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    usage: dict\n",
    "        Keys are device ids as integers.\n",
    "        Values are memory usage as integers in MB.\n",
    "    \"\"\"\n",
    "    result = subprocess.check_output(\n",
    "        [\n",
    "            'nvidia-smi', '--query-gpu=memory.used',\n",
    "            '--format=csv,nounits,noheader'\n",
    "        ])\n",
    "    # Convert lines into a dictionary\n",
    "    gpu_memory = [int(x) for x in result.strip().split('\\n')]\n",
    "    gpu_memory_map = dict(zip(range(len(gpu_memory)), gpu_memory))\n",
    "    return gpu_memory_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_from_z(z, fish):\n",
    "    tiff = fish.get_tif_rasl(z)\n",
    "    ntime = fish.frame_et.shape[0]\n",
    "    frames = np.zeros((ntime, tiff.frame_shape[0],tiff.frame_shape[1])).astype(np.float32)\n",
    "    for t in range(ntime):\n",
    "        frame = np.array(tiff.get_frame(t)).astype(np.float32)\n",
    "        frames[t] = frame\n",
    "    return frames\n",
    "\n",
    "def get_imaging_from_fish(f,n_jobs=8):\n",
    "    nZ = f.num_zplanes\n",
    "    # frames_by_z = pool.map(partial(get_frames_from_z, fish=f), range(nZ))\n",
    "    frames_by_z = Parallel(n_jobs=n_jobs)(delayed(get_frames_from_z)(z,fish=f) for z in range(nZ))\n",
    "    imaging = np.stack(frames_by_z).swapaxes(0,1).astype(np.float32)\n",
    "    return imaging\n",
    "\n",
    "def gen_imaging(nT, nZ, H, W):\n",
    "    return np.random.randint(0,3000,[nT,nZ,H,W]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_volume(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    new[0] = im\n",
    "    for i, img in enumerate(images[1:]):\n",
    "        new[i] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new\n",
    "\n",
    "def resize_batch(images, fx, fy, interpolation=cv2.INTER_CUBIC):\n",
    "    im = cv2.resize(images[0,0], None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    new = np.zeros([images.shape[0],images.shape[1], im.shape[0],im.shape[1]]).astype(np.float32)\n",
    "    for b, vol in enumerate(images):\n",
    "        for z, img in enumerate(vol):\n",
    "            new[b,z] = cv2.resize(img, None, fx=fx, fy=fy, interpolation=interpolation)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging = get_imaging_from_fish(f)\n",
    "# imaging = gen_imaging(32,11,232,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishImageData(Dataset):    \n",
    "    def __init__(self, imaging):\n",
    "        data = imaging - imaging.mean(0)\n",
    "        self.data = T.from_numpy(data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]-1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data[idx+1]\n",
    "    \n",
    "class FishDiffData(Dataset):    \n",
    "    def __init__(self, imaging):\n",
    "        X = imaging - imaging.mean(0)\n",
    "        self.X = T.from_numpy(X)\n",
    "        self.Y = T.from_numpy(np.diff(X))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.Y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "data = FishImageData(imaging)\n",
    "# data = FishDiffData(imaging)\n",
    "batch_size = 64\n",
    "nZ, H, W = data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_schedule(t,k=5):\n",
    "    t0 = t/2\n",
    "    k = k/t0\n",
    "    t = np.arange(t)\n",
    "    return (1/(1+np.exp(-k*(t-t0)))).astype(np.float32)\n",
    "\n",
    "plt.plot(sigmoid_schedule(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 64, layers[3], stride=2)\n",
    "#         self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "#         self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 232 x 512\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "#         print(x.shape)\n",
    "        # 58 x 128\n",
    "\n",
    "        x = self.layer1(x)\n",
    "#         print(x.shape)\n",
    "        # 29 x 64\n",
    "        x = self.layer2(x)\n",
    "#         print(x.shape)\n",
    "        # 15 x 32\n",
    "        x = self.layer3(x)\n",
    "#         print(x.shape)\n",
    "        # 8 x 16\n",
    "        x = self.layer4(x)\n",
    "        # 4 x 8\n",
    "        x = x.view(x.shape[0],-1).mean(1)\n",
    "        # 1 x 1\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "        return x[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(padding_type, kernel_size):\n",
    "    assert padding_type in ['SAME', 'VALID']\n",
    "    if padding_type == 'SAME':\n",
    "        return tuple((k - 1) // 2 for k in kernel_size)\n",
    "    return tuple(0 for _ in kernel_size)\n",
    "\n",
    "\n",
    "class Vol2D(nn.Module):\n",
    "    \"Use same 2D operations mapped over each z slice\"\n",
    "    def __init__(self, tensor=T.cuda.FloatTensor):\n",
    "        super(Vol2D, self).__init__()\n",
    "        self.tensor = tensor\n",
    "        \n",
    "    def vol_PixelShuffle(self, x):\n",
    "        # Helper for subpixel convolution\n",
    "        first = self.pixel_shuffle(x[:,0])\n",
    "        # b x z x H x W\n",
    "        ret = self.tensor(x.shape[0],x.shape[1],first.shape[2], first.shape[3])\n",
    "        for z in range(x.shape[1]):\n",
    "            ret[:,z] = self.pixel_shuffle(x[:,z])[:,0]\n",
    "        return ret\n",
    "        \n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def vol_MaxPool2d(self, x, kernel_size):\n",
    "        # batch x Z*C x H x W\n",
    "        input = x.view(x.shape[0],-1,x.shape[3],x.shape[4])\n",
    "        pooled = F.max_pool2d(input,kernel_size)\n",
    "        return pooled.reshape(pooled.shape[0],x.shape[1],x.shape[2],pooled.shape[2],pooled.shape[3])\n",
    "    \n",
    "    def vol_BatchNorm2d(self, x, bn):\n",
    "        activations = self.tensor(x.shape)\n",
    "        for z in range(x.shape[1]):\n",
    "            activations[:,z] = bn(x[:,z].contiguous())\n",
    "        return activations\n",
    "                \n",
    "    def vol_conv2d(self, x, weight, pad):\n",
    "        # batch x Z x C x H x W\n",
    "        activations = self.tensor(x.shape[0],x.shape[1],weight.shape[0],x.shape[3],x.shape[4])\n",
    "        for z in range(x.shape[1]):\n",
    "            activations[:,z] = F.conv2d(x[:,z], weight, padding=pad)\n",
    "        return activations\n",
    "\n",
    "class SuperResBlock(Vol2D):\n",
    "    \"\"\"Upsample Volume using subpixel convolution.\n",
    "    \n",
    "    Reference: https://arxiv.org/pdf/1609.05158.pdf\"\"\"\n",
    "    def __init__(self, upscale_factor, tensor):\n",
    "        super(SuperResBlock, self).__init__(tensor=T.cuda.FloatTensor)\n",
    "        self.tensor = tensor\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dconv1 = nn.Parameter(self.tensor(64,1,5,5))\n",
    "        self.dpad1 = (2,2)\n",
    "        self.dbn1 = nn.BatchNorm2d(64)\n",
    "        self.dconv2 = nn.Parameter(self.tensor(64,64,3,3))\n",
    "        self.dpad2 = (1,1)\n",
    "        self.dbn2 = nn.BatchNorm2d(64)\n",
    "        self.dconv3 = nn.Parameter(self.tensor(32,64,3,3))\n",
    "        self.dpad3 = (1,1)\n",
    "        self.dbn3 = nn.BatchNorm2d(32)\n",
    "        self.dconv4 = nn.Parameter(self.tensor(upscale_factor**2,32,3,3))\n",
    "        self.dpad4 = (1,1)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv1, self.dpad1), self.dbn1))\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv2, self.dpad2), self.dbn2))\n",
    "        x = self.activation(self.vol_BatchNorm2d(self.vol_conv2d(x, self.dconv3, self.dpad3), self.dbn3))\n",
    "        x = self.vol_conv2d(x, self.dconv4, self.dpad4)\n",
    "        x = self.vol_PixelShuffle(x)\n",
    "        # add back single channel\n",
    "        x = x[:,:,None]\n",
    "        return x\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        nn.init.orthogonal_(self.dconv1, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv2, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv3, nn.init.calculate_gain('relu'))\n",
    "        nn.init.orthogonal_(self.dconv4)\n",
    "        for bn in [self.dbn1,self.dbn2,self.dbn3]:\n",
    "            nn.init.constant_(bn.weight, 1)\n",
    "            nn.init.constant_(bn.bias, 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(Vol2D):\n",
    "    def __init__(self, nZ=11, H=232, W=512, nEmbedding=20, tensor=T.cuda.FloatTensor):\n",
    "        super(Conv, self).__init__(tensor)\n",
    "        self.tensor = tensor\n",
    "        self.nZ = nZ\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        self.lowH = 8\n",
    "        self.lowW = 16\n",
    "        self.lowFeatures = 1\n",
    "        # batch x channel x Z x H x W\n",
    "        # Encoding\n",
    "        self.resnet = ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "        self.resOut = 1\n",
    "        \n",
    "        # b x 11 x 32 x 11 x 25\n",
    "        self.encoding_mean = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        self.encoding_logvar = nn.Linear(self.resOut*self.nZ, nEmbedding)\n",
    "        \n",
    "        # Decoding\n",
    "        self.activation = nn.Tanh()\n",
    "        self.decoding = nn.Linear(nEmbedding,self.lowFeatures*nZ*self.lowH*self.lowW)\n",
    "        self.upconv1 = SuperResBlock(2,tensor)\n",
    "        # 11 x 16 x 32\n",
    "        self.upconv2 = SuperResBlock(2,tensor)\n",
    "        # 11 x 32 x 64\n",
    "        self.upconv3 = SuperResBlock(2,tensor)\n",
    "        # 11 x 64 x 128\n",
    "        self.upconv4 = SuperResBlock(2,tensor)\n",
    "        # 11 x 128 x 256\n",
    "        self.upconv5 = SuperResBlock(2,tensor)\n",
    "        # 11 x 256 x 512\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def sample_embedding(self, mu, logvar):\n",
    "        if self.training:\n",
    "            # during training so far, had this implementation which lowers logvar (until Jul 7, 2018)\n",
    "#             std = torch.exp(0.1*logvar)\n",
    "#             dist = T.distributions.normal.Normal(T.zeros_like(std),T.ones_like(std))\n",
    "#             std_z = dist.sample()\n",
    "#             return mu + std*std_z\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = x[:,:,None]\n",
    "        out = self.tensor(x.shape[0],x.shape[1],self.resOut)\n",
    "        for z in range(x.shape[1]):\n",
    "            out[:,z] = self.resnet(x[:,z])\n",
    "        mean = self.encoding_mean(out.reshape(x.shape[0],-1))\n",
    "        logvar = self.encoding_logvar(out.reshape(x.shape[0],-1))\n",
    "        return mean, logvar\n",
    "    \n",
    "    def crop(self, x):\n",
    "        cropH = (x.shape[2] - self.H)/2\n",
    "        cropW = (x.shape[3] - self.W)/2\n",
    "        if cropH>0:\n",
    "            x = x[:,:,int(np.floor(cropH)):-int(np.ceil(cropH))]\n",
    "        if cropW>0:\n",
    "            x = x[:,:,:,int(np.floor(cropW)):-int(np.ceil(cropW))]\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        # b x 20\n",
    "        x = self.activation(self.decoding(x))\n",
    "        x = x.reshape(x.shape[0],self.nZ,self.lowFeatures,self.lowH,self.lowW)\n",
    "        x = self.upconv1(x)\n",
    "        x = self.upconv2(x)\n",
    "        x = self.upconv3(x)\n",
    "        x = self.upconv4(x)\n",
    "        x = self.upconv5(x)\n",
    "        x = self.crop(x[:,:,0])\n",
    "        # squeeze channel\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        encoded = self.sample_embedding(mean, logvar)\n",
    "        decoded = self.decode(encoded)\n",
    "        return decoded, mean, logvar\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        nn.init.xavier_normal_(self.encoding_mean.weight)\n",
    "        # TODO - make larger?\n",
    "        nn.init.xavier_normal_(self.encoding_logvar.weight,1e-3)\n",
    "\n",
    "\n",
    "\n",
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(pred, target, mu, logvar):\n",
    "    MSE = F.mse_loss(pred, target, size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    var = logvar.exp()\n",
    "#     print(float(var.min()), float(var.max()))\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "#     reg = T.sum(logvar.exp())\n",
    "    reg = 0\n",
    "    return MSE, KLD, reg, float(mu.mean()), float(logvar.mean())\n",
    "    \n",
    "        \n",
    "# def train(model,data,nepochs=10, lambdaA=(1e-8, 1e-6), lambdaB=(1e-6, 1e-6),\n",
    "#           lambdaC=(1e-5, 1e-5), lambdaD=(1e-5, 1e-5), lr=0.1, verbose=True):\n",
    "def train(model,data,nepochs=10, lr=1e-3, half=False, cuda=True):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = T.optim.Adam(model.parameters(),lr=lr)\n",
    "#     optimizer = T.optim.SGD(model.parameters(),lr=lr, momentum=0.9)\n",
    "    kl_schedule = T.from_numpy(sigmoid_schedule(nepochs))\n",
    "    if cuda:\n",
    "        kl_schedule = kl_schedule.cuda()\n",
    "    for e in range(nepochs):\n",
    "        print(\"epoch {}: \".format(e), end=\"\")\n",
    "        cum_loss = 0\n",
    "        cum_mse_loss = 0\n",
    "        for batch_data in dataloader:\n",
    "            X, Y = batch_data\n",
    "            # add 1 channel\n",
    "            if half:\n",
    "                X = X.half()\n",
    "                Y = Y.half()\n",
    "            if cuda:\n",
    "                X = X.cuda()\n",
    "                Y = Y.cuda()\n",
    "            Y_pred, mean, logvar = model(X)\n",
    "            mse, kld, reg, mu_mean, logvar_mean = loss_function(Y_pred, Y, mean, logvar)\n",
    "            loss = mse + kl_schedule[e] * kld + reg\n",
    "            if e==0:\n",
    "                print(\"MSE: {:.3E}, KLD: {:.3E}, REG: {:.3E}\".format(float(mse),float(kld),float(reg)))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "            optimizer.step()\n",
    "            cum_loss += float(loss)\n",
    "            cum_mse_loss += float(mse)\n",
    "\n",
    "        print(\"avg_loss: {:3E}, mse_loss: {:3E}\".format(\n",
    "            cum_loss/len(data), cum_mse_loss/len(data)))\n",
    "        print(\"mu_mean: {:3E}, logvar_mean: {:3E}\".format(mu_mean,logvar_mean))\n",
    "        \n",
    "\n",
    "nEmbedding = 10\n",
    "batch_size = 8\n",
    "nZ, H, W = data[0][0].shape\n",
    "half=False\n",
    "cuda=True\n",
    "\n",
    "tensorlib = T\n",
    "if cuda:\n",
    "    tensorlib = T.cuda\n",
    "\n",
    "if half:\n",
    "    tensor = tensorlib.HalfTensor\n",
    "else:\n",
    "    tensor = tensorlib.FloatTensor\n",
    "\n",
    "conv_model = Conv(nZ,H,W,nEmbedding,tensor=tensor)\n",
    "if half:\n",
    "    conv_model.half()\n",
    "if cuda:\n",
    "    conv_model.cuda()\n",
    "print(\"total num params:\", np.sum([np.prod(x.shape) for x in conv_model.parameters()]))\n",
    "# conv_model(data[0][0][None,:,None].cuda()).shape\n",
    "train(conv_model,data,100,lr=1e-3, half=half, cuda=cuda)\n",
    "# 1.91E+02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.randn(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"180709_resVAE_4layer_decode_3.64e+9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.save(conv_model.state_dict(),model_name+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Memory usage: %s (gb)' % (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024**2))\n",
    "# del(conv_model)\n",
    "gc.collect()\n",
    "T.cuda.empty_cache()\n",
    "print('Memory usage: %s (gb)' % (resource.getrusage(resource.RUSAGE_SELF).ru_maxrss/1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_vs_real(model,data):\n",
    "    plt.figure(figsize=(30,15))\n",
    "\n",
    "    with T.no_grad():\n",
    "        for i in range(4):\n",
    "            time = np.random.randint(len(data))\n",
    "            z = np.random.randint(nZ)\n",
    "            X, Y = data[time]\n",
    "            x = X[None].cuda()\n",
    "            y = Y[None].cuda()\n",
    "            X_pred, _, _ = model(x)\n",
    "            loss = float(F.mse_loss(X_pred,y).cpu())\n",
    "            prev_loss = float(F.mse_loss(x,y).cpu())\n",
    "            zero_loss = float(F.mse_loss(y,T.zeros_like(y)).cpu())\n",
    "            mymax = max(float(y[0,z].max()[0]),float(x[0,z].max()[0]),float(X_pred[0,z].max()[0]))\n",
    "            plt.subplot(4,3,i*3+1)\n",
    "            plt.imshow(X[z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "            plt.title(\"Time=\"+str(time) + \", z=\"+str(z))\n",
    "            plt.subplot(4,3,i*3+2)\n",
    "            plt.imshow(Y[z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "            plt.title(\"Time=\"+str(time+1) + \", z=\"+str(z))\n",
    "            plt.subplot(4,3,i*3+3)\n",
    "            plt.imshow(X_pred[0,z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "            plt.title(\"MSE: Pred={:.0f}, Prev={:.0f}, Zero={:.0f}\".format(loss,prev_loss,zero_loss))\n",
    "\n",
    "plot_model_vs_real(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_from_embedding(model,frame,embedding,niters=20, lr=1e-3):\n",
    "    model.eval()\n",
    "    frame = frame.cuda()\n",
    "    frame.requires_grad = True\n",
    "    embedding_pred, _ = model.encode(frame)\n",
    "    print(embedding_pred.shape)\n",
    "    embedding_pred.backward(gradient=embedding)\n",
    "    return frame.grad[0]\n",
    "\n",
    "# frame = data[0][0]\n",
    "# embedding = T.from_numpy(np.eye(10)[0].astype(np.float32)).cuda()\n",
    "# prev_img = get_gradient_from_embedding(conv_model, frame[None], embedding[None])\n",
    "# with T.no_grad():\n",
    "#     next_img = conv_model.decode(embedding[None])[0]\n",
    "# plt.imshow(prev_img[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_from_embedding(model,frame,embedding,niters=75, lr=1e-1, rand=False):\n",
    "    \"Take an embedding vector, and use backprop to find the volume\"\n",
    "    if rand:\n",
    "        prev_img = T.rand_like(frame[None], requires_grad=True).cuda()\n",
    "    else:\n",
    "        prev_img = frame[None].cuda()\n",
    "        prev_img.requires_grad = True\n",
    "    optimizer = T.optim.Adam([prev_img],lr=lr)\n",
    "    model.eval()\n",
    "    for i in range(niters):\n",
    "        embedding_pred, _ = model.encode(prev_img)\n",
    "        loss = F.mse_loss(embedding_pred,embedding[None]) #+ 1e-7*T.norm(prev_img,1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(\"iter {} loss: \".format(i), float(loss))\n",
    "    model.train()\n",
    "    return prev_img[0].detach().cpu().numpy()\n",
    "\n",
    "# frame = data[0][0].cuda()\n",
    "# embedding = T.from_numpy(1000*np.eye(10)[1].astype(np.float32)).cuda()\n",
    "# prev_img = get_input_from_embedding(conv_model, frame, embedding,niters=81, rand=True)\n",
    "# plt.imshow(prev_img[6])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imgs = []\n",
    "for _ in range(10):\n",
    "    imgs.append(get_input_from_embedding(conv_model, frame, embedding,niters=81, rand=True)[[6]])\n",
    "plt.imshow(np.vstack(imgs).mean(0))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "frame = data[500][0]\n",
    "# frame = 'rand'\n",
    "embedding = T.from_numpy(1000*np.eye(10)[1].astype(np.float32)).cuda()\n",
    "prev_img = get_input_from_embedding(conv_model, frame, embedding,niters=100)\n",
    "plt.imshow(prev_img[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret(model,prev_vol, next_vol, nEmbedding, prev_func):\n",
    "    \"Plot prev & next frame for each latent dimension\"\n",
    "    plt.figure(figsize=(10,50))\n",
    "    plt.subplot(2+nEmbedding,2,1)\n",
    "    plt.imshow(prev_vol[6])\n",
    "    plt.title(\"Prev Frame\")\n",
    "    plt.subplot(2+nEmbedding,2,2)\n",
    "    plt.imshow(next_vol[6])\n",
    "    plt.title(\"Next Frame\")\n",
    "    \n",
    "    embedding = T.from_numpy(np.zeros(nEmbedding).astype(np.float32)).cuda()[None]\n",
    "    with T.no_grad():\n",
    "        next_img = model.decode(embedding)[0]\n",
    "    prev_img = prev_func(model, prev_vol[None], embedding)\n",
    "    plt.subplot(2+nEmbedding,2,3)\n",
    "    plt.imshow(prev_img[6])\n",
    "    plt.title(\"Prev (Zero Vector)\")\n",
    "    plt.subplot(2+nEmbedding,2,4)\n",
    "    plt.imshow(next_img[6])\n",
    "    plt.title(\"Next (Zero Vector)\")\n",
    "    for i in range(nEmbedding):\n",
    "        embedding = T.from_numpy(np.eye(nEmbedding)[i].astype(np.float32)).cuda()[None]\n",
    "        with T.no_grad():\n",
    "            next_img = model.decode(embedding)[0]\n",
    "        prev_img = prev_func(model, prev_vol[None], embedding)\n",
    "        plt.subplot(2+nEmbedding,2,i*2+5)\n",
    "        plt.imshow(prev_img[6])\n",
    "        plt.title(\"Prev (Dim {})\".format(i))\n",
    "        plt.subplot(2+nEmbedding,2,i*2+6)\n",
    "        plt.imshow(next_img[6])\n",
    "        plt.title(\"Next (Dim {})\".format(i))\n",
    "    plt.tight_layout()\n",
    "\n",
    "x, y = data[1000]\n",
    "interpret(conv_model,x,y,10,get_gradient_from_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_over_time(model,data, batch_size=64):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    embeddings = []\n",
    "    model.eval()\n",
    "    for batch_data in dataloader:\n",
    "        X, _ = batch_data\n",
    "        # add 1 channel\n",
    "        with T.no_grad():\n",
    "            embedding, _ = model.encode(X.cuda())\n",
    "        embeddings.append(embedding.cpu().numpy())\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    nEmbeddings = embeddings.shape[1]\n",
    "    half = int(np.ceil(nEmbeddings / 2))\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(embeddings[:,0:half])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half))\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(embeddings[:,half:])\n",
    "    plt.title(\"Embeddings over time\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.legend(np.arange(half,nEmbeddings))\n",
    "    plt.tight_layout()\n",
    "    return embeddings\n",
    "embeddings = plot_embedding_over_time(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skvideo.io\n",
    "def makePredVideo(model, data, batch_size=8):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=False)\n",
    "    writer = skvideo.io.FFmpegWriter(model_name + \".mp4\",outputdict={\n",
    "        '-b': '30000000'})\n",
    "    for batch_data in dataloader:\n",
    "        X, _ = batch_data\n",
    "        with T.no_grad():\n",
    "            vol_preds, _, _ = model(X.cuda())\n",
    "        for actual,pred in zip(X,vol_preds):\n",
    "            # 7th z layer\n",
    "            f = pred[6]\n",
    "            H = f.shape[0]\n",
    "            frame = np.zeros([H*2,f.shape[1]])\n",
    "            frame[:H] = actual[6]\n",
    "            frame[H:] = pred[6]\n",
    "            writer.writeFrame(frame)\n",
    "            \n",
    "    writer.close()\n",
    "    return frame, actual[6], pred[6]\n",
    "frame, actual, pred = makePredVideo(conv_model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with T.no_grad():\n",
    "    time = 1864\n",
    "    z = 6\n",
    "    X, Y = data[time]\n",
    "    x = X[None].cuda()\n",
    "    y = Y[None].cuda()\n",
    "    X_pred, _, _ = conv_model(x)\n",
    "    loss = float(F.mse_loss(X_pred,y).cpu())\n",
    "    prev_loss = float(F.mse_loss(x,y).cpu())\n",
    "    zero_loss = float(F.mse_loss(y,T.zeros_like(y)).cpu())\n",
    "    mymax = max(float(y[0,z].max()[0]),float(x[0,z].max()[0]),float(X_pred[0,z].max()[0]))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(X[z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "    plt.title(\"Time=\"+str(time) + \", z=\"+str(z))\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(Y[z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "    plt.title(\"Time=\"+str(time+1) + \", z=\"+str(z))\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(X_pred[0,z].cpu().numpy(), vmin=0, vmax=mymax)\n",
    "    plt.title(\"MSE: Pred={:.0f}, Prev={:.0f}, Zero={:.0f}\".format(loss,prev_loss,zero_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(actual.min(),actual.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(actual.min(),actual.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred.min(),pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(actual,vmin=0,vmax=862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred,vmin=0,vmax=862)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
